{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "supported-phoenix",
   "metadata": {},
   "source": [
    "For this second sweep the following changes have been made:\n",
    " - Parameters have been reduced to the range around the optimal parameter found during sweep 1.\n",
    " - A new parameter called dataset is added that randomly chooses between strib and kolding datasets.\n",
    " - Some parameters have been defaulted such as optimizer and lookback.\n",
    "     - This is done to improve the other parameters even more, as these parameters showed to be the best choice in run 1.\n",
    " - For the sake of experiment, I will add an option for zero additional layers to the number of layers parameter.\n",
    " - Seeds have been added.\n",
    " - Number of Epochs have been reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "worth-monroe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "from utils import processing\n",
    "from utils import utils\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import LSTM, GRU, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, TimeDistributed, \\\n",
    "    BatchNormalization\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "unnecessary-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
    "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
    "tf.random.set_seed(hash(\"by removing stochasticity\") % 2**32 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "mineral-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams[\"figure.figsize\"] = (18,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "gothic-affiliation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "current-judgment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(config):\n",
    "    # Load csv & parse dates to datetime index\n",
    "    data = pd.read_csv(f'../data/processed/{config.dataset}_features.csv', index_col='Datetime', parse_dates=['Datetime'])\n",
    "    # Select Features\n",
    "    data = data[['Value', 'sunshine_mins', 'airtemp_c', 'daylength_hrs', 'wkdy_sin', 'wkdy_cos', 'wknd', 'mnth_sin', 'mnth_cos']]\n",
    "    \n",
    "    train, val, test = processing.create_datasets(data, split=split, \n",
    "                                                  steps=steps, lookback=config.lookback, \n",
    "                                                  horizon=horizon, batch_size=config.batch_size, \n",
    "                                                  scaler='standard')    \n",
    "    return train, val, test\n",
    "    \n",
    "    \n",
    "def build_model(config):\n",
    "        \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Input(shape=(config.lookback, config.num_features)))\n",
    "\n",
    "    # CNN Block\n",
    "    model.add(Conv1D(filters=config.cnn_layer_size_1, kernel_size=3, activation=config.activation_cnn))\n",
    "    model.add(MaxPooling1D(pool_size=2))    \n",
    "\n",
    "    model.add(Conv1D(filters=config.cnn_layer_size_2, kernel_size=3, activation=config.activation_cnn))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(Conv1D(filters=config.cnn_layer_size_3, kernel_size=3, activation=config.activation_cnn))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    # RNN Block\n",
    "\n",
    "    model.add(GRU(config.gru_layer_size_1, return_sequences=True, activation=config.activation_gru))\n",
    "    model.add(Dropout(config.dropout))\n",
    "    \n",
    "    model.add(GRU(config.gru_layer_size_2, return_sequences=True, activation=config.activation_gru))\n",
    "    model.add(Dropout(config.dropout))\n",
    "    \n",
    "    model.add(GRU(config.gru_layer_size_3, return_sequences=False, activation=config.activation_gru))\n",
    "    model.add(Dropout(config.dropout))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    opt = config.optimizer\n",
    "    if opt == 'sgd':\n",
    "        opt = SGD(learning_rate=config.learning_rate, momentum=config.momentum)\n",
    "    elif opt == 'rmsprop':\n",
    "        opt = RMSprop(learning_rate=config.learning_rate)\n",
    "    else:\n",
    "        opt = Adam(learning_rate=config.learning_rate)\n",
    "        \n",
    "    model.compile(optimizer=opt, loss='mse', metrics=['mae', 'mape'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def log_defaults():\n",
    "    # Default values from the first sweep\n",
    "    # The following values resulted in the strongest model\n",
    "    wandb_config = {\n",
    "        'num_features' : 9,\n",
    "        'epochs' : 50,\n",
    "        'batch_size' : 227,\n",
    "        'num_cnn_layers' : 2, # Number of additional layers\n",
    "        'num_gru_layers' : 2, # Number of additional layers\n",
    "        'optimizer' : 'sgd',\n",
    "        'dropout' : 0.015,\n",
    "        'lookback' : 718,\n",
    "        'activation_cnn' : 'relu',\n",
    "        'activation_gru' : 'tanh',\n",
    "        'cnn_layer_size_1' : 70,\n",
    "        'cnn_layer_size_2' : 106,\n",
    "        'cnn_layer_size_3' : 106,\n",
    "        'gru_layer_size_1' : 51,\n",
    "        'gru_layer_size_2' : 194,\n",
    "        'gru_layer_size_3' : 194,\n",
    "        'learning_rate' : 0.024,\n",
    "        'momentum' : 0.9,\n",
    "        'dataset' : 'kolding'\n",
    "    }\n",
    "    return wandb_config\n",
    "    \n",
    "\n",
    "def run_tuner():\n",
    "    \n",
    "    wandb.init(config=log_defaults(), group='cnnrnn-sweep-3', project='thesis')\n",
    "    \n",
    "    model = build_model(config=wandb.config)\n",
    "    \n",
    "    train, val, _ = load_data(config=wandb.config)\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.6, min_lr=0.001, patience=5)\n",
    "    \n",
    "    callbacks = [WandbCallback(), reduce_lr]\n",
    "    \n",
    "    model.fit(\n",
    "        train,\n",
    "        epochs=wandb.config.epochs,\n",
    "        validation_data=val,\n",
    "        callbacks=callbacks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "strange-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweep Config\n",
    "sweep_config = {\n",
    "    'method': 'random',\n",
    "    'metric': {\n",
    "        'name': 'val_loss',\n",
    "        'goal': 'minimize'\n",
    "    },\n",
    "    'early_terminate': {\n",
    "        'type': 'hyperband',\n",
    "        'min_iter': 5\n",
    "    },\n",
    "    'parameters': {\n",
    "        'num_features' : {\n",
    "            'value' : 9\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'distribution': 'q_log_uniform',\n",
    "            'q': 1,\n",
    "            'min': math.log(32),\n",
    "            'max': math.log(256)\n",
    "        },\n",
    "        'lookback': {\n",
    "            'value': 24*31\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'value': 'sgd'\n",
    "        },\n",
    "        'dropout': {\n",
    "            'distribution': 'uniform',\n",
    "            'min': 0.01,\n",
    "            'max': 0.5\n",
    "        },\n",
    "        'epochs': {\n",
    "            'value': 25\n",
    "        },\n",
    "        'activation_gru': {\n",
    "            'value': 'tanh'\n",
    "        },\n",
    "        'activation_cnn': {\n",
    "            'value': 'relu'\n",
    "        },\n",
    "        'cnn_layer_size_1': {\n",
    "            'distribution': 'q_log_uniform',\n",
    "            'q': 1,\n",
    "            'min': math.log(32),\n",
    "            'max': math.log(256)\n",
    "        },\n",
    "        'cnn_layer_size_2': {\n",
    "            'distribution': 'q_log_uniform',\n",
    "            'q': 1,\n",
    "            'min': math.log(32),\n",
    "            'max': math.log(256)\n",
    "        },\n",
    "        'cnn_layer_size_3': {\n",
    "            'distribution': 'q_log_uniform',\n",
    "            'q': 1,\n",
    "            'min': math.log(32),\n",
    "            'max': math.log(256)\n",
    "        },\n",
    "        'gru_layer_size_1': {\n",
    "            'distribution': 'q_log_uniform',\n",
    "            'q': 1,\n",
    "            'min': math.log(32),\n",
    "            'max': math.log(256)\n",
    "        },\n",
    "        'gru_layer_size_2': {\n",
    "            'distribution': 'q_log_uniform',\n",
    "            'q': 1,\n",
    "            'min': math.log(32),\n",
    "            'max': math.log(256)\n",
    "        },\n",
    "        'gru_layer_size_3': {\n",
    "            'distribution': 'q_log_uniform',\n",
    "            'q': 1,\n",
    "            'min': math.log(32),\n",
    "            'max': math.log(256)\n",
    "        },\n",
    "        'learning_rate': {\n",
    "            'distribution': 'uniform',\n",
    "            'min': 0.001,\n",
    "            'max': 0.04\n",
    "        },\n",
    "        'momentum': {\n",
    "            'distribution': 'uniform',\n",
    "            'min': 0.5,\n",
    "            'max': 1\n",
    "        },\n",
    "        'num_cnn_layers': {\n",
    "            'value': 2\n",
    "        },\n",
    "        'num_gru_layers': {\n",
    "            'value': 2\n",
    "        },\n",
    "        'dataset': {\n",
    "            'values': ['kolding', 'strib']\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "animated-reminder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional Parameters\n",
    "split = 0.80 # split percentage for training data\n",
    "steps = 1 # timesteps: 1 hour\n",
    "horizon = 1 # the target hour in the future we want to predict 1 hour ahead\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "recovered-wales",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: f6tc66bl\n",
      "Sweep URL: https://wandb.ai/nbvanting/thesis/sweeps/f6tc66bl\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project='thesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "above-birthday",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: vzdog0go with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 180\n",
      "wandb: \tcnn_layer_size_1: 92\n",
      "wandb: \tcnn_layer_size_2: 94\n",
      "wandb: \tcnn_layer_size_3: 89\n",
      "wandb: \tdataset: kolding\n",
      "wandb: \tdropout: 0.3128109462373897\n",
      "wandb: \tepochs: 25\n",
      "wandb: \tgru_layer_size_1: 33\n",
      "wandb: \tgru_layer_size_2: 85\n",
      "wandb: \tgru_layer_size_3: 63\n",
      "wandb: \tlearning_rate: 0.009599069072943795\n",
      "wandb: \tlookback: 744\n",
      "wandb: \tmomentum: 0.9184209591699685\n",
      "wandb: \tnum_cnn_layers: 2\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 2\n",
      "wandb: \toptimizer: sgd\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n",
      "c:\\users\\nicol\\envs\\thesis\\lib\\site-packages\\IPython\\html.py:12: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  warn(\"The `IPython.html` package has been deprecated since IPython 4.0. \"\n",
      "wandb: wandb version 0.10.29 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">rose-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/f6tc66bl\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/f6tc66bl</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/vzdog0go\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/vzdog0go</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_162825-vzdog0go</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "81/81 [==============================] - 53s 579ms/step - loss: 0.7962 - mae: 0.6994 - mape: 362.8096 - val_loss: 1.3632 - val_mae: 0.8970 - val_mape: 210.3083\n",
      "Epoch 2/25\n",
      "81/81 [==============================] - 45s 558ms/step - loss: 0.7166 - mae: 0.6660 - mape: 312.5047 - val_loss: 1.3332 - val_mae: 0.9141 - val_mape: 242.1300\n",
      "Epoch 3/25\n",
      "81/81 [==============================] - 45s 556ms/step - loss: 0.6809 - mae: 0.6493 - mape: 343.6742 - val_loss: 1.2124 - val_mae: 0.8796 - val_mape: 227.2636\n",
      "Epoch 4/25\n",
      "81/81 [==============================] - 46s 569ms/step - loss: 0.6297 - mae: 0.6328 - mape: 628.4665 - val_loss: 0.6221 - val_mae: 0.6143 - val_mape: 190.1386\n",
      "Epoch 5/25\n",
      "81/81 [==============================] - 45s 557ms/step - loss: 0.4328 - mae: 0.5148 - mape: 484.3412 - val_loss: 0.4155 - val_mae: 0.5074 - val_mape: 177.8502\n",
      "Epoch 6/25\n",
      "81/81 [==============================] - 45s 555ms/step - loss: 0.3364 - mae: 0.4514 - mape: 530.2902 - val_loss: 0.2913 - val_mae: 0.4294 - val_mape: 160.9912\n",
      "Epoch 7/25\n",
      "81/81 [==============================] - 45s 556ms/step - loss: 0.2868 - mae: 0.4164 - mape: 500.4998 - val_loss: 0.2686 - val_mae: 0.4250 - val_mape: 168.4665\n",
      "Epoch 8/25\n",
      "81/81 [==============================] - 45s 557ms/step - loss: 0.2452 - mae: 0.3863 - mape: 533.7569 - val_loss: 0.2121 - val_mae: 0.3668 - val_mape: 135.5384\n",
      "Epoch 9/25\n",
      "81/81 [==============================] - 45s 555ms/step - loss: 0.2159 - mae: 0.3614 - mape: 682.3569 - val_loss: 0.1991 - val_mae: 0.3557 - val_mape: 138.5625\n",
      "Epoch 10/25\n",
      "81/81 [==============================] - 49s 600ms/step - loss: 0.2057 - mae: 0.3504 - mape: 519.1075 - val_loss: 0.1663 - val_mae: 0.3264 - val_mape: 106.8742\n",
      "Epoch 11/25\n",
      "81/81 [==============================] - 46s 570ms/step - loss: 0.1910 - mae: 0.3375 - mape: 477.7802 - val_loss: 0.1651 - val_mae: 0.3300 - val_mape: 121.1153\n",
      "Epoch 12/25\n",
      "81/81 [==============================] - 45s 557ms/step - loss: 0.1805 - mae: 0.3289 - mape: 269.7864 - val_loss: 0.1537 - val_mae: 0.3154 - val_mape: 119.5219\n",
      "Epoch 13/25\n",
      "81/81 [==============================] - 46s 564ms/step - loss: 0.1637 - mae: 0.3111 - mape: 335.1184 - val_loss: 0.1555 - val_mae: 0.3238 - val_mape: 123.1368\n",
      "Epoch 14/25\n",
      "81/81 [==============================] - 46s 573ms/step - loss: 0.1626 - mae: 0.3102 - mape: 363.3109 - val_loss: 0.1356 - val_mae: 0.2948 - val_mape: 108.6491\n",
      "Epoch 15/25\n",
      "81/81 [==============================] - 47s 574ms/step - loss: 0.1497 - mae: 0.2981 - mape: 485.1779 - val_loss: 0.1391 - val_mae: 0.3015 - val_mape: 116.6301\n",
      "Epoch 16/25\n",
      "81/81 [==============================] - 46s 568ms/step - loss: 0.1475 - mae: 0.2957 - mape: 306.9108 - val_loss: 0.1257 - val_mae: 0.2880 - val_mape: 102.6236\n",
      "Epoch 17/25\n",
      "81/81 [==============================] - 47s 581ms/step - loss: 0.1373 - mae: 0.2870 - mape: 313.9802 - val_loss: 0.1461 - val_mae: 0.3077 - val_mape: 110.2815\n",
      "Epoch 18/25\n",
      "81/81 [==============================] - 48s 588ms/step - loss: 0.1384 - mae: 0.2855 - mape: 323.2071 - val_loss: 0.1603 - val_mae: 0.3209 - val_mape: 126.5450\n",
      "Epoch 19/25\n",
      "81/81 [==============================] - 48s 591ms/step - loss: 0.1330 - mae: 0.2805 - mape: 396.1546 - val_loss: 0.1148 - val_mae: 0.2727 - val_mape: 97.9742\n",
      "Epoch 20/25\n",
      "81/81 [==============================] - 48s 589ms/step - loss: 0.1279 - mae: 0.2749 - mape: 196.6629 - val_loss: 0.1195 - val_mae: 0.2796 - val_mape: 95.7779\n",
      "Epoch 21/25\n",
      "81/81 [==============================] - 47s 584ms/step - loss: 0.1188 - mae: 0.2661 - mape: 590.7768 - val_loss: 0.1301 - val_mae: 0.2923 - val_mape: 104.3552\n",
      "Epoch 22/25\n",
      "81/81 [==============================] - 47s 585ms/step - loss: 0.1282 - mae: 0.2758 - mape: 300.4692 - val_loss: 0.1190 - val_mae: 0.2809 - val_mape: 105.5273\n",
      "Epoch 23/25\n",
      "81/81 [==============================] - 47s 584ms/step - loss: 0.1159 - mae: 0.2626 - mape: 278.5665 - val_loss: 0.1097 - val_mae: 0.2666 - val_mape: 104.6923\n",
      "Epoch 24/25\n",
      "81/81 [==============================] - 48s 588ms/step - loss: 0.1186 - mae: 0.2653 - mape: 385.0279 - val_loss: 0.1215 - val_mae: 0.2852 - val_mape: 111.4148\n",
      "Epoch 25/25\n",
      "81/81 [==============================] - 50s 614ms/step - loss: 0.1133 - mae: 0.2588 - mape: 324.6453 - val_loss: 0.1174 - val_mae: 0.2767 - val_mape: 106.7445\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 39116<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_162825-vzdog0go\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_162825-vzdog0go\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>24</td></tr><tr><td>loss</td><td>0.11301</td></tr><tr><td>mae</td><td>0.25883</td></tr><tr><td>mape</td><td>282.91248</td></tr><tr><td>val_loss</td><td>0.1174</td></tr><tr><td>val_mae</td><td>0.27669</td></tr><tr><td>val_mape</td><td>106.74454</td></tr><tr><td>_runtime</td><td>1176</td></tr><tr><td>_timestamp</td><td>1620139681</td></tr><tr><td>_step</td><td>24</td></tr><tr><td>best_val_loss</td><td>0.1097</td></tr><tr><td>best_epoch</td><td>22</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>██▇▆▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mae</td><td>███▇▅▄▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mape</td><td>▄▃▃▆▇▆█▆▆▅▆▃▃▃▄▃▃▃▃▁▅▂▂▃▂</td></tr><tr><td>val_loss</td><td>██▇▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_mae</td><td>███▅▄▃▃▂▂▂▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>val_mape</td><td>▆█▇▆▅▄▄▃▃▂▂▂▂▂▂▁▂▂▁▁▁▁▁▂▂</td></tr><tr><td>_runtime</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▆▆▆▆▇▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▆▆▆▆▇▇▇██</td></tr><tr><td>_step</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">rose-sweep-1</strong>: <a href=\"https://wandb.ai/nbvanting/thesis/runs/vzdog0go\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/vzdog0go</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: wbxmnktc with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 107\n",
      "wandb: \tcnn_layer_size_1: 89\n",
      "wandb: \tcnn_layer_size_2: 52\n",
      "wandb: \tcnn_layer_size_3: 45\n",
      "wandb: \tdataset: kolding\n",
      "wandb: \tdropout: 0.2722160418051974\n",
      "wandb: \tepochs: 25\n",
      "wandb: \tgru_layer_size_1: 60\n",
      "wandb: \tgru_layer_size_2: 75\n",
      "wandb: \tgru_layer_size_3: 176\n",
      "wandb: \tlearning_rate: 0.014346654394248926\n",
      "wandb: \tlookback: 744\n",
      "wandb: \tmomentum: 0.6199037047603387\n",
      "wandb: \tnum_cnn_layers: 2\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 2\n",
      "wandb: \toptimizer: sgd\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n",
      "wandb: wandb version 0.10.29 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">ethereal-sweep-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/f6tc66bl\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/f6tc66bl</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/wbxmnktc\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/wbxmnktc</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_164805-wbxmnktc</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "137/137 [==============================] - 67s 438ms/step - loss: 0.7758 - mae: 0.6895 - mape: 320.8885 - val_loss: 1.3529 - val_mae: 0.9256 - val_mape: 261.4790\n",
      "Epoch 2/25\n",
      "137/137 [==============================] - 60s 441ms/step - loss: 0.7069 - mae: 0.6652 - mape: 354.2654 - val_loss: 1.3149 - val_mae: 0.9199 - val_mape: 258.4648\n",
      "Epoch 3/25\n",
      "137/137 [==============================] - 62s 450ms/step - loss: 0.6944 - mae: 0.6640 - mape: 376.6527 - val_loss: 1.2811 - val_mae: 0.9447 - val_mape: 303.8045\n",
      "Epoch 4/25\n",
      "137/137 [==============================] - 57s 419ms/step - loss: 0.6597 - mae: 0.6486 - mape: 449.0285 - val_loss: 1.1726 - val_mae: 0.9213 - val_mape: 314.0505\n",
      "Epoch 5/25\n",
      "137/137 [==============================] - 61s 446ms/step - loss: 0.5889 - mae: 0.6164 - mape: 456.5183 - val_loss: 0.7068 - val_mae: 0.6599 - val_mape: 172.4054\n",
      "Epoch 6/25\n",
      "137/137 [==============================] - 59s 433ms/step - loss: 0.4559 - mae: 0.5319 - mape: 532.3486 - val_loss: 0.6043 - val_mae: 0.5789 - val_mape: 158.7605\n",
      "Epoch 7/25\n",
      "101/137 [=====================>........] - ETA: 15s - loss: 0.3979 - mae: 0.4921 - mape: 338.7516"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3036<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_164805-wbxmnktc\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_164805-wbxmnktc\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>5</td></tr><tr><td>loss</td><td>0.43229</td></tr><tr><td>mae</td><td>0.51871</td></tr><tr><td>mape</td><td>761.77686</td></tr><tr><td>val_loss</td><td>0.60431</td></tr><tr><td>val_mae</td><td>0.57894</td></tr><tr><td>val_mape</td><td>158.76051</td></tr><tr><td>_runtime</td><td>377</td></tr><tr><td>_timestamp</td><td>1620140062</td></tr><tr><td>_step</td><td>5</td></tr><tr><td>best_val_loss</td><td>0.60431</td></tr><tr><td>best_epoch</td><td>5</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▄▅▇█</td></tr><tr><td>loss</td><td>█▇▇▆▄▁</td></tr><tr><td>mae</td><td>██▇▇▄▁</td></tr><tr><td>mape</td><td>▁▁▂▃▇█</td></tr><tr><td>val_loss</td><td>██▇▆▂▁</td></tr><tr><td>val_mae</td><td>████▃▁</td></tr><tr><td>val_mape</td><td>▆▅██▂▁</td></tr><tr><td>_runtime</td><td>▁▂▄▅▇█</td></tr><tr><td>_timestamp</td><td>▁▂▄▅▇█</td></tr><tr><td>_step</td><td>▁▂▄▅▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">ethereal-sweep-2</strong>: <a href=\"https://wandb.ai/nbvanting/thesis/runs/wbxmnktc\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/wbxmnktc</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: 94gywita with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 163\n",
      "wandb: \tcnn_layer_size_1: 209\n",
      "wandb: \tcnn_layer_size_2: 137\n",
      "wandb: \tcnn_layer_size_3: 169\n",
      "wandb: \tdataset: kolding\n",
      "wandb: \tdropout: 0.41776592352622927\n",
      "wandb: \tepochs: 25\n",
      "wandb: \tgru_layer_size_1: 87\n",
      "wandb: \tgru_layer_size_2: 48\n",
      "wandb: \tgru_layer_size_3: 57\n",
      "wandb: \tlearning_rate: 0.004941414861716273\n",
      "wandb: \tlookback: 744\n",
      "wandb: \tmomentum: 0.7288996917868451\n",
      "wandb: \tnum_cnn_layers: 2\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 2\n",
      "wandb: \toptimizer: sgd\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n",
      "wandb: wandb version 0.10.29 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">elated-sweep-3</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/f6tc66bl\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/f6tc66bl</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/94gywita\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/94gywita</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_165511-94gywita</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "90/90 [==============================] - 99s 1s/step - loss: 0.8133 - mae: 0.7073 - mape: 383.0837 - val_loss: 1.3721 - val_mae: 0.9149 - val_mape: 246.8313\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 90s 1s/step - loss: 0.7299 - mae: 0.6751 - mape: 373.8995 - val_loss: 1.3667 - val_mae: 0.9141 - val_mape: 247.9168\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 93s 1s/step - loss: 0.7142 - mae: 0.6682 - mape: 511.8698 - val_loss: 1.3608 - val_mae: 0.9010 - val_mape: 228.8569\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 96s 1s/step - loss: 0.7213 - mae: 0.6687 - mape: 444.9777 - val_loss: 1.3616 - val_mae: 0.9454 - val_mape: 291.0338\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 91s 1s/step - loss: 0.7035 - mae: 0.6637 - mape: 393.3679 - val_loss: 1.3375 - val_mae: 0.8933 - val_mape: 218.3350\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 97s 1s/step - loss: 0.6905 - mae: 0.6575 - mape: 457.6458 - val_loss: 1.3080 - val_mae: 0.8961 - val_mape: 228.6194\n",
      "Epoch 7/25\n",
      "24/90 [=======>......................] - ETA: 1:09 - loss: 0.6909 - mae: 0.6610 - mape: 315.1373"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 41176<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_165511-94gywita\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_165511-94gywita\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>5</td></tr><tr><td>loss</td><td>0.68867</td></tr><tr><td>mae</td><td>0.65805</td></tr><tr><td>mape</td><td>423.25562</td></tr><tr><td>val_loss</td><td>1.30803</td></tr><tr><td>val_mae</td><td>0.89615</td></tr><tr><td>val_mape</td><td>228.61937</td></tr><tr><td>_runtime</td><td>570</td></tr><tr><td>_timestamp</td><td>1620140681</td></tr><tr><td>_step</td><td>5</td></tr><tr><td>best_val_loss</td><td>1.30803</td></tr><tr><td>best_epoch</td><td>5</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▄▅▇█</td></tr><tr><td>loss</td><td>█▄▃▃▂▁</td></tr><tr><td>mae</td><td>█▄▃▃▂▁</td></tr><tr><td>mape</td><td>▅▁█▅▂▆</td></tr><tr><td>val_loss</td><td>█▇▇▇▄▁</td></tr><tr><td>val_mae</td><td>▄▄▂█▁▁</td></tr><tr><td>val_mape</td><td>▄▄▂█▁▂</td></tr><tr><td>_runtime</td><td>▁▂▄▅▇█</td></tr><tr><td>_timestamp</td><td>▁▂▄▅▇█</td></tr><tr><td>_step</td><td>▁▂▄▅▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">elated-sweep-3</strong>: <a href=\"https://wandb.ai/nbvanting/thesis/runs/94gywita\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/94gywita</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: lmy1jl92 with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 112\n",
      "wandb: \tcnn_layer_size_1: 105\n",
      "wandb: \tcnn_layer_size_2: 67\n",
      "wandb: \tcnn_layer_size_3: 74\n",
      "wandb: \tdataset: strib\n",
      "wandb: \tdropout: 0.1845357936746025\n",
      "wandb: \tepochs: 25\n",
      "wandb: \tgru_layer_size_1: 201\n",
      "wandb: \tgru_layer_size_2: 101\n",
      "wandb: \tgru_layer_size_3: 199\n",
      "wandb: \tlearning_rate: 0.03896813199932402\n",
      "wandb: \tlookback: 744\n",
      "wandb: \tmomentum: 0.6830867443211333\n",
      "wandb: \tnum_cnn_layers: 2\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 2\n",
      "wandb: \toptimizer: sgd\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n",
      "wandb: wandb version 0.10.29 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">ruby-sweep-4</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/f6tc66bl\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/f6tc66bl</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/lmy1jl92\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/lmy1jl92</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_170513-lmy1jl92</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "130/130 [==============================] - 121s 881ms/step - loss: 0.8002 - mae: 0.7096 - mape: 211.9159 - val_loss: 1.2209 - val_mae: 0.8720 - val_mape: 164.0910\n",
      "Epoch 2/25\n",
      "130/130 [==============================] - 107s 826ms/step - loss: 0.6407 - mae: 0.6339 - mape: 243.2071 - val_loss: 0.3185 - val_mae: 0.4256 - val_mape: 127.4579\n",
      "Epoch 3/25\n",
      "130/130 [==============================] - 110s 844ms/step - loss: 0.2379 - mae: 0.3810 - mape: 231.6937 - val_loss: 0.1750 - val_mae: 0.3255 - val_mape: 97.7555\n",
      "Epoch 4/25\n",
      "130/130 [==============================] - 108s 831ms/step - loss: 0.1715 - mae: 0.3209 - mape: 197.3703 - val_loss: 0.1472 - val_mae: 0.3038 - val_mape: 85.1703\n",
      "Epoch 5/25\n",
      "130/130 [==============================] - 109s 835ms/step - loss: 0.1423 - mae: 0.2918 - mape: 181.5891 - val_loss: 0.1803 - val_mae: 0.3228 - val_mape: 66.4564\n",
      "Epoch 6/25\n",
      "130/130 [==============================] - 106s 812ms/step - loss: 0.1296 - mae: 0.2764 - mape: 170.4278 - val_loss: 0.1169 - val_mae: 0.2690 - val_mape: 80.3183\n",
      "Epoch 7/25\n",
      "130/130 [==============================] - 107s 824ms/step - loss: 0.1176 - mae: 0.2614 - mape: 169.5903 - val_loss: 0.1142 - val_mae: 0.2693 - val_mape: 74.9876\n",
      "Epoch 8/25\n",
      "130/130 [==============================] - 110s 848ms/step - loss: 0.1086 - mae: 0.2489 - mape: 165.7310 - val_loss: 0.1132 - val_mae: 0.2711 - val_mape: 81.5186\n",
      "Epoch 9/25\n",
      "130/130 [==============================] - 106s 819ms/step - loss: 0.1044 - mae: 0.2475 - mape: 173.1238 - val_loss: 0.1139 - val_mae: 0.2566 - val_mape: 65.7459\n",
      "Epoch 10/25\n",
      "130/130 [==============================] - 106s 812ms/step - loss: 0.1002 - mae: 0.2395 - mape: 152.6154 - val_loss: 0.1060 - val_mae: 0.2614 - val_mape: 80.2521\n",
      "Epoch 11/25\n",
      "130/130 [==============================] - 106s 818ms/step - loss: 0.0959 - mae: 0.2359 - mape: 146.6894 - val_loss: 0.1009 - val_mae: 0.2432 - val_mape: 64.4979\n",
      "Epoch 12/25\n",
      "130/130 [==============================] - 107s 820ms/step - loss: 0.0946 - mae: 0.2319 - mape: 133.6053 - val_loss: 0.1051 - val_mae: 0.2564 - val_mape: 78.6263\n",
      "Epoch 13/25\n",
      "130/130 [==============================] - 104s 802ms/step - loss: 0.0910 - mae: 0.2296 - mape: 136.7183 - val_loss: 0.1209 - val_mae: 0.2606 - val_mape: 60.5508\n",
      "Epoch 14/25\n",
      "130/130 [==============================] - 106s 818ms/step - loss: 0.0916 - mae: 0.2276 - mape: 138.1191 - val_loss: 0.0982 - val_mae: 0.2460 - val_mape: 75.3643\n",
      "Epoch 15/25\n",
      "130/130 [==============================] - 110s 848ms/step - loss: 0.0871 - mae: 0.2233 - mape: 142.5903 - val_loss: 0.1039 - val_mae: 0.2535 - val_mape: 72.0796\n",
      "Epoch 16/25\n",
      "130/130 [==============================] - 108s 830ms/step - loss: 0.0860 - mae: 0.2227 - mape: 136.1610 - val_loss: 0.1002 - val_mae: 0.2408 - val_mape: 65.6188\n",
      "Epoch 17/25\n",
      "130/130 [==============================] - 108s 833ms/step - loss: 0.0846 - mae: 0.2201 - mape: 117.1618 - val_loss: 0.0989 - val_mae: 0.2401 - val_mape: 64.1854\n",
      "Epoch 18/25\n",
      "130/130 [==============================] - 106s 818ms/step - loss: 0.0847 - mae: 0.2204 - mape: 129.4525 - val_loss: 0.0958 - val_mae: 0.2373 - val_mape: 69.4113\n",
      "Epoch 19/25\n",
      "130/130 [==============================] - 109s 839ms/step - loss: 0.0806 - mae: 0.2154 - mape: 130.2070 - val_loss: 0.1063 - val_mae: 0.2550 - val_mape: 79.2361\n",
      "Epoch 20/25\n",
      "130/130 [==============================] - 107s 820ms/step - loss: 0.0803 - mae: 0.2146 - mape: 119.5093 - val_loss: 0.0976 - val_mae: 0.2377 - val_mape: 68.2804\n",
      "Epoch 21/25\n",
      "130/130 [==============================] - 103s 795ms/step - loss: 0.0803 - mae: 0.2141 - mape: 130.4720 - val_loss: 0.0955 - val_mae: 0.2347 - val_mape: 58.1389\n",
      "Epoch 22/25\n",
      "130/130 [==============================] - 103s 791ms/step - loss: 0.0793 - mae: 0.2140 - mape: 124.0595 - val_loss: 0.0997 - val_mae: 0.2463 - val_mape: 86.4199\n",
      "Epoch 23/25\n",
      "130/130 [==============================] - 106s 818ms/step - loss: 0.0772 - mae: 0.2103 - mape: 112.9765 - val_loss: 0.1035 - val_mae: 0.2383 - val_mape: 56.6222\n",
      "Epoch 24/25\n",
      "130/130 [==============================] - 112s 860ms/step - loss: 0.0766 - mae: 0.2090 - mape: 126.3658 - val_loss: 0.1061 - val_mae: 0.2523 - val_mape: 82.4023\n",
      "Epoch 25/25\n",
      "130/130 [==============================] - 108s 829ms/step - loss: 0.0741 - mae: 0.2064 - mape: 106.4169 - val_loss: 0.0948 - val_mae: 0.2323 - val_mape: 69.0916\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 40916<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_170513-lmy1jl92\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_170513-lmy1jl92\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>24</td></tr><tr><td>loss</td><td>0.0751</td></tr><tr><td>mae</td><td>0.20749</td></tr><tr><td>mape</td><td>110.43</td></tr><tr><td>val_loss</td><td>0.09478</td></tr><tr><td>val_mae</td><td>0.23232</td></tr><tr><td>val_mape</td><td>69.09159</td></tr><tr><td>_runtime</td><td>2701</td></tr><tr><td>_timestamp</td><td>1620143414</td></tr><tr><td>_step</td><td>24</td></tr><tr><td>best_val_loss</td><td>0.09478</td></tr><tr><td>best_epoch</td><td>24</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▅▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mae</td><td>█▆▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mape</td><td>▇█▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁</td></tr><tr><td>val_loss</td><td>█▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_mae</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_mape</td><td>█▆▄▃▂▃▂▃▂▃▂▂▁▂▂▂▁▂▂▂▁▃▁▃▂</td></tr><tr><td>_runtime</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>_step</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">ruby-sweep-4</strong>: <a href=\"https://wandb.ai/nbvanting/thesis/runs/lmy1jl92\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/lmy1jl92</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: 98jt0p8m with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 54\n",
      "wandb: \tcnn_layer_size_1: 231\n",
      "wandb: \tcnn_layer_size_2: 94\n",
      "wandb: \tcnn_layer_size_3: 138\n",
      "wandb: \tdataset: strib\n",
      "wandb: \tdropout: 0.4218991396086124\n",
      "wandb: \tepochs: 25\n",
      "wandb: \tgru_layer_size_1: 180\n",
      "wandb: \tgru_layer_size_2: 219\n",
      "wandb: \tgru_layer_size_3: 104\n",
      "wandb: \tlearning_rate: 0.015894954686850395\n",
      "wandb: \tlookback: 744\n",
      "wandb: \tmomentum: 0.5565848644124397\n",
      "wandb: \tnum_cnn_layers: 2\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 2\n",
      "wandb: \toptimizer: sgd\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n",
      "wandb: wandb version 0.10.29 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">jumping-sweep-5</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/f6tc66bl\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/f6tc66bl</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/98jt0p8m\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/98jt0p8m</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_175023-98jt0p8m</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "270/270 [==============================] - 162s 573ms/step - loss: 0.7941 - mae: 0.7025 - mape: 228.2991 - val_loss: 1.2314 - val_mae: 0.8676 - val_mape: 177.0470\n",
      "Epoch 2/25\n",
      "270/270 [==============================] - 146s 541ms/step - loss: 0.7344 - mae: 0.6770 - mape: 263.7257 - val_loss: 0.8589 - val_mae: 0.7396 - val_mape: 152.9547\n",
      "Epoch 3/25\n",
      "270/270 [==============================] - 139s 515ms/step - loss: 0.5091 - mae: 0.5679 - mape: 236.6278 - val_loss: 0.3760 - val_mae: 0.4592 - val_mape: 137.7453\n",
      "Epoch 4/25\n",
      "270/270 [==============================] - 140s 517ms/step - loss: 0.3101 - mae: 0.4370 - mape: 239.8327 - val_loss: 0.2130 - val_mae: 0.3644 - val_mape: 110.8189\n",
      "Epoch 5/25\n",
      "270/270 [==============================] - 132s 490ms/step - loss: 0.2228 - mae: 0.3661 - mape: 195.7371 - val_loss: 0.1984 - val_mae: 0.3436 - val_mape: 91.9576\n",
      "Epoch 6/25\n",
      "270/270 [==============================] - 132s 487ms/step - loss: 0.1798 - mae: 0.3257 - mape: 162.6277 - val_loss: 0.1344 - val_mae: 0.2811 - val_mape: 95.3826\n",
      "Epoch 7/25\n",
      "270/270 [==============================] - 132s 490ms/step - loss: 0.1499 - mae: 0.2971 - mape: 146.9700 - val_loss: 0.1334 - val_mae: 0.2926 - val_mape: 109.6698\n",
      "Epoch 8/25\n",
      "270/270 [==============================] - 133s 491ms/step - loss: 0.1379 - mae: 0.2856 - mape: 147.8949 - val_loss: 0.1106 - val_mae: 0.2548 - val_mape: 73.1089\n",
      "Epoch 9/25\n",
      "270/270 [==============================] - 135s 499ms/step - loss: 0.1277 - mae: 0.2742 - mape: 142.3744 - val_loss: 0.1195 - val_mae: 0.2624 - val_mape: 68.8353\n",
      "Epoch 10/25\n",
      "270/270 [==============================] - 135s 502ms/step - loss: 0.1217 - mae: 0.2679 - mape: 138.1089 - val_loss: 0.1148 - val_mae: 0.2561 - val_mape: 67.5084\n",
      "Epoch 11/25\n",
      "270/270 [==============================] - 137s 509ms/step - loss: 0.1135 - mae: 0.2580 - mape: 144.5173 - val_loss: 0.1141 - val_mae: 0.2509 - val_mape: 67.2314\n",
      "Epoch 12/25\n",
      "270/270 [==============================] - 140s 517ms/step - loss: 0.1101 - mae: 0.2526 - mape: 125.5769 - val_loss: 0.1276 - val_mae: 0.2703 - val_mape: 64.8595\n",
      "Epoch 13/25\n",
      "270/270 [==============================] - 140s 518ms/step - loss: 0.1047 - mae: 0.2472 - mape: 128.3576 - val_loss: 0.1009 - val_mae: 0.2466 - val_mape: 79.3353\n",
      "Epoch 14/25\n",
      "270/270 [==============================] - 142s 524ms/step - loss: 0.1023 - mae: 0.2447 - mape: 135.4445 - val_loss: 0.0963 - val_mae: 0.2422 - val_mape: 86.8668\n",
      "Epoch 15/25\n",
      "270/270 [==============================] - 139s 515ms/step - loss: 0.1022 - mae: 0.2448 - mape: 123.4493 - val_loss: 0.1381 - val_mae: 0.2816 - val_mape: 61.5788\n",
      "Epoch 16/25\n",
      "270/270 [==============================] - 137s 507ms/step - loss: 0.0976 - mae: 0.2387 - mape: 121.3548 - val_loss: 0.0974 - val_mae: 0.2420 - val_mape: 90.8120\n",
      "Epoch 17/25\n",
      "270/270 [==============================] - 143s 531ms/step - loss: 0.0930 - mae: 0.2335 - mape: 116.3160 - val_loss: 0.1034 - val_mae: 0.2394 - val_mape: 72.2581\n",
      "Epoch 18/25\n",
      "270/270 [==============================] - 138s 511ms/step - loss: 0.0961 - mae: 0.2382 - mape: 122.8041 - val_loss: 0.1103 - val_mae: 0.2503 - val_mape: 66.1883\n",
      "Epoch 19/25\n",
      "270/270 [==============================] - 138s 510ms/step - loss: 0.0896 - mae: 0.2305 - mape: 121.7181 - val_loss: 0.0922 - val_mae: 0.2292 - val_mape: 76.9885\n",
      "Epoch 20/25\n",
      "270/270 [==============================] - 138s 511ms/step - loss: 0.0875 - mae: 0.2261 - mape: 123.9263 - val_loss: 0.0898 - val_mae: 0.2315 - val_mape: 86.3350\n",
      "Epoch 21/25\n",
      "270/270 [==============================] - 139s 513ms/step - loss: 0.0873 - mae: 0.2269 - mape: 113.1313 - val_loss: 0.0944 - val_mae: 0.2371 - val_mape: 82.1067\n",
      "Epoch 22/25\n",
      "270/270 [==============================] - 135s 500ms/step - loss: 0.0851 - mae: 0.2215 - mape: 115.6739 - val_loss: 0.0964 - val_mae: 0.2358 - val_mape: 78.2541\n",
      "Epoch 23/25\n",
      "270/270 [==============================] - 136s 502ms/step - loss: 0.0848 - mae: 0.2234 - mape: 116.5026 - val_loss: 0.0982 - val_mae: 0.2342 - val_mape: 71.5488\n",
      "Epoch 24/25\n",
      "270/270 [==============================] - 134s 496ms/step - loss: 0.0820 - mae: 0.2200 - mape: 125.9473 - val_loss: 0.1116 - val_mae: 0.2457 - val_mape: 64.3677\n",
      "Epoch 25/25\n",
      "270/270 [==============================] - 134s 495ms/step - loss: 0.0815 - mae: 0.2180 - mape: 110.0534 - val_loss: 0.0912 - val_mae: 0.2293 - val_mape: 78.3835\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 31092<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_175023-98jt0p8m\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_175023-98jt0p8m\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>24</td></tr><tr><td>loss</td><td>0.08032</td></tr><tr><td>mae</td><td>0.21652</td></tr><tr><td>mape</td><td>111.5629</td></tr><tr><td>val_loss</td><td>0.09124</td></tr><tr><td>val_mae</td><td>0.22929</td></tr><tr><td>val_mape</td><td>78.38348</td></tr><tr><td>_runtime</td><td>3460</td></tr><tr><td>_timestamp</td><td>1620146883</td></tr><tr><td>_step</td><td>24</td></tr><tr><td>best_val_loss</td><td>0.0898</td></tr><tr><td>best_epoch</td><td>19</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▇▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mae</td><td>██▅▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mape</td><td>█▇█▇▆▄▃▃▃▃▃▂▂▂▂▂▁▂▂▂▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_mae</td><td>█▇▄▂▂▂▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_mape</td><td>█▇▆▄▃▃▄▂▁▁▁▁▂▃▁▃▂▁▂▃▂▂▂▁▂</td></tr><tr><td>_runtime</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>_step</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">jumping-sweep-5</strong>: <a href=\"https://wandb.ai/nbvanting/thesis/runs/98jt0p8m\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/98jt0p8m</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: 4gtz6pjy with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 161\n",
      "wandb: \tcnn_layer_size_1: 144\n",
      "wandb: \tcnn_layer_size_2: 105\n",
      "wandb: \tcnn_layer_size_3: 36\n",
      "wandb: \tdataset: strib\n",
      "wandb: \tdropout: 0.0934218555120621\n",
      "wandb: \tepochs: 25\n",
      "wandb: \tgru_layer_size_1: 36\n",
      "wandb: \tgru_layer_size_2: 62\n",
      "wandb: \tgru_layer_size_3: 119\n",
      "wandb: \tlearning_rate: 0.013573657917683571\n",
      "wandb: \tlookback: 744\n",
      "wandb: \tmomentum: 0.5840467808291915\n",
      "wandb: \tnum_cnn_layers: 2\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 2\n",
      "wandb: \toptimizer: sgd\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n",
      "wandb: wandb version 0.10.29 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">stilted-sweep-6</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/f6tc66bl\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/f6tc66bl</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/4gtz6pjy\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/4gtz6pjy</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_184808-4gtz6pjy</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "91/91 [==============================] - 63s 626ms/step - loss: 0.8575 - mae: 0.7334 - mape: 189.5678 - val_loss: 1.3099 - val_mae: 0.8937 - val_mape: 171.1269\n",
      "Epoch 2/25\n",
      "91/91 [==============================] - 54s 589ms/step - loss: 0.7531 - mae: 0.6862 - mape: 230.3961 - val_loss: 1.2467 - val_mae: 0.8740 - val_mape: 197.1547\n",
      "Epoch 3/25\n",
      "91/91 [==============================] - 54s 592ms/step - loss: 0.7437 - mae: 0.6841 - mape: 224.1536 - val_loss: 1.2275 - val_mae: 0.8758 - val_mape: 158.6468\n",
      "Epoch 4/25\n",
      "91/91 [==============================] - 54s 595ms/step - loss: 0.7104 - mae: 0.6694 - mape: 217.8322 - val_loss: 1.0797 - val_mae: 0.8255 - val_mape: 190.4794\n",
      "Epoch 5/25\n",
      "91/91 [==============================] - 54s 589ms/step - loss: 0.6512 - mae: 0.6469 - mape: 213.9663 - val_loss: 0.7743 - val_mae: 0.6972 - val_mape: 145.2502\n",
      "Epoch 6/25\n",
      "91/91 [==============================] - 54s 592ms/step - loss: 0.4761 - mae: 0.5578 - mape: 231.3445 - val_loss: 0.3865 - val_mae: 0.5070 - val_mape: 136.8623\n",
      "Epoch 7/25\n",
      "91/91 [==============================] - 54s 591ms/step - loss: 0.3423 - mae: 0.4708 - mape: 238.5172 - val_loss: 0.3123 - val_mae: 0.4244 - val_mape: 130.2014\n",
      "Epoch 8/25\n",
      "51/91 [===============>..............] - ETA: 23s - loss: 0.2949 - mae: 0.4295 - mape: 206.4835"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 41876<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_184808-4gtz6pjy\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_184808-4gtz6pjy\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>6</td></tr><tr><td>loss</td><td>0.3257</td></tr><tr><td>mae</td><td>0.45711</td></tr><tr><td>mape</td><td>241.22015</td></tr><tr><td>val_loss</td><td>0.31229</td></tr><tr><td>val_mae</td><td>0.42436</td></tr><tr><td>val_mape</td><td>130.2014</td></tr><tr><td>_runtime</td><td>392</td></tr><tr><td>_timestamp</td><td>1620147280</td></tr><tr><td>_step</td><td>6</td></tr><tr><td>best_val_loss</td><td>0.31229</td></tr><tr><td>best_epoch</td><td>6</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▅▆▇█</td></tr><tr><td>loss</td><td>█▇▇▇▅▃▁</td></tr><tr><td>mae</td><td>█▇▇▇▆▃▁</td></tr><tr><td>mape</td><td>▃▅▂▁▁█▇</td></tr><tr><td>val_loss</td><td>██▇▆▄▂▁</td></tr><tr><td>val_mae</td><td>███▇▅▂▁</td></tr><tr><td>val_mape</td><td>▅█▄▇▃▂▁</td></tr><tr><td>_runtime</td><td>▁▂▃▅▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▃▅▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▅▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">stilted-sweep-6</strong>: <a href=\"https://wandb.ai/nbvanting/thesis/runs/4gtz6pjy\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/4gtz6pjy</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: 3585hyq9 with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 175\n",
      "wandb: \tcnn_layer_size_1: 156\n",
      "wandb: \tcnn_layer_size_2: 73\n",
      "wandb: \tcnn_layer_size_3: 126\n",
      "wandb: \tdataset: strib\n",
      "wandb: \tdropout: 0.21593520780215705\n",
      "wandb: \tepochs: 25\n",
      "wandb: \tgru_layer_size_1: 37\n",
      "wandb: \tgru_layer_size_2: 218\n",
      "wandb: \tgru_layer_size_3: 149\n",
      "wandb: \tlearning_rate: 0.03630478461924794\n",
      "wandb: \tlookback: 744\n",
      "wandb: \tmomentum: 0.9679976376365662\n",
      "wandb: \tnum_cnn_layers: 2\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 2\n",
      "wandb: \toptimizer: sgd\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n",
      "wandb: wandb version 0.10.29 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">cool-sweep-7</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/f6tc66bl\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/f6tc66bl</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/3585hyq9\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/3585hyq9</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_185515-3585hyq9</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "84/84 [==============================] - 97s 1s/step - loss: 0.8339 - mae: 0.7242 - mape: 219.3210 - val_loss: 1.0735 - val_mae: 0.8216 - val_mape: 211.8753\n",
      "Epoch 2/25\n",
      "84/84 [==============================] - 88s 1s/step - loss: 0.4895 - mae: 0.5508 - mape: 258.0579 - val_loss: 0.2260 - val_mae: 0.3749 - val_mape: 160.0569\n",
      "Epoch 3/25\n",
      "84/84 [==============================] - 87s 1s/step - loss: 0.1785 - mae: 0.3285 - mape: 186.8191 - val_loss: 0.2136 - val_mae: 0.3657 - val_mape: 77.5764\n",
      "Epoch 4/25\n",
      "84/84 [==============================] - 87s 1s/step - loss: 0.1383 - mae: 0.2865 - mape: 175.3832 - val_loss: 0.1331 - val_mae: 0.2834 - val_mape: 108.8501\n",
      "Epoch 5/25\n",
      "84/84 [==============================] - 88s 1s/step - loss: 0.1280 - mae: 0.2742 - mape: 159.6769 - val_loss: 0.1295 - val_mae: 0.2792 - val_mape: 87.5068\n",
      "Epoch 6/25\n",
      "84/84 [==============================] - 88s 1s/step - loss: 0.1031 - mae: 0.2463 - mape: 127.3788 - val_loss: 0.1766 - val_mae: 0.3170 - val_mape: 72.4446\n",
      "Epoch 7/25\n",
      "84/84 [==============================] - 88s 1s/step - loss: 0.1015 - mae: 0.2397 - mape: 132.7146 - val_loss: 0.1158 - val_mae: 0.2643 - val_mape: 77.1814\n",
      "Epoch 8/25\n",
      "84/84 [==============================] - 88s 1s/step - loss: 0.1022 - mae: 0.2453 - mape: 136.3599 - val_loss: 0.1187 - val_mae: 0.2701 - val_mape: 96.3841\n",
      "Epoch 9/25\n",
      "84/84 [==============================] - 88s 1s/step - loss: 0.0989 - mae: 0.2415 - mape: 156.1532 - val_loss: 0.1329 - val_mae: 0.2787 - val_mape: 66.6989\n",
      "Epoch 10/25\n",
      "84/84 [==============================] - 88s 1s/step - loss: 0.1018 - mae: 0.2409 - mape: 147.1833 - val_loss: 0.0967 - val_mae: 0.2423 - val_mape: 79.3324\n",
      "Epoch 11/25\n",
      "84/84 [==============================] - 88s 1s/step - loss: 0.0878 - mae: 0.2270 - mape: 152.8890 - val_loss: 0.0968 - val_mae: 0.2342 - val_mape: 77.3369\n",
      "Epoch 12/25\n",
      "84/84 [==============================] - 89s 1s/step - loss: 0.0861 - mae: 0.2236 - mape: 130.6811 - val_loss: 0.0953 - val_mae: 0.2310 - val_mape: 65.8419\n",
      "Epoch 13/25\n",
      "84/84 [==============================] - 88s 1s/step - loss: 0.0822 - mae: 0.2207 - mape: 139.1756 - val_loss: 0.1041 - val_mae: 0.2484 - val_mape: 75.6811\n",
      "Epoch 14/25\n",
      "84/84 [==============================] - 88s 1s/step - loss: 0.0803 - mae: 0.2153 - mape: 142.4380 - val_loss: 0.1035 - val_mae: 0.2415 - val_mape: 64.7350\n",
      "Epoch 15/25\n",
      "84/84 [==============================] - 89s 1s/step - loss: 0.0776 - mae: 0.2125 - mape: 117.9167 - val_loss: 0.1150 - val_mae: 0.2635 - val_mape: 111.4710\n",
      "Epoch 16/25\n",
      "84/84 [==============================] - 89s 1s/step - loss: 0.0790 - mae: 0.2150 - mape: 133.6814 - val_loss: 0.0964 - val_mae: 0.2336 - val_mape: 67.5702\n",
      "Epoch 17/25\n",
      "84/84 [==============================] - 89s 1s/step - loss: 0.0793 - mae: 0.2159 - mape: 116.6926 - val_loss: 0.1595 - val_mae: 0.2917 - val_mape: 65.2207\n",
      "Epoch 18/25\n",
      "84/84 [==============================] - 88s 1s/step - loss: 0.0821 - mae: 0.2219 - mape: 133.4074 - val_loss: 0.1077 - val_mae: 0.2533 - val_mape: 87.1749\n",
      "Epoch 19/25\n",
      "84/84 [==============================] - 89s 1s/step - loss: 0.0694 - mae: 0.2007 - mape: 121.7716 - val_loss: 0.0990 - val_mae: 0.2364 - val_mape: 67.4037\n",
      "Epoch 20/25\n",
      "84/84 [==============================] - 89s 1s/step - loss: 0.0685 - mae: 0.1991 - mape: 109.6187 - val_loss: 0.1069 - val_mae: 0.2469 - val_mape: 69.2919\n",
      "Epoch 21/25\n",
      "84/84 [==============================] - 89s 1s/step - loss: 0.0675 - mae: 0.1978 - mape: 103.9562 - val_loss: 0.1002 - val_mae: 0.2357 - val_mape: 78.2041\n",
      "Epoch 22/25\n",
      "84/84 [==============================] - 90s 1s/step - loss: 0.0692 - mae: 0.2015 - mape: 113.6703 - val_loss: 0.1031 - val_mae: 0.2398 - val_mape: 79.8391\n",
      "Epoch 23/25\n",
      "84/84 [==============================] - 89s 1s/step - loss: 0.0649 - mae: 0.1923 - mape: 109.2468 - val_loss: 0.1022 - val_mae: 0.2436 - val_mape: 78.5454\n",
      "Epoch 24/25\n",
      "84/84 [==============================] - 89s 1s/step - loss: 0.0646 - mae: 0.1947 - mape: 105.1989 - val_loss: 0.1095 - val_mae: 0.2484 - val_mape: 80.8811\n",
      "Epoch 25/25\n",
      "84/84 [==============================] - 89s 1s/step - loss: 0.0645 - mae: 0.1946 - mape: 107.5494 - val_loss: 0.1186 - val_mae: 0.2557 - val_mape: 70.8045\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1548<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_185515-3585hyq9\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_185515-3585hyq9\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>24</td></tr><tr><td>loss</td><td>0.06479</td></tr><tr><td>mae</td><td>0.19478</td></tr><tr><td>mape</td><td>99.9927</td></tr><tr><td>val_loss</td><td>0.11861</td></tr><tr><td>val_mae</td><td>0.25566</td></tr><tr><td>val_mape</td><td>70.80453</td></tr><tr><td>_runtime</td><td>2228</td></tr><tr><td>_timestamp</td><td>1620149543</td></tr><tr><td>_step</td><td>24</td></tr><tr><td>best_val_loss</td><td>0.09535</td></tr><tr><td>best_epoch</td><td>11</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mae</td><td>█▅▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mape</td><td>▇█▅▄▃▂▂▂▃▃▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁</td></tr><tr><td>val_loss</td><td>█▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_mae</td><td>█▃▃▂▂▂▁▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_mape</td><td>█▆▂▃▂▁▂▃▁▂▂▁▂▁▃▁▁▂▁▁▂▂▂▂▁</td></tr><tr><td>_runtime</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>_step</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">cool-sweep-7</strong>: <a href=\"https://wandb.ai/nbvanting/thesis/runs/3585hyq9\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/3585hyq9</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: 96cf1ah6 with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 32\n",
      "wandb: \tcnn_layer_size_1: 97\n",
      "wandb: \tcnn_layer_size_2: 157\n",
      "wandb: \tcnn_layer_size_3: 117\n",
      "wandb: \tdataset: strib\n",
      "wandb: \tdropout: 0.231495417114896\n",
      "wandb: \tepochs: 25\n",
      "wandb: \tgru_layer_size_1: 163\n",
      "wandb: \tgru_layer_size_2: 152\n",
      "wandb: \tgru_layer_size_3: 99\n",
      "wandb: \tlearning_rate: 0.0331747167365047\n",
      "wandb: \tlookback: 744\n",
      "wandb: \tmomentum: 0.6350569265959602\n",
      "wandb: \tnum_cnn_layers: 2\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 2\n",
      "wandb: \toptimizer: sgd\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n",
      "wandb: wandb version 0.10.29 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">flowing-sweep-8</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/f6tc66bl\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/f6tc66bl</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/96cf1ah6\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/96cf1ah6</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_193227-96cf1ah6</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "455/455 [==============================] - 136s 284ms/step - loss: 0.7592 - mae: 0.6893 - mape: 220.7708 - val_loss: 0.2942 - val_mae: 0.3997 - val_mape: 135.4178\n",
      "Epoch 2/25\n",
      "455/455 [==============================] - 121s 266ms/step - loss: 0.2172 - mae: 0.3613 - mape: 205.6719 - val_loss: 0.2312 - val_mae: 0.3613 - val_mape: 74.3889\n",
      "Epoch 3/25\n",
      "455/455 [==============================] - 122s 268ms/step - loss: 0.1518 - mae: 0.2986 - mape: 156.5124 - val_loss: 0.1602 - val_mae: 0.3089 - val_mape: 67.7176\n",
      "Epoch 4/25\n",
      "455/455 [==============================] - 122s 268ms/step - loss: 0.1304 - mae: 0.2747 - mape: 151.1156 - val_loss: 0.1355 - val_mae: 0.2805 - val_mape: 61.7988\n",
      "Epoch 5/25\n",
      "455/455 [==============================] - 122s 268ms/step - loss: 0.1153 - mae: 0.2572 - mape: 134.8537 - val_loss: 0.1112 - val_mae: 0.2593 - val_mape: 76.3854\n",
      "Epoch 6/25\n",
      "455/455 [==============================] - 120s 265ms/step - loss: 0.1061 - mae: 0.2476 - mape: 132.5423 - val_loss: 0.1034 - val_mae: 0.2464 - val_mape: 65.7728\n",
      "Epoch 7/25\n",
      "455/455 [==============================] - 122s 268ms/step - loss: 0.1009 - mae: 0.2401 - mape: 134.5394 - val_loss: 0.1023 - val_mae: 0.2452 - val_mape: 67.7072\n",
      "Epoch 8/25\n",
      "455/455 [==============================] - 121s 266ms/step - loss: 0.0976 - mae: 0.2358 - mape: 121.5662 - val_loss: 0.0947 - val_mae: 0.2330 - val_mape: 62.1632\n",
      "Epoch 9/25\n",
      "455/455 [==============================] - 124s 272ms/step - loss: 0.0932 - mae: 0.2317 - mape: 116.7584 - val_loss: 0.1048 - val_mae: 0.2456 - val_mape: 76.8980\n",
      "Epoch 10/25\n",
      "455/455 [==============================] - 122s 268ms/step - loss: 0.0892 - mae: 0.2259 - mape: 114.1165 - val_loss: 0.1032 - val_mae: 0.2450 - val_mape: 82.6776\n",
      "Epoch 11/25\n",
      "455/455 [==============================] - 124s 272ms/step - loss: 0.0878 - mae: 0.2248 - mape: 116.4938 - val_loss: 0.1364 - val_mae: 0.2667 - val_mape: 55.9884\n",
      "Epoch 12/25\n",
      "455/455 [==============================] - 126s 277ms/step - loss: 0.0852 - mae: 0.2200 - mape: 111.5303 - val_loss: 0.0996 - val_mae: 0.2379 - val_mape: 73.6158\n",
      "Epoch 13/25\n",
      "455/455 [==============================] - 123s 270ms/step - loss: 0.0824 - mae: 0.2177 - mape: 119.5715 - val_loss: 0.1049 - val_mae: 0.2400 - val_mape: 67.9576\n",
      "Epoch 14/25\n",
      "455/455 [==============================] - 123s 270ms/step - loss: 0.0785 - mae: 0.2128 - mape: 105.4954 - val_loss: 0.0868 - val_mae: 0.2220 - val_mape: 70.7117\n",
      "Epoch 15/25\n",
      "455/455 [==============================] - 125s 275ms/step - loss: 0.0755 - mae: 0.2079 - mape: 106.9842 - val_loss: 0.0911 - val_mae: 0.2279 - val_mape: 75.3700\n",
      "Epoch 16/25\n",
      "455/455 [==============================] - 125s 274ms/step - loss: 0.0752 - mae: 0.2075 - mape: 104.8259 - val_loss: 0.1001 - val_mae: 0.2363 - val_mape: 67.7345\n",
      "Epoch 17/25\n",
      "455/455 [==============================] - 126s 276ms/step - loss: 0.0723 - mae: 0.2031 - mape: 105.3172 - val_loss: 0.0934 - val_mae: 0.2296 - val_mape: 72.3434\n",
      "Epoch 18/25\n",
      "455/455 [==============================] - 126s 276ms/step - loss: 0.0725 - mae: 0.2047 - mape: 105.3957 - val_loss: 0.0901 - val_mae: 0.2288 - val_mape: 78.1667\n",
      "Epoch 19/25\n",
      "455/455 [==============================] - 123s 269ms/step - loss: 0.0699 - mae: 0.2007 - mape: 107.8732 - val_loss: 0.1003 - val_mae: 0.2395 - val_mape: 81.1114\n",
      "Epoch 20/25\n",
      "455/455 [==============================] - 131s 289ms/step - loss: 0.0672 - mae: 0.1964 - mape: 104.1468 - val_loss: 0.0919 - val_mae: 0.2279 - val_mape: 72.0328\n",
      "Epoch 21/25\n",
      "455/455 [==============================] - 126s 276ms/step - loss: 0.0670 - mae: 0.1961 - mape: 102.4435 - val_loss: 0.0889 - val_mae: 0.2242 - val_mape: 80.3872\n",
      "Epoch 22/25\n",
      "455/455 [==============================] - 125s 274ms/step - loss: 0.0665 - mae: 0.1951 - mape: 100.4151 - val_loss: 0.0928 - val_mae: 0.2290 - val_mape: 73.2159\n",
      "Epoch 23/25\n",
      "455/455 [==============================] - 125s 274ms/step - loss: 0.0655 - mae: 0.1947 - mape: 104.1739 - val_loss: 0.1144 - val_mae: 0.2469 - val_mape: 69.2724\n",
      "Epoch 24/25\n",
      "455/455 [==============================] - 122s 269ms/step - loss: 0.0656 - mae: 0.1941 - mape: 101.4112 - val_loss: 0.1024 - val_mae: 0.2384 - val_mape: 67.0274\n",
      "Epoch 25/25\n",
      "455/455 [==============================] - 122s 268ms/step - loss: 0.0640 - mae: 0.1928 - mape: 100.8077 - val_loss: 0.0908 - val_mae: 0.2282 - val_mape: 82.1019\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 41424<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_193227-96cf1ah6\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_193227-96cf1ah6\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>24</td></tr><tr><td>loss</td><td>0.06233</td></tr><tr><td>mae</td><td>0.19052</td></tr><tr><td>mape</td><td>107.70701</td></tr><tr><td>val_loss</td><td>0.09082</td></tr><tr><td>val_mae</td><td>0.22823</td></tr><tr><td>val_mape</td><td>82.10187</td></tr><tr><td>_runtime</td><td>3108</td></tr><tr><td>_timestamp</td><td>1620152655</td></tr><tr><td>_step</td><td>24</td></tr><tr><td>best_val_loss</td><td>0.0868</td></tr><tr><td>best_epoch</td><td>13</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mae</td><td>█▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mape</td><td>█▆▄▄▃▃▃▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▂▂▁</td></tr><tr><td>val_loss</td><td>█▆▃▃▂▂▂▁▂▂▃▁▂▁▁▁▁▁▁▁▁▁▂▂▁</td></tr><tr><td>val_mae</td><td>█▆▄▃▂▂▂▁▂▂▃▂▂▁▁▂▁▁▂▁▁▁▂▂▁</td></tr><tr><td>val_mape</td><td>█▃▂▂▃▂▂▂▃▃▁▃▂▂▃▂▂▃▃▂▃▃▂▂▃</td></tr><tr><td>_runtime</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>_step</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">flowing-sweep-8</strong>: <a href=\"https://wandb.ai/nbvanting/thesis/runs/96cf1ah6\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/96cf1ah6</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: nq3a5w3o with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 162\n",
      "wandb: \tcnn_layer_size_1: 72\n",
      "wandb: \tcnn_layer_size_2: 121\n",
      "wandb: \tcnn_layer_size_3: 38\n",
      "wandb: \tdataset: kolding\n",
      "wandb: \tdropout: 0.13842264737720672\n",
      "wandb: \tepochs: 25\n",
      "wandb: \tgru_layer_size_1: 136\n",
      "wandb: \tgru_layer_size_2: 60\n",
      "wandb: \tgru_layer_size_3: 215\n",
      "wandb: \tlearning_rate: 0.01736808635970167\n",
      "wandb: \tlookback: 744\n",
      "wandb: \tmomentum: 0.5390575653408554\n",
      "wandb: \tnum_cnn_layers: 2\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 2\n",
      "wandb: \toptimizer: sgd\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n",
      "wandb: wandb version 0.10.29 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">rosy-sweep-9</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/f6tc66bl\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/f6tc66bl</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/nq3a5w3o\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/nq3a5w3o</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_202420-nq3a5w3o</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "90/90 [==============================] - 95s 987ms/step - loss: 0.7893 - mae: 0.7003 - mape: 374.4505 - val_loss: 1.3629 - val_mae: 0.9256 - val_mape: 254.3705\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 83s 919ms/step - loss: 0.7029 - mae: 0.6644 - mape: 394.9838 - val_loss: 1.3619 - val_mae: 0.9435 - val_mape: 277.3477\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 83s 917ms/step - loss: 0.6976 - mae: 0.6621 - mape: 422.5771 - val_loss: 1.3951 - val_mae: 0.9869 - val_mape: 324.4165\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 82s 910ms/step - loss: 0.6964 - mae: 0.6657 - mape: 414.2880 - val_loss: 1.3775 - val_mae: 0.9847 - val_mape: 324.4638\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 81s 896ms/step - loss: 0.6903 - mae: 0.6652 - mape: 379.1002 - val_loss: 1.2996 - val_mae: 0.9380 - val_mape: 272.7420\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 82s 910ms/step - loss: 0.6833 - mae: 0.6616 - mape: 433.5902 - val_loss: 1.3031 - val_mae: 0.9582 - val_mape: 306.9843\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 83s 925ms/step - loss: 0.6645 - mae: 0.6538 - mape: 453.5145 - val_loss: 1.1772 - val_mae: 0.8935 - val_mape: 254.2342\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 82s 913ms/step - loss: 0.6235 - mae: 0.6357 - mape: 541.0086 - val_loss: 0.9438 - val_mae: 0.8236 - val_mape: 283.9708\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 84s 935ms/step - loss: 0.5112 - mae: 0.5739 - mape: 488.7926 - val_loss: 0.6038 - val_mae: 0.6141 - val_mape: 190.2713\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 81s 902ms/step - loss: 0.4301 - mae: 0.5193 - mape: 576.4452 - val_loss: 0.5006 - val_mae: 0.5650 - val_mape: 213.9447\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 80s 892ms/step - loss: 0.3876 - mae: 0.4885 - mape: 741.9791 - val_loss: 0.4611 - val_mae: 0.5531 - val_mape: 238.3394\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 81s 901ms/step - loss: 0.3424 - mae: 0.4575 - mape: 764.8694 - val_loss: 0.3560 - val_mae: 0.4752 - val_mape: 186.4832\n",
      "Epoch 13/25\n",
      " 9/90 [==>...........................] - ETA: 1:10 - loss: 0.2984 - mae: 0.4260 - mape: 201.2143"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 38212<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_202420-nq3a5w3o\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_202420-nq3a5w3o\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>11</td></tr><tr><td>loss</td><td>0.32867</td></tr><tr><td>mae</td><td>0.44633</td></tr><tr><td>mape</td><td>787.61371</td></tr><tr><td>val_loss</td><td>0.35603</td></tr><tr><td>val_mae</td><td>0.47523</td></tr><tr><td>val_mape</td><td>186.48318</td></tr><tr><td>_runtime</td><td>1003</td></tr><tr><td>_timestamp</td><td>1620153663</td></tr><tr><td>_step</td><td>11</td></tr><tr><td>best_val_loss</td><td>0.35603</td></tr><tr><td>best_epoch</td><td>11</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>loss</td><td>█▇▇▇▇▇▆▆▄▂▂▁</td></tr><tr><td>mae</td><td>███▇▇▇▇▆▄▃▂▁</td></tr><tr><td>mape</td><td>▂▂▂▁▁▂▂▃▆▆▇█</td></tr><tr><td>val_loss</td><td>████▇▇▇▅▃▂▂▁</td></tr><tr><td>val_mae</td><td>▇▇██▇█▇▆▃▂▂▁</td></tr><tr><td>val_mape</td><td>▄▆██▅▇▄▆▁▂▄▁</td></tr><tr><td>_runtime</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>_timestamp</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>_step</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">rosy-sweep-9</strong>: <a href=\"https://wandb.ai/nbvanting/thesis/runs/nq3a5w3o\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/nq3a5w3o</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Sweep Agent: Waiting for job.\n",
      "wandb: Job received.\n",
      "wandb: Agent Starting Run: 7bxsbwo7 with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 147\n",
      "wandb: \tcnn_layer_size_1: 32\n",
      "wandb: \tcnn_layer_size_2: 78\n",
      "wandb: \tcnn_layer_size_3: 38\n",
      "wandb: \tdataset: kolding\n",
      "wandb: \tdropout: 0.08791089961754245\n",
      "wandb: \tepochs: 25\n",
      "wandb: \tgru_layer_size_1: 133\n",
      "wandb: \tgru_layer_size_2: 48\n",
      "wandb: \tgru_layer_size_3: 108\n",
      "wandb: \tlearning_rate: 0.014745383918515442\n",
      "wandb: \tlookback: 744\n",
      "wandb: \tmomentum: 0.7736504000202488\n",
      "wandb: \tnum_cnn_layers: 2\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 2\n",
      "wandb: \toptimizer: sgd\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n",
      "wandb: wandb version 0.10.29 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">fresh-sweep-10</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/f6tc66bl\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/f6tc66bl</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/7bxsbwo7\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/7bxsbwo7</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_204126-7bxsbwo7</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "100/100 [==============================] - 70s 634ms/step - loss: 0.7952 - mae: 0.6919 - mape: 303.0058 - val_loss: 1.3751 - val_mae: 0.9118 - val_mape: 243.5748\n",
      "Epoch 2/25\n",
      "100/100 [==============================] - 59s 587ms/step - loss: 0.7122 - mae: 0.6647 - mape: 457.5337 - val_loss: 1.3531 - val_mae: 0.9172 - val_mape: 254.8871\n",
      "Epoch 3/25\n",
      "100/100 [==============================] - 57s 571ms/step - loss: 0.6855 - mae: 0.6538 - mape: 390.8345 - val_loss: 1.4204 - val_mae: 0.8734 - val_mape: 136.2679\n",
      "Epoch 4/25\n",
      "100/100 [==============================] - 56s 557ms/step - loss: 0.6786 - mae: 0.6521 - mape: 391.6583 - val_loss: 1.2122 - val_mae: 0.8811 - val_mape: 219.8545\n",
      "Epoch 5/25\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 0.6193 - mae: 0.6277 - mape: 417.9128 - val_loss: 0.7725 - val_mae: 0.6849 - val_mape: 172.0443\n",
      "Epoch 6/25\n",
      "100/100 [==============================] - 54s 543ms/step - loss: 0.4524 - mae: 0.5318 - mape: 684.5988 - val_loss: 0.5005 - val_mae: 0.5350 - val_mape: 163.0738\n",
      "Epoch 7/25\n",
      "100/100 [==============================] - 54s 543ms/step - loss: 0.3413 - mae: 0.4569 - mape: 790.0365 - val_loss: 1.0027 - val_mae: 0.8325 - val_mape: 278.0999\n",
      "Epoch 8/25\n",
      " 42/100 [===========>..................] - ETA: 30s - loss: 0.3754 - mae: 0.4836 - mape: 726.9548"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 38332<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_204126-7bxsbwo7\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_204126-7bxsbwo7\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>6</td></tr><tr><td>loss</td><td>0.32084</td></tr><tr><td>mae</td><td>0.44195</td></tr><tr><td>mape</td><td>713.81537</td></tr><tr><td>val_loss</td><td>1.00268</td></tr><tr><td>val_mae</td><td>0.83251</td></tr><tr><td>val_mape</td><td>278.09988</td></tr><tr><td>_runtime</td><td>411</td></tr><tr><td>_timestamp</td><td>1620154097</td></tr><tr><td>_step</td><td>6</td></tr><tr><td>best_val_loss</td><td>0.50048</td></tr><tr><td>best_epoch</td><td>5</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▅▆▇█</td></tr><tr><td>loss</td><td>█▇▇▇▅▃▁</td></tr><tr><td>mae</td><td>███▇▆▃▁</td></tr><tr><td>mape</td><td>▁▂▁▂▂▄█</td></tr><tr><td>val_loss</td><td>█▇█▆▃▁▅</td></tr><tr><td>val_mae</td><td>██▇▇▄▁▆</td></tr><tr><td>val_mape</td><td>▆▇▁▅▃▂█</td></tr><tr><td>_runtime</td><td>▁▂▃▅▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▃▅▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▅▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">fresh-sweep-10</strong>: <a href=\"https://wandb.ai/nbvanting/thesis/runs/7bxsbwo7\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/7bxsbwo7</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=run_tuner, count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-crossing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
