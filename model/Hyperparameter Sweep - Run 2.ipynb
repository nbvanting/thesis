{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "supported-phoenix",
   "metadata": {},
   "source": [
    "For this second sweep the following changes have been made:\n",
    " - Parameters have been reduced to the range around the optimal parameter found during sweep 1.\n",
    " - A new parameter called dataset is added that randomly chooses between strib and kolding datasets.\n",
    " - Some parameters have been defaulted such as optimizer and lookback.\n",
    "     - This is done to improve the other parameters even more, as these parameters showed to be the best choice in run 1.\n",
    " - For the sake of experiment, I will add an option for zero additional layers to the number of layers parameter.\n",
    " - Seeds have been added.\n",
    " - Number of Epochs have been reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "worth-monroe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "from utils import processing\n",
    "from utils import utils\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import LSTM, GRU, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, TimeDistributed, \\\n",
    "    BatchNormalization\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unnecessary-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
    "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
    "tf.random.set_seed(hash(\"by removing stochasticity\") % 2**32 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mineral-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams[\"figure.figsize\"] = (18,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "gothic-affiliation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: nbvanting (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "current-judgment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(config):\n",
    "    # Load csv & parse dates to datetime index\n",
    "    data = pd.read_csv(f'../data/processed/{config.dataset}_features.csv', index_col='Datetime', parse_dates=['Datetime'])\n",
    "    # Select Features\n",
    "    data = data[['Value', 'sunshine_mins', 'airtemp_c', 'daylength_hrs', 'wkdy_sin', 'wkdy_cos', 'wknd', 'mnth_sin', 'mnth_cos']]\n",
    "    \n",
    "    train, val, test = processing.create_datasets(data, split=split, \n",
    "                                                  steps=steps, lookback=config.lookback, \n",
    "                                                  horizon=horizon, batch_size=config.batch_size, \n",
    "                                                  scaler='standard')    \n",
    "    return train, val, test\n",
    "    \n",
    "    \n",
    "def build_model(config):\n",
    "        \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Input(shape=(config.lookback, config.num_features)))\n",
    "\n",
    "    # CNN Block\n",
    "    model.add(Conv1D(filters=config.cnn_layer_size_1, kernel_size=3, activation=config.activation_cnn))\n",
    "    model.add(MaxPooling1D(pool_size=2))    \n",
    "    for i in range(config.num_cnn_layers):\n",
    "        model.add(Conv1D(filters=config.cnn_layer_size_2, kernel_size=3, activation=config.activation_cnn))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    # RNN Block\n",
    "    for i in range(config.num_gru_layers):\n",
    "        model.add(GRU(config.gru_layer_size_1, return_sequences=True, activation=config.activation_gru))\n",
    "        model.add(Dropout(config.dropout))\n",
    "    \n",
    "    model.add(GRU(config.gru_layer_size_2, return_sequences=False, activation=config.activation_gru))\n",
    "    model.add(Dropout(config.dropout))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    opt = config.optimizer\n",
    "    if opt == 'sgd':\n",
    "        opt = SGD(learning_rate=config.learning_rate, momentum=config.momentum)\n",
    "    elif opt == 'rmsprop':\n",
    "        opt = RMSprop(learning_rate=config.learning_rate)\n",
    "    else:\n",
    "        opt = Adam(learning_rate=config.learning_rate)\n",
    "        \n",
    "    model.compile(optimizer=opt, loss='mse', metrics=['mae', 'mape'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def log_defaults():\n",
    "    # Default values from the first sweep\n",
    "    # The following values resulted in the strongest model\n",
    "    wandb_config = {\n",
    "        'num_features' : 9,\n",
    "        'epochs' : 50,\n",
    "        'batch_size' : 227,\n",
    "        'num_cnn_layers' : 2, # Number of additional layers\n",
    "        'num_gru_layers' : 2, # Number of additional layers\n",
    "        'optimizer' : 'sgd',\n",
    "        'dropout' : 0.015,\n",
    "        'lookback' : 718,\n",
    "        'activation_cnn' : 'relu',\n",
    "        'activation_gru' : 'tanh',\n",
    "        'cnn_layer_size_1' : 70,\n",
    "        'cnn_layer_size_2' : 106,\n",
    "        'gru_layer_size_1' : 51,\n",
    "        'gru_layer_size_2' : 194,\n",
    "        'learning_rate' : 0.024,\n",
    "        'momentum' : 0.9,\n",
    "        'dataset' : 'kolding'\n",
    "    }\n",
    "    return wandb_config\n",
    "    \n",
    "\n",
    "def run_tuner():\n",
    "    \n",
    "    wandb.init(config=log_defaults(), group='cnnrnn-sweep-2', project='thesis')\n",
    "    \n",
    "    model = build_model(config=wandb.config)\n",
    "    \n",
    "    train, val, _ = load_data(config=wandb.config)\n",
    "\n",
    "    callbacks = [WandbCallback()]\n",
    "    \n",
    "    model.fit(\n",
    "        train,\n",
    "        epochs=wandb.config.epochs,\n",
    "        validation_data=val,\n",
    "        callbacks=callbacks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "strange-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweep Config\n",
    "sweep_config = {\n",
    "    'method': 'random',\n",
    "    'metric': {\n",
    "        'name': 'val_loss',\n",
    "        'goal': 'minimize'\n",
    "    },\n",
    "    'early_terminate': {\n",
    "        'type': 'hyperband',\n",
    "        'min_iter': 5\n",
    "    },\n",
    "    'parameters': {\n",
    "        'num_features' : {\n",
    "            'value' : 9\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'distribution': 'q_log_uniform',\n",
    "            'q': 1,\n",
    "            'min': math.log(200),\n",
    "            'max': math.log(256)\n",
    "        },\n",
    "        'lookback': {\n",
    "            'value': 24*31\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'value': 'sgd'\n",
    "        },\n",
    "        'dropout': {\n",
    "            'distribution': 'uniform',\n",
    "            'min': 0.01,\n",
    "            'max': 0.5\n",
    "        },\n",
    "        'epochs': {\n",
    "            'value': 10\n",
    "        },\n",
    "        'activation_gru': {\n",
    "            'value': 'tanh'\n",
    "        },\n",
    "        'activation_cnn': {\n",
    "            'value': 'relu'\n",
    "        },\n",
    "        'cnn_layer_size_1': {\n",
    "            'distribution': 'q_log_uniform',\n",
    "            'q': 1,\n",
    "            'min': math.log(62),\n",
    "            'max': math.log(78)\n",
    "        },\n",
    "        'cnn_layer_size_2': {\n",
    "            'distribution': 'q_log_uniform',\n",
    "            'q': 1,\n",
    "            'min': math.log(100),\n",
    "            'max': math.log(112)\n",
    "        },\n",
    "        'gru_layer_size_1': {\n",
    "            'distribution': 'q_log_uniform',\n",
    "            'q': 1,\n",
    "            'min': math.log(32),\n",
    "            'max': math.log(70)\n",
    "        },\n",
    "        'gru_layer_size_2': {\n",
    "            'distribution': 'q_log_uniform',\n",
    "            'q': 1,\n",
    "            'min': math.log(188),\n",
    "            'max': math.log(200)\n",
    "        },\n",
    "        'learning_rate': {\n",
    "            'distribution': 'uniform',\n",
    "            'min': 0.001,\n",
    "            'max': 0.04\n",
    "        },\n",
    "        'momentum': {\n",
    "            'distribution': 'uniform',\n",
    "            'min': 0.2,\n",
    "            'max': 0.99\n",
    "        },\n",
    "        'num_cnn_layers': {\n",
    "            'values': [0, 1, 2]\n",
    "        },\n",
    "        'num_gru_layers': {\n",
    "            'values': [0, 1, 2]\n",
    "        },\n",
    "        'dataset': {\n",
    "            'values': ['kolding', 'strib']\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "animated-reminder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional Parameters\n",
    "split = 0.80 # split percentage for training data\n",
    "steps = 1 # timesteps: 1 hour\n",
    "horizon = 1 # the target hour in the future we want to predict 1 hour ahead\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "recovered-wales",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 359c75sk\n",
      "Sweep URL: https://wandb.ai/nbvanting/thesis/sweeps/359c75sk\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project='thesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-birthday",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: 8x8vt07z with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 250\n",
      "wandb: \tcnn_layer_size_1: 72\n",
      "wandb: \tcnn_layer_size_2: 104\n",
      "wandb: \tdataset: kolding\n",
      "wandb: \tdropout: 0.018265304838042416\n",
      "wandb: \tepochs: 10\n",
      "wandb: \tgru_layer_size_1: 62\n",
      "wandb: \tgru_layer_size_2: 191\n",
      "wandb: \tlearning_rate: 0.0035326769839099147\n",
      "wandb: \tlookback: 744\n",
      "wandb: \tmomentum: 0.8522771463899708\n",
      "wandb: \tnum_cnn_layers: 2\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 2\n",
      "wandb: \toptimizer: sgd\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n",
      "c:\\users\\nicol\\envs\\thesis\\lib\\site-packages\\IPython\\html.py:12: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  warn(\"The `IPython.html` package has been deprecated since IPython 4.0. \"\n",
      "wandb: wandb version 0.10.29 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">wise-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/359c75sk\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/359c75sk</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/8x8vt07z\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/8x8vt07z</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_132523-8x8vt07z</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "59/59 [==============================] - 68s 1s/step - loss: 0.8513 - mae: 0.7190 - mape: 385.3535 - val_loss: 1.3881 - val_mae: 0.9590 - val_mape: 301.0055\n",
      "Epoch 2/10\n",
      "59/59 [==============================] - 64s 1s/step - loss: 0.7111 - mae: 0.6666 - mape: 440.1818 - val_loss: 1.3761 - val_mae: 0.9502 - val_mape: 290.9503\n",
      "Epoch 3/10\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.7028 - mae: 0.6642 - mape: 469.8456 - val_loss: 1.3765 - val_mae: 0.9568 - val_mape: 297.7268\n",
      "Epoch 4/10\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.6992 - mae: 0.6607 - mape: 369.9667 - val_loss: 1.3641 - val_mae: 0.9497 - val_mape: 290.0808\n",
      "Epoch 5/10\n",
      "59/59 [==============================] - 68s 1s/step - loss: 0.6856 - mae: 0.6537 - mape: 678.8828 - val_loss: 1.3591 - val_mae: 0.9541 - val_mape: 295.1304\n",
      "Epoch 6/10\n",
      "59/59 [==============================] - 67s 1s/step - loss: 0.6844 - mae: 0.6563 - mape: 389.4756 - val_loss: 1.3567 - val_mae: 0.9623 - val_mape: 305.6464\n",
      "Epoch 7/10\n",
      "59/59 [==============================] - 72s 1s/step - loss: 0.6867 - mae: 0.6580 - mape: 490.6803 - val_loss: 1.3128 - val_mae: 0.9280 - val_mape: 267.4825\n",
      "Epoch 8/10\n",
      "59/59 [==============================] - 70s 1s/step - loss: 0.6742 - mae: 0.6513 - mape: 510.6674 - val_loss: 1.2849 - val_mae: 0.9050 - val_mape: 239.0940\n",
      "Epoch 9/10\n",
      "59/59 [==============================] - 68s 1s/step - loss: 0.6593 - mae: 0.6480 - mape: 434.9284 - val_loss: 1.2988 - val_mae: 0.9505 - val_mape: 302.5717\n",
      "Epoch 10/10\n",
      "59/59 [==============================] - 69s 1s/step - loss: 0.6559 - mae: 0.6469 - mape: 779.9325 - val_loss: 1.2326 - val_mae: 0.9006 - val_mape: 249.4715\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 39460<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_132523-8x8vt07z\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_132523-8x8vt07z\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.65274</td></tr><tr><td>mae</td><td>0.64521</td></tr><tr><td>mape</td><td>521.67957</td></tr><tr><td>val_loss</td><td>1.23259</td></tr><tr><td>val_mae</td><td>0.90062</td></tr><tr><td>val_mape</td><td>249.47147</td></tr><tr><td>_runtime</td><td>698</td></tr><tr><td>_timestamp</td><td>1620128221</td></tr><tr><td>_step</td><td>9</td></tr><tr><td>best_val_loss</td><td>1.23259</td></tr><tr><td>best_epoch</td><td>9</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▄▄▃▃▃▂▂▁▁</td></tr><tr><td>mae</td><td>█▄▃▃▃▂▂▂▁▁</td></tr><tr><td>mape</td><td>▁▃▃▄▆▅▅▄▆█</td></tr><tr><td>val_loss</td><td>█▇▇▇▇▇▅▃▄▁</td></tr><tr><td>val_mae</td><td>█▇▇▇▇█▄▂▇▁</td></tr><tr><td>val_mape</td><td>█▆▇▆▇█▄▁█▂</td></tr><tr><td>_runtime</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">wise-sweep-1</strong>: <a href=\"https://wandb.ai/nbvanting/thesis/runs/8x8vt07z\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/8x8vt07z</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: 9w92np4b with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 256\n",
      "wandb: \tcnn_layer_size_1: 72\n",
      "wandb: \tcnn_layer_size_2: 104\n",
      "wandb: \tdataset: strib\n",
      "wandb: \tdropout: 0.3562743156002092\n",
      "wandb: \tepochs: 10\n",
      "wandb: \tgru_layer_size_1: 50\n",
      "wandb: \tgru_layer_size_2: 196\n",
      "wandb: \tlearning_rate: 0.010370659787089297\n",
      "wandb: \tlookback: 744\n",
      "wandb: \tmomentum: 0.5220828738785559\n",
      "wandb: \tnum_cnn_layers: 2\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 2\n",
      "wandb: \toptimizer: sgd\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n",
      "wandb: wandb version 0.10.29 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">apricot-sweep-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/359c75sk\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/359c75sk</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/9w92np4b\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/9w92np4b</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_133706-9w92np4b</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "57/57 [==============================] - 71s 1s/step - loss: 0.9001 - mae: 0.7498 - mape: 159.7119 - val_loss: 1.3080 - val_mae: 0.8934 - val_mape: 174.1241\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 55s 964ms/step - loss: 0.7716 - mae: 0.6998 - mape: 255.8502 - val_loss: 1.3116 - val_mae: 0.8958 - val_mape: 170.2188\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 55s 969ms/step - loss: 0.7624 - mae: 0.6921 - mape: 233.5141 - val_loss: 1.2801 - val_mae: 0.8837 - val_mape: 183.9246\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 55s 969ms/step - loss: 0.7640 - mae: 0.6936 - mape: 249.5402 - val_loss: 1.2613 - val_mae: 0.8774 - val_mape: 198.9182\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 54s 954ms/step - loss: 0.7578 - mae: 0.6916 - mape: 245.6929 - val_loss: 1.2523 - val_mae: 0.8748 - val_mape: 194.5359\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 54s 954ms/step - loss: 0.7547 - mae: 0.6910 - mape: 238.1472 - val_loss: 1.2438 - val_mae: 0.8731 - val_mape: 185.0673\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 54s 938ms/step - loss: 0.7421 - mae: 0.6818 - mape: 238.8250 - val_loss: 1.2311 - val_mae: 0.8702 - val_mape: 181.8525\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 56s 972ms/step - loss: 0.7323 - mae: 0.6779 - mape: 238.2889 - val_loss: 1.2118 - val_mae: 0.8668 - val_mape: 172.4950\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 56s 974ms/step - loss: 0.7267 - mae: 0.6773 - mape: 239.9470 - val_loss: 1.1943 - val_mae: 0.8663 - val_mape: 160.0838\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 56s 978ms/step - loss: 0.7082 - mae: 0.6689 - mape: 220.4919 - val_loss: 1.1558 - val_mae: 0.8554 - val_mape: 163.0611\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 41076<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_133706-9w92np4b\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_133706-9w92np4b\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.70245</td></tr><tr><td>mae</td><td>0.66521</td></tr><tr><td>mape</td><td>223.79549</td></tr><tr><td>val_loss</td><td>1.1558</td></tr><tr><td>val_mae</td><td>0.85536</td></tr><tr><td>val_mape</td><td>163.0611</td></tr><tr><td>_runtime</td><td>571</td></tr><tr><td>_timestamp</td><td>1620128797</td></tr><tr><td>_step</td><td>9</td></tr><tr><td>best_val_loss</td><td>1.1558</td></tr><tr><td>best_epoch</td><td>9</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▅▄▄▃▃▃▂▂▁</td></tr><tr><td>mae</td><td>█▅▄▄▃▃▃▂▂▁</td></tr><tr><td>mape</td><td>▁█▆▇▇▆▆▆▇▆</td></tr><tr><td>val_loss</td><td>██▇▆▅▅▄▄▃▁</td></tr><tr><td>val_mae</td><td>██▆▅▄▄▄▃▃▁</td></tr><tr><td>val_mape</td><td>▄▃▅█▇▆▅▃▁▂</td></tr><tr><td>_runtime</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">apricot-sweep-2</strong>: <a href=\"https://wandb.ai/nbvanting/thesis/runs/9w92np4b\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/9w92np4b</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: ax4tew0i with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 249\n",
      "wandb: \tcnn_layer_size_1: 72\n",
      "wandb: \tcnn_layer_size_2: 102\n",
      "wandb: \tdataset: kolding\n",
      "wandb: \tdropout: 0.4253583718248085\n",
      "wandb: \tepochs: 10\n",
      "wandb: \tgru_layer_size_1: 69\n",
      "wandb: \tgru_layer_size_2: 199\n",
      "wandb: \tlearning_rate: 0.011542956821584297\n",
      "wandb: \tlookback: 744\n",
      "wandb: \tmomentum: 0.2231179278946988\n",
      "wandb: \tnum_cnn_layers: 2\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 0\n",
      "wandb: \toptimizer: sgd\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n",
      "wandb: wandb version 0.10.29 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">restful-sweep-3</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/359c75sk\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/359c75sk</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/ax4tew0i\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/ax4tew0i</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_134642-ax4tew0i</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "59/59 [==============================] - 54s 859ms/step - loss: 0.8161 - mae: 0.7171 - mape: 273.6674 - val_loss: 1.3341 - val_mae: 0.9298 - val_mape: 278.7491\n",
      "Epoch 2/10\n",
      "59/59 [==============================] - 47s 801ms/step - loss: 0.6915 - mae: 0.6590 - mape: 458.5755 - val_loss: 1.2816 - val_mae: 0.9227 - val_mape: 289.3993\n",
      "Epoch 3/10\n",
      "59/59 [==============================] - 47s 795ms/step - loss: 0.6537 - mae: 0.6393 - mape: 439.0189 - val_loss: 1.1748 - val_mae: 0.8807 - val_mape: 274.4645\n",
      "Epoch 4/10\n",
      "59/59 [==============================] - 50s 845ms/step - loss: 0.6214 - mae: 0.6254 - mape: 454.2323 - val_loss: 1.0198 - val_mae: 0.8376 - val_mape: 283.4481\n",
      "Epoch 5/10\n",
      "59/59 [==============================] - 48s 818ms/step - loss: 0.5564 - mae: 0.5957 - mape: 760.3484 - val_loss: 0.9351 - val_mae: 0.8361 - val_mape: 341.9534\n",
      "Epoch 6/10\n",
      "59/59 [==============================] - 51s 865ms/step - loss: 0.4998 - mae: 0.5639 - mape: 728.2318 - val_loss: 0.6939 - val_mae: 0.7005 - val_mape: 254.4466\n",
      "Epoch 7/10\n",
      "59/59 [==============================] - 48s 819ms/step - loss: 0.4539 - mae: 0.5353 - mape: 624.1936 - val_loss: 0.5912 - val_mae: 0.6496 - val_mape: 255.0430\n",
      "Epoch 8/10\n",
      "59/59 [==============================] - 48s 805ms/step - loss: 0.3921 - mae: 0.4978 - mape: 630.0881 - val_loss: 0.4898 - val_mae: 0.5908 - val_mape: 220.8472\n",
      "Epoch 9/10\n",
      "59/59 [==============================] - 48s 811ms/step - loss: 0.3593 - mae: 0.4760 - mape: 492.0598 - val_loss: 0.3381 - val_mae: 0.4496 - val_mape: 144.5797\n",
      "Epoch 10/10\n",
      "59/59 [==============================] - 49s 827ms/step - loss: 0.3064 - mae: 0.4364 - mape: 579.8145 - val_loss: 0.2675 - val_mae: 0.4232 - val_mape: 149.5222\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 38352<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_134642-ax4tew0i\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_134642-ax4tew0i\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.30055</td></tr><tr><td>mae</td><td>0.43208</td></tr><tr><td>mape</td><td>428.72668</td></tr><tr><td>val_loss</td><td>0.26753</td></tr><tr><td>val_mae</td><td>0.42324</td></tr><tr><td>val_mape</td><td>149.5222</td></tr><tr><td>_runtime</td><td>495</td></tr><tr><td>_timestamp</td><td>1620129297</td></tr><tr><td>_step</td><td>9</td></tr><tr><td>best_val_loss</td><td>0.26753</td></tr><tr><td>best_epoch</td><td>9</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>mae</td><td>█▇▇▆▅▅▄▃▂▁</td></tr><tr><td>mape</td><td>▁▃▃▃▅▃▇█▃▄</td></tr><tr><td>val_loss</td><td>██▇▆▅▄▃▂▁▁</td></tr><tr><td>val_mae</td><td>██▇▇▇▅▄▃▁▁</td></tr><tr><td>val_mape</td><td>▆▆▆▆█▅▅▄▁▁</td></tr><tr><td>_runtime</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">restful-sweep-3</strong>: <a href=\"https://wandb.ai/nbvanting/thesis/runs/ax4tew0i\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/ax4tew0i</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: xdzlt1qh with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 208\n",
      "wandb: \tcnn_layer_size_1: 70\n",
      "wandb: \tcnn_layer_size_2: 102\n",
      "wandb: \tdataset: kolding\n",
      "wandb: \tdropout: 0.42109981846297884\n",
      "wandb: \tepochs: 10\n",
      "wandb: \tgru_layer_size_1: 40\n",
      "wandb: \tgru_layer_size_2: 191\n",
      "wandb: \tlearning_rate: 0.006892674713992945\n",
      "wandb: \tlookback: 744\n",
      "wandb: \tmomentum: 0.44439765825782684\n",
      "wandb: \tnum_cnn_layers: 1\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 2\n",
      "wandb: \toptimizer: sgd\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n",
      "wandb: wandb version 0.10.29 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">gentle-sweep-4</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/359c75sk\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/359c75sk</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/xdzlt1qh\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/xdzlt1qh</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_135502-xdzlt1qh</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "70/70 [==============================] - 144s 2s/step - loss: 0.8675 - mae: 0.7264 - mape: 173.8809 - val_loss: 1.3710 - val_mae: 0.9446 - val_mape: 287.2042\n",
      "Epoch 2/10\n",
      "70/70 [==============================] - 134s 2s/step - loss: 0.7119 - mae: 0.6660 - mape: 294.4088 - val_loss: 1.3636 - val_mae: 0.9415 - val_mape: 286.3240\n",
      "Epoch 3/10\n",
      "70/70 [==============================] - 137s 2s/step - loss: 0.7041 - mae: 0.6636 - mape: 308.6088 - val_loss: 1.3563 - val_mae: 0.9393 - val_mape: 285.8980\n",
      "Epoch 4/10\n",
      "70/70 [==============================] - 137s 2s/step - loss: 0.6978 - mae: 0.6606 - mape: 293.2338 - val_loss: 1.3662 - val_mae: 0.9572 - val_mape: 310.0359\n",
      "Epoch 5/10\n",
      "70/70 [==============================] - 136s 2s/step - loss: 0.7013 - mae: 0.6610 - mape: 335.8334 - val_loss: 1.3365 - val_mae: 0.9334 - val_mape: 285.5710\n",
      "Epoch 6/10\n",
      "70/70 [==============================] - 139s 2s/step - loss: 0.6907 - mae: 0.6559 - mape: 303.2647 - val_loss: 1.3235 - val_mae: 0.9325 - val_mape: 291.9466\n",
      "Epoch 7/10\n",
      "37/70 [==============>...............] - ETA: 1:03 - loss: 0.6799 - mae: 0.6542 - mape: 287.0643"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 21812<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_135502-xdzlt1qh\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_135502-xdzlt1qh\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>5</td></tr><tr><td>loss</td><td>0.69919</td></tr><tr><td>mae</td><td>0.65819</td></tr><tr><td>mape</td><td>338.31277</td></tr><tr><td>val_loss</td><td>1.32351</td></tr><tr><td>val_mae</td><td>0.93253</td></tr><tr><td>val_mape</td><td>291.94662</td></tr><tr><td>_runtime</td><td>834</td></tr><tr><td>_timestamp</td><td>1620130136</td></tr><tr><td>_step</td><td>5</td></tr><tr><td>best_val_loss</td><td>1.32351</td></tr><tr><td>best_epoch</td><td>5</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▄▅▇█</td></tr><tr><td>loss</td><td>█▃▂▂▁▁</td></tr><tr><td>mae</td><td>█▃▂▂▂▁</td></tr><tr><td>mape</td><td>▁▅▄▆█▅</td></tr><tr><td>val_loss</td><td>█▇▆▇▃▁</td></tr><tr><td>val_mae</td><td>▄▄▃█▁▁</td></tr><tr><td>val_mape</td><td>▁▁▁█▁▃</td></tr><tr><td>_runtime</td><td>▁▂▄▅▇█</td></tr><tr><td>_timestamp</td><td>▁▂▄▅▇█</td></tr><tr><td>_step</td><td>▁▂▄▅▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">gentle-sweep-4</strong>: <a href=\"https://wandb.ai/nbvanting/thesis/runs/xdzlt1qh\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/xdzlt1qh</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: 8ym0xcy9 with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 201\n",
      "wandb: \tcnn_layer_size_1: 75\n",
      "wandb: \tcnn_layer_size_2: 105\n",
      "wandb: \tdataset: kolding\n",
      "wandb: \tdropout: 0.03770062046505656\n",
      "wandb: \tepochs: 10\n",
      "wandb: \tgru_layer_size_1: 46\n",
      "wandb: \tgru_layer_size_2: 190\n",
      "wandb: \tlearning_rate: 0.029068026775151804\n",
      "wandb: \tlookback: 744\n",
      "wandb: \tmomentum: 0.49368544710626955\n",
      "wandb: \tnum_cnn_layers: 0\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 1\n",
      "wandb: \toptimizer: sgd\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n",
      "wandb: wandb version 0.10.29 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">super-sweep-5</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/359c75sk\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/359c75sk</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/8ym0xcy9\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/8ym0xcy9</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_141014-8ym0xcy9</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "73/73 [==============================] - 276s 4s/step - loss: 0.7163 - mae: 0.6628 - mape: 356.6735 - val_loss: 0.8881 - val_mae: 0.7326 - val_mape: 263.6144\n",
      "Epoch 2/10\n",
      "73/73 [==============================] - 269s 4s/step - loss: 0.5241 - mae: 0.5561 - mape: 419.4080 - val_loss: 0.8056 - val_mae: 0.6965 - val_mape: 280.7363\n",
      "Epoch 3/10\n",
      "73/73 [==============================] - 267s 4s/step - loss: 0.4573 - mae: 0.5189 - mape: 404.7264 - val_loss: 0.6988 - val_mae: 0.6359 - val_mape: 290.5775\n",
      "Epoch 4/10\n",
      "73/73 [==============================] - 267s 4s/step - loss: 0.4103 - mae: 0.4893 - mape: 334.2630 - val_loss: 0.6121 - val_mae: 0.5791 - val_mape: 238.3814\n",
      "Epoch 5/10\n",
      "73/73 [==============================] - 268s 4s/step - loss: 0.3782 - mae: 0.4655 - mape: 280.2192 - val_loss: 0.5844 - val_mae: 0.5639 - val_mape: 231.4915\n",
      "Epoch 6/10\n",
      "73/73 [==============================] - 266s 4s/step - loss: 0.3448 - mae: 0.4413 - mape: 485.5671 - val_loss: 0.5583 - val_mae: 0.5278 - val_mape: 194.1802\n",
      "Epoch 7/10\n",
      "73/73 [==============================] - 271s 4s/step - loss: 0.3150 - mae: 0.4200 - mape: 387.2129 - val_loss: 0.5413 - val_mae: 0.5658 - val_mape: 229.3679\n",
      "Epoch 8/10\n",
      "73/73 [==============================] - 276s 4s/step - loss: 0.3014 - mae: 0.4116 - mape: 457.9845 - val_loss: 0.4651 - val_mae: 0.5004 - val_mape: 185.2525\n",
      "Epoch 9/10\n",
      "73/73 [==============================] - 265s 4s/step - loss: 0.2768 - mae: 0.3951 - mape: 396.3323 - val_loss: 0.4284 - val_mae: 0.4720 - val_mape: 168.7551\n",
      "Epoch 10/10\n",
      "73/73 [==============================] - 265s 4s/step - loss: 0.2662 - mae: 0.3894 - mape: 389.6627 - val_loss: 0.3961 - val_mae: 0.4443 - val_mape: 159.1329\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 38480<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_141014-8ym0xcy9\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_141014-8ym0xcy9\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.25818</td></tr><tr><td>mae</td><td>0.38305</td></tr><tr><td>mape</td><td>335.85718</td></tr><tr><td>val_loss</td><td>0.39608</td></tr><tr><td>val_mae</td><td>0.4443</td></tr><tr><td>val_mape</td><td>159.1329</td></tr><tr><td>_runtime</td><td>2696</td></tr><tr><td>_timestamp</td><td>1620132910</td></tr><tr><td>_step</td><td>9</td></tr><tr><td>best_val_loss</td><td>0.39608</td></tr><tr><td>best_epoch</td><td>9</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▆▄▄▃▂▂▂▁▁</td></tr><tr><td>mae</td><td>█▆▅▄▃▂▂▂▁▁</td></tr><tr><td>mape</td><td>▃▅█▆▁▇▄▇▃▂</td></tr><tr><td>val_loss</td><td>█▇▅▄▄▃▃▂▁▁</td></tr><tr><td>val_mae</td><td>█▇▆▄▄▃▄▂▂▁</td></tr><tr><td>val_mape</td><td>▇▇█▅▅▃▅▂▂▁</td></tr><tr><td>_runtime</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">super-sweep-5</strong>: <a href=\"https://wandb.ai/nbvanting/thesis/runs/8ym0xcy9\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/8ym0xcy9</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Sweep Agent: Waiting for job.\n",
      "500 response executing GraphQL.\n",
      "{\"errors\":[{\"message\":\"Post \\\"http://anaconda.default.svc.cluster.local/search\\\": context deadline exceeded\",\"path\":[\"agentHeartbeat\"]}],\"data\":{\"agentHeartbeat\":null}}\n",
      "wandb: ERROR Error while calling W&B API: Post \"http://anaconda.default.svc.cluster.local/search\": context deadline exceeded (<Response [500]>)\n",
      "wandb: Job received.\n",
      "wandb: Agent Starting Run: i6nfubcq with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 219\n",
      "wandb: \tcnn_layer_size_1: 69\n",
      "wandb: \tcnn_layer_size_2: 101\n",
      "wandb: \tdataset: kolding\n",
      "wandb: \tdropout: 0.4599103820888477\n",
      "wandb: \tepochs: 10\n",
      "wandb: \tgru_layer_size_1: 45\n",
      "wandb: \tgru_layer_size_2: 197\n",
      "wandb: \tlearning_rate: 0.024923394424840387\n",
      "wandb: \tlookback: 744\n",
      "wandb: \tmomentum: 0.7754471115694828\n",
      "wandb: \tnum_cnn_layers: 0\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 1\n",
      "wandb: \toptimizer: sgd\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n",
      "wandb: wandb version 0.10.29 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">zany-sweep-6</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/359c75sk\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/359c75sk</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/i6nfubcq\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/i6nfubcq</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210504_145554-i6nfubcq</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "67/67 [==============================] - 303s 4s/step - loss: 0.7529 - mae: 0.6782 - mape: 385.8344 - val_loss: 0.8832 - val_mae: 0.7144 - val_mape: 225.2812\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 308s 5s/step - loss: 0.5533 - mae: 0.5705 - mape: 465.9402 - val_loss: 0.8587 - val_mae: 0.7409 - val_mape: 327.1571\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 289s 4s/step - loss: 0.5033 - mae: 0.5419 - mape: 301.5889 - val_loss: 0.6812 - val_mae: 0.6164 - val_mape: 236.7942\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 293s 4s/step - loss: 0.4221 - mae: 0.4950 - mape: 540.2770 - val_loss: 0.6063 - val_mae: 0.5774 - val_mape: 220.1642\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 295s 4s/step - loss: 0.3860 - mae: 0.4694 - mape: 918.5082 - val_loss: 0.5629 - val_mae: 0.5627 - val_mape: 216.8304\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 300s 4s/step - loss: 0.3567 - mae: 0.4462 - mape: 438.8760 - val_loss: 0.5157 - val_mae: 0.4907 - val_mape: 156.8706\n",
      "Epoch 7/10\n",
      " 7/67 [==>...........................] - ETA: 4:36 - loss: 0.3435 - mae: 0.4264 - mape: 295.8773"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=run_tuner, count=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-crossing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
