{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "protective-genius",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from utils import processing\n",
    "from utils import utils\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import LSTM, GRU, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, TimeDistributed, \\\n",
    "    BatchNormalization\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "three-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams[\"figure.figsize\"] = (18,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "frequent-malaysia",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: nbvanting (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "proud-arrival",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(config, dataset_name):\n",
    "    # Load csv & parse dates to datetime index\n",
    "    data = pd.read_csv(f'../data/processed/{dataset_name}_features.csv', index_col='Datetime', parse_dates=['Datetime'])\n",
    "    # Select Features\n",
    "    data = data[['Value', 'sunshine_mins', 'airtemp_c', 'daylength_hrs', 'wkdy_sin', 'wkdy_cos', 'wknd', 'mnth_sin', 'mnth_cos']]\n",
    "    \n",
    "    train, val, test = processing.create_datasets(data, split=split, \n",
    "                                                  steps=steps, lookback=config.lookback, \n",
    "                                                  horizon=horizon, batch_size=config.batch_size, \n",
    "                                                  scaler='standard')    \n",
    "    return train, val, test\n",
    "    \n",
    "    \n",
    "def build_model(config):\n",
    "        \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Input(shape=(config.lookback, config.num_features)))\n",
    "\n",
    "    # CNN Block\n",
    "    model.add(Conv1D(filters=config.cnn_layer_size_1, kernel_size=3, activation=config.activation_cnn))\n",
    "    model.add(MaxPooling1D(pool_size=2))    \n",
    "    for i in range(config.num_cnn_layers):\n",
    "        model.add(Conv1D(filters=config.cnn_layer_size_2, kernel_size=3, activation=config.activation_cnn))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    # RNN Block\n",
    "    for i in range(config.num_gru_layers):\n",
    "        model.add(GRU(config.gru_layer_size_1, return_sequences=True, activation=config.activation_gru))\n",
    "        model.add(Dropout(config.dropout))\n",
    "    \n",
    "    model.add(GRU(config.gru_layer_size_2, return_sequences=False, activation=config.activation_gru))\n",
    "    model.add(Dropout(config.dropout))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    opt = config.optimizer\n",
    "    if opt == 'sgd':\n",
    "        opt = SGD(learning_rate=config.learning_rate, momentum=config.momentum)\n",
    "    elif opt == 'rmsprop':\n",
    "        opt = RMSprop(learning_rate=config.learning_rate)\n",
    "    else:\n",
    "        opt = Adam(learning_rate=config.learning_rate)\n",
    "        \n",
    "    model.compile(optimizer=opt, loss='mse', metrics=['mae', 'mape'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def log_defaults():\n",
    "\n",
    "    wandb_config = {\n",
    "        'num_features' : 9,\n",
    "        'epochs' : 50,\n",
    "        'batch_size' : 32,\n",
    "        'num_cnn_layers' : 1,\n",
    "        'num_gru_layers' : 1,\n",
    "        'optimizer' : 'adam',\n",
    "        'dropout' : 0.5,\n",
    "        'lookback' : 24*30,\n",
    "        'activation_cnn' : 'relu',\n",
    "        'activation_gru' : 'tanh',\n",
    "        'cnn_layer_size_1' : 64,\n",
    "        'cnn_layer_size_2' : 64,\n",
    "        'gru_layer_size_1' : 50,\n",
    "        'gru_layer_size_2' : 100,\n",
    "        'learning_rate' : 0.001,\n",
    "        'momentum' : 0.9,\n",
    "    }\n",
    "    return wandb_config\n",
    "    \n",
    "\n",
    "def run_tuner():\n",
    "    \n",
    "    wandb.init(config=log_defaults(), project='thesis')\n",
    "    \n",
    "    model = build_model(config=wandb.config)\n",
    "    \n",
    "    train, val, _ = load_data(config=wandb.config, dataset_name='kolding')\n",
    "\n",
    "    callbacks = [WandbCallback()]\n",
    "    \n",
    "    model.fit(\n",
    "        train,\n",
    "        epochs=wandb.config.epochs,\n",
    "        validation_data=val,\n",
    "        callbacks=callbacks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sporting-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweep Config\n",
    "sweep_config = {\n",
    "    'method': 'random',\n",
    "    'metric': {\n",
    "        'name': 'val_loss',\n",
    "        'goal': 'minimize'\n",
    "    },\n",
    "    'early_terminate': {\n",
    "        'type': 'hyperband',\n",
    "        'min_iter': 5\n",
    "    },\n",
    "    'parameters': {\n",
    "        'num_features' : {\n",
    "            'value' : 9\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'distribution': 'q_log_uniform',\n",
    "            'q': 1,\n",
    "            'min': math.log(32),\n",
    "            'max': math.log(256)\n",
    "        },\n",
    "        'lookback': {\n",
    "            'distribution': 'int_uniform',\n",
    "            'min': 24*7,\n",
    "            'max': 24*31\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'values': ['rmsprop', 'sgd', 'adam']\n",
    "        },\n",
    "        'dropout': {\n",
    "            'distribution': 'uniform',\n",
    "            'min': 0,\n",
    "            'max': 0.5\n",
    "        },\n",
    "        'epochs': {\n",
    "            'value': 50\n",
    "        },\n",
    "        'activation_gru': {\n",
    "            'value': 'tanh'\n",
    "        },\n",
    "        'activation_cnn': {\n",
    "            'value': 'relu'\n",
    "        },\n",
    "        'cnn_layer_size_1': {\n",
    "            'distribution': 'q_log_uniform',\n",
    "            'q': 1,\n",
    "            'min': math.log(32),\n",
    "            'max': math.log(256)\n",
    "        },\n",
    "        'cnn_layer_size_2': {\n",
    "            'distribution': 'q_log_uniform',\n",
    "            'q': 1,\n",
    "            'min': math.log(32),\n",
    "            'max': math.log(256)\n",
    "        },\n",
    "        'gru_layer_size_1': {\n",
    "            'distribution': 'q_log_uniform',\n",
    "            'q': 1,\n",
    "            'min': math.log(32),\n",
    "            'max': math.log(256)\n",
    "        },\n",
    "        'gru_layer_size_2': {\n",
    "            'distribution': 'q_log_uniform',\n",
    "            'q': 1,\n",
    "            'min': math.log(32),\n",
    "            'max': math.log(256)\n",
    "        },\n",
    "        'learning_rate': {\n",
    "            'distribution': 'uniform',\n",
    "            'min': 0.001,\n",
    "            'max': 0.1\n",
    "        },\n",
    "        'momentum': {\n",
    "            'values': [0.8, 0.85, 0.9, 0.95]\n",
    "        },\n",
    "        'num_cnn_layers': {\n",
    "            'values': [1, 2]\n",
    "        },\n",
    "        'num_gru_layers': {\n",
    "            'values': [1, 2]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "psychological-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional Parameters\n",
    "split = 0.80 # split percentage for training data\n",
    "steps = 1 # timesteps: 1 hour\n",
    "horizon = 1 # the target hour in the future we want to predict 1 hour ahead\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "emerging-military",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: y7xar0dh\n",
      "Sweep URL: https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project='thesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-dialogue",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: 2ckvdj53 with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 130\n",
      "wandb: \tcnn_layer_size_1: 57\n",
      "wandb: \tcnn_layer_size_2: 51\n",
      "wandb: \tdropout: 0.48513791567026154\n",
      "wandb: \tepochs: 50\n",
      "wandb: \tgru_layer_size_1: 118\n",
      "wandb: \tgru_layer_size_2: 34\n",
      "wandb: \tlearning_rate: 0.06795239772836459\n",
      "wandb: \tlookback: 555\n",
      "wandb: \tmomentum: 0.8\n",
      "wandb: \tnum_cnn_layers: 2\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 1\n",
      "wandb: \toptimizer: adam\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n",
      "c:\\users\\nicol\\envs\\thesis\\lib\\site-packages\\IPython\\html.py:12: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  warn(\"The `IPython.html` package has been deprecated since IPython 4.0. \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">easy-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/2ckvdj53\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/2ckvdj53</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_124921-2ckvdj53</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "114/114 [==============================] - 32s 247ms/step - loss: 2.5134 - mae: 1.1315 - mape: 568.5951 - val_loss: 1.5980 - val_mae: 0.9060 - val_mape: 116.7106\n",
      "Epoch 2/50\n",
      "114/114 [==============================] - 25s 219ms/step - loss: 1.0005 - mae: 0.7731 - mape: 188.4544 - val_loss: 2.0299 - val_mae: 0.9914 - val_mape: 300.4307\n",
      "Epoch 3/50\n",
      "114/114 [==============================] - 25s 220ms/step - loss: 1.0240 - mae: 0.7797 - mape: 181.6530 - val_loss: 1.3756 - val_mae: 0.8906 - val_mape: 246.9705\n",
      "Epoch 4/50\n",
      "114/114 [==============================] - 23s 202ms/step - loss: 1.0133 - mae: 0.7850 - mape: 189.7667 - val_loss: 1.3932 - val_mae: 0.8892 - val_mape: 223.5679\n",
      "Epoch 5/50\n",
      "114/114 [==============================] - 23s 202ms/step - loss: 1.0276 - mae: 0.7863 - mape: 194.8492 - val_loss: 1.6111 - val_mae: 0.9079 - val_mape: 122.7724\n",
      "Epoch 6/50\n",
      "114/114 [==============================] - 23s 202ms/step - loss: 1.0447 - mae: 0.7908 - mape: 226.4052 - val_loss: 1.6035 - val_mae: 0.9068 - val_mape: 119.2228\n",
      "Epoch 7/50\n",
      "114/114 [==============================] - 23s 202ms/step - loss: 1.0111 - mae: 0.7783 - mape: 176.4557 - val_loss: 1.6191 - val_mae: 0.9092 - val_mape: 126.5884\n",
      "Epoch 8/50\n",
      "114/114 [==============================] - 23s 202ms/step - loss: 1.0321 - mae: 0.7903 - mape: 193.4086 - val_loss: 1.5179 - val_mae: 0.8953 - val_mape: 118.9982\n",
      "Epoch 9/50\n",
      "114/114 [==============================] - 23s 204ms/step - loss: 1.0117 - mae: 0.7817 - mape: 190.0472 - val_loss: 1.5524 - val_mae: 0.8996 - val_mape: 101.7262\n",
      "Epoch 10/50\n",
      "114/114 [==============================] - 24s 206ms/step - loss: 1.0724 - mae: 0.8001 - mape: 213.7153 - val_loss: 1.6172 - val_mae: 0.9089 - val_mape: 125.6646\n",
      "Epoch 11/50\n",
      "114/114 [==============================] - 23s 206ms/step - loss: 1.0297 - mae: 0.7842 - mape: 175.2243 - val_loss: 1.5729 - val_mae: 0.9024 - val_mape: 105.6058\n",
      "Epoch 12/50\n",
      "114/114 [==============================] - 23s 203ms/step - loss: 1.0391 - mae: 0.7904 - mape: 217.9957 - val_loss: 1.3510 - val_mae: 0.8959 - val_mape: 290.3188\n",
      "Epoch 13/50\n",
      "114/114 [==============================] - 23s 203ms/step - loss: 1.0388 - mae: 0.7925 - mape: 222.5194 - val_loss: 1.4688 - val_mae: 0.8908 - val_mape: 151.6690\n",
      "Epoch 14/50\n",
      "114/114 [==============================] - 23s 205ms/step - loss: 1.0356 - mae: 0.7913 - mape: 192.2649 - val_loss: 1.5978 - val_mae: 0.9059 - val_mape: 116.6306\n",
      "Epoch 15/50\n",
      "114/114 [==============================] - 23s 205ms/step - loss: 1.0477 - mae: 0.7962 - mape: 256.3398 - val_loss: 1.3955 - val_mae: 0.8891 - val_mape: 220.8276\n",
      "Epoch 16/50\n",
      "114/114 [==============================] - 24s 207ms/step - loss: 1.0660 - mae: 0.8040 - mape: 246.4099 - val_loss: 1.7599 - val_mae: 0.9330 - val_mape: 190.8215\n",
      "Epoch 17/50\n",
      "114/114 [==============================] - 24s 208ms/step - loss: 1.0169 - mae: 0.7813 - mape: 190.2214 - val_loss: 1.6617 - val_mae: 0.9161 - val_mape: 146.6180\n",
      "Epoch 18/50\n",
      "114/114 [==============================] - 23s 206ms/step - loss: 1.0300 - mae: 0.7872 - mape: 206.3121 - val_loss: 1.3810 - val_mae: 0.8900 - val_mape: 239.2707\n",
      "Epoch 19/50\n",
      "114/114 [==============================] - 24s 215ms/step - loss: 1.0293 - mae: 0.7932 - mape: 197.5823 - val_loss: 1.5399 - val_mae: 0.8980 - val_mape: 107.2430\n",
      "Epoch 20/50\n",
      "114/114 [==============================] - 24s 208ms/step - loss: 1.0234 - mae: 0.7868 - mape: 189.4415 - val_loss: 1.3810 - val_mae: 0.8900 - val_mape: 239.3145\n",
      "Epoch 21/50\n",
      "114/114 [==============================] - 24s 208ms/step - loss: 1.0190 - mae: 0.7839 - mape: 183.8347 - val_loss: 1.5221 - val_mae: 0.8958 - val_mape: 116.6328\n",
      "Epoch 22/50\n",
      "114/114 [==============================] - 24s 214ms/step - loss: 1.0540 - mae: 0.7983 - mape: 225.7466 - val_loss: 1.9650 - val_mae: 0.9753 - val_mape: 275.1882\n",
      "Epoch 23/50\n",
      "114/114 [==============================] - 26s 224ms/step - loss: 1.0922 - mae: 0.8058 - mape: 264.1399 - val_loss: 2.0046 - val_mae: 0.9850 - val_mape: 290.6575\n",
      "Epoch 24/50\n",
      "114/114 [==============================] - 24s 209ms/step - loss: 1.0381 - mae: 0.7868 - mape: 206.8515 - val_loss: 1.4813 - val_mae: 0.8916 - val_mape: 142.3344\n",
      "Epoch 25/50\n",
      "114/114 [==============================] - 24s 206ms/step - loss: 1.0337 - mae: 0.7912 - mape: 221.6869 - val_loss: 1.7645 - val_mae: 0.9339 - val_mape: 192.8333\n",
      "Epoch 26/50\n",
      "114/114 [==============================] - 24s 206ms/step - loss: 1.0725 - mae: 0.8036 - mape: 251.0916 - val_loss: 1.7916 - val_mae: 0.9387 - val_mape: 204.4050\n",
      "Epoch 27/50\n",
      "114/114 [==============================] - 24s 206ms/step - loss: 1.0381 - mae: 0.7897 - mape: 186.7229 - val_loss: 1.8803 - val_mae: 0.9561 - val_mape: 241.2410\n",
      "Epoch 28/50\n",
      "114/114 [==============================] - 24s 208ms/step - loss: 1.0668 - mae: 0.8032 - mape: 232.2692 - val_loss: 1.4309 - val_mae: 0.8892 - val_mape: 183.6600\n",
      "Epoch 29/50\n",
      "114/114 [==============================] - 24s 207ms/step - loss: 1.0523 - mae: 0.8000 - mape: 206.4115 - val_loss: 1.5795 - val_mae: 0.9033 - val_mape: 108.4109\n",
      "Epoch 30/50\n",
      "114/114 [==============================] - 24s 206ms/step - loss: 1.0313 - mae: 0.7910 - mape: 206.9465 - val_loss: 1.5628 - val_mae: 0.9010 - val_mape: 101.5751\n",
      "Epoch 31/50\n",
      "114/114 [==============================] - 23s 205ms/step - loss: 1.0135 - mae: 0.7807 - mape: 194.1113 - val_loss: 1.9456 - val_mae: 0.9706 - val_mape: 267.4854\n",
      "Epoch 32/50\n",
      "114/114 [==============================] - 23s 205ms/step - loss: 1.0622 - mae: 0.7968 - mape: 200.2959 - val_loss: 1.8724 - val_mae: 0.9545 - val_mape: 238.0389\n",
      "Epoch 33/50\n",
      "114/114 [==============================] - 24s 206ms/step - loss: 1.0383 - mae: 0.7882 - mape: 197.9517 - val_loss: 1.6120 - val_mae: 0.9081 - val_mape: 123.2184\n",
      "Epoch 34/50\n",
      "114/114 [==============================] - 24s 207ms/step - loss: 1.0518 - mae: 0.8003 - mape: 254.0035 - val_loss: 1.5819 - val_mae: 0.9036 - val_mape: 109.4709\n",
      "Epoch 35/50\n",
      "114/114 [==============================] - 24s 207ms/step - loss: 1.0342 - mae: 0.7862 - mape: 220.0177 - val_loss: 1.3890 - val_mae: 0.8894 - val_mape: 228.7432\n",
      "Epoch 36/50\n",
      "114/114 [==============================] - 24s 207ms/step - loss: 1.0485 - mae: 0.7943 - mape: 212.6673 - val_loss: 1.3590 - val_mae: 0.8935 - val_mape: 274.1009\n",
      "Epoch 37/50\n",
      "114/114 [==============================] - 24s 209ms/step - loss: 1.0855 - mae: 0.8132 - mape: 285.7783 - val_loss: 1.4680 - val_mae: 0.8908 - val_mape: 152.2120\n",
      "Epoch 38/50\n",
      "114/114 [==============================] - 24s 207ms/step - loss: 1.0367 - mae: 0.7957 - mape: 217.5423 - val_loss: 1.5656 - val_mae: 0.9014 - val_mape: 102.7010\n",
      "Epoch 39/50\n",
      "114/114 [==============================] - 24s 207ms/step - loss: 1.0230 - mae: 0.7843 - mape: 175.0936 - val_loss: 1.3847 - val_mae: 0.8897 - val_mape: 234.3340\n",
      "Epoch 40/50\n",
      "114/114 [==============================] - 24s 207ms/step - loss: 1.0367 - mae: 0.7921 - mape: 212.7302 - val_loss: 2.2743 - val_mae: 1.0588 - val_mape: 389.5177\n",
      "Epoch 41/50\n",
      "114/114 [==============================] - 24s 207ms/step - loss: 1.0680 - mae: 0.7990 - mape: 215.6017 - val_loss: 1.4331 - val_mae: 0.8892 - val_mape: 181.6423\n",
      "Epoch 42/50\n",
      "114/114 [==============================] - 23s 206ms/step - loss: 1.0512 - mae: 0.7946 - mape: 203.9449 - val_loss: 2.0716 - val_mae: 1.0023 - val_mape: 316.2634\n",
      "Epoch 43/50\n",
      "114/114 [==============================] - 23s 206ms/step - loss: 1.0540 - mae: 0.7963 - mape: 204.9052 - val_loss: 1.6137 - val_mae: 0.9084 - val_mape: 124.0000\n",
      "Epoch 44/50\n",
      "114/114 [==============================] - 24s 209ms/step - loss: 1.0337 - mae: 0.7874 - mape: 181.5872 - val_loss: 1.5943 - val_mae: 0.9054 - val_mape: 115.0305\n",
      "Epoch 45/50\n",
      "114/114 [==============================] - 24s 206ms/step - loss: 1.0213 - mae: 0.7861 - mape: 185.1038 - val_loss: 1.4489 - val_mae: 0.8897 - val_mape: 167.5616\n",
      "Epoch 46/50\n",
      "114/114 [==============================] - 24s 208ms/step - loss: 1.0367 - mae: 0.7926 - mape: 203.3268 - val_loss: 1.5519 - val_mae: 0.8995 - val_mape: 101.9298\n",
      "Epoch 47/50\n",
      "114/114 [==============================] - 24s 207ms/step - loss: 1.0317 - mae: 0.7878 - mape: 184.7095 - val_loss: 1.6664 - val_mae: 0.9169 - val_mape: 148.8338\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 24s 206ms/step - loss: 1.0339 - mae: 0.7868 - mape: 194.2294 - val_loss: 1.4163 - val_mae: 0.8889 - val_mape: 197.8769\n",
      "Epoch 49/50\n",
      "114/114 [==============================] - 24s 207ms/step - loss: 1.0449 - mae: 0.7957 - mape: 176.6646 - val_loss: 1.3949 - val_mae: 0.8891 - val_mape: 221.5493\n",
      "Epoch 50/50\n",
      "114/114 [==============================] - 25s 222ms/step - loss: 1.0446 - mae: 0.7965 - mape: 226.5836 - val_loss: 1.6678 - val_mae: 0.9172 - val_mape: 149.4739\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 36436<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_124921-2ckvdj53\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_124921-2ckvdj53\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>49</td></tr><tr><td>loss</td><td>1.06072</td></tr><tr><td>mae</td><td>0.80051</td></tr><tr><td>mape</td><td>200.51965</td></tr><tr><td>val_loss</td><td>1.6678</td></tr><tr><td>val_mae</td><td>0.91716</td></tr><tr><td>val_mape</td><td>149.47392</td></tr><tr><td>_runtime</td><td>1199</td></tr><tr><td>_timestamp</td><td>1620040160</td></tr><tr><td>_step</td><td>49</td></tr><tr><td>best_val_loss</td><td>1.35098</td></tr><tr><td>best_epoch</td><td>11</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▁▁▁▂▁▁▁▁▂▁▁▁▁▁▁▁▂▂▁▁▁▂▁▁▁▁▂▂▂▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>mae</td><td>█▁▁▁▂▁▂▁▂▂▁▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▁▂▂</td></tr><tr><td>mape</td><td>█▂▁▁▃▂▁▂▂▃▂▂▃▂▂▂▂▄▄▃▃▂▃▃▃▂▂▄▄▅▃▁▃▁▂▁▃▁▃▂</td></tr><tr><td>val_loss</td><td>▃█▁▁▃▄▃▃▃▁▂▃▅▄▁▃▃▇▇▂▅▆▂▃▇▆▄▃▁▂▃▁▂█▄▃▃▄▂▄</td></tr><tr><td>val_mae</td><td>▂▇▁▁▂▂▁▂▂▁▁▂▄▃▁▂▁▆▇▁▄▅▁▂▆▅▂▂▁▁▂▁▁█▂▂▂▃▁▃</td></tr><tr><td>val_mape</td><td>▁▇▆▅▂▂▂▁▁▇▃▁▄▂▅▁▁▇▇▂▄▆▄▁▆▅▂▁▇▃▁▅▄█▂▁▁▃▄▃</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">easy-sweep-1</strong>: <a href=\"https://wandb.ai/nbvanting/thesis/runs/2ckvdj53\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/2ckvdj53</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: oikn5xn0 with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 247\n",
      "wandb: \tcnn_layer_size_1: 88\n",
      "wandb: \tcnn_layer_size_2: 133\n",
      "wandb: \tdropout: 0.20357324572128604\n",
      "wandb: \tepochs: 50\n",
      "wandb: \tgru_layer_size_1: 76\n",
      "wandb: \tgru_layer_size_2: 102\n",
      "wandb: \tlearning_rate: 0.08804630995000742\n",
      "wandb: \tlookback: 364\n",
      "wandb: \tmomentum: 0.9\n",
      "wandb: \tnum_cnn_layers: 2\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 2\n",
      "wandb: \toptimizer: rmsprop\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">cool-sweep-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/oikn5xn0\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/oikn5xn0</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_130924-oikn5xn0</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "61/61 [==============================] - 38s 522ms/step - loss: 24.7364 - mae: 3.2560 - mape: 1972.0849 - val_loss: 6.4521 - val_mae: 2.2750 - val_mape: 1039.8361\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 32s 524ms/step - loss: 7.6089 - mae: 2.4774 - mape: 1677.2017 - val_loss: 4.6357 - val_mae: 1.9626 - val_mape: 1303.8403\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 32s 530ms/step - loss: 6.5507 - mae: 2.3017 - mape: 1426.6061 - val_loss: 5.6909 - val_mae: 2.1011 - val_mape: 940.7719\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 32s 531ms/step - loss: 3.7597 - mae: 1.6915 - mape: 1054.1621 - val_loss: 3.0911 - val_mae: 1.5903 - val_mape: 1031.3175\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 32s 528ms/step - loss: 1.8857 - mae: 1.0851 - mape: 539.3077 - val_loss: 3.6385 - val_mae: 1.5378 - val_mape: 619.5294\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 32s 528ms/step - loss: 2.1173 - mae: 1.1930 - mape: 711.8286 - val_loss: 1.5096 - val_mae: 1.0695 - val_mape: 555.4808\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 32s 532ms/step - loss: 2.0122 - mae: 1.1606 - mape: 660.5870 - val_loss: 3.5463 - val_mae: 1.5078 - val_mape: 602.3118\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 32s 523ms/step - loss: 2.2870 - mae: 1.2376 - mape: 712.5431 - val_loss: 1.3465 - val_mae: 0.9807 - val_mape: 439.2356\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 32s 529ms/step - loss: 1.9819 - mae: 1.1468 - mape: 626.3014 - val_loss: 2.9704 - val_mae: 1.3097 - val_mape: 486.2121\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 32s 527ms/step - loss: 2.0199 - mae: 1.1424 - mape: 609.2926 - val_loss: 1.8044 - val_mae: 1.1909 - val_mape: 687.7059\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 32s 529ms/step - loss: 1.9394 - mae: 1.1291 - mape: 613.8057 - val_loss: 1.9359 - val_mae: 0.9754 - val_mape: 230.1168\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 32s 526ms/step - loss: 1.8761 - mae: 1.0793 - mape: 527.1874 - val_loss: 1.2798 - val_mae: 0.9178 - val_mape: 332.2140\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 32s 529ms/step - loss: 1.8719 - mae: 1.1054 - mape: 585.8084 - val_loss: 3.4332 - val_mae: 1.4702 - val_mape: 580.6827\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 32s 528ms/step - loss: 2.0036 - mae: 1.1428 - mape: 614.2743 - val_loss: 2.0325 - val_mae: 1.2723 - val_mape: 766.0843\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 32s 528ms/step - loss: 2.1307 - mae: 1.1958 - mape: 671.7955 - val_loss: 3.4738 - val_mae: 1.4838 - val_mape: 588.5157\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 32s 530ms/step - loss: 1.8859 - mae: 1.0930 - mape: 552.1382 - val_loss: 1.3043 - val_mae: 0.9485 - val_mape: 388.2509\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 32s 528ms/step - loss: 1.7813 - mae: 1.0710 - mape: 542.2759 - val_loss: 1.6914 - val_mae: 0.9185 - val_mape: 156.7601\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 33s 535ms/step - loss: 1.9065 - mae: 1.0787 - mape: 479.6570 - val_loss: 1.4065 - val_mae: 1.0169 - val_mape: 490.0261\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 32s 530ms/step - loss: 1.9027 - mae: 1.1174 - mape: 577.2596 - val_loss: 3.6508 - val_mae: 1.5418 - val_mape: 621.8090\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 32s 530ms/step - loss: 1.9018 - mae: 1.1114 - mape: 570.3301 - val_loss: 2.1936 - val_mae: 1.3264 - val_mape: 814.7621\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 32s 531ms/step - loss: 1.8185 - mae: 1.0866 - mape: 538.6014 - val_loss: 2.4780 - val_mae: 1.1392 - val_mape: 373.4956\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 32s 530ms/step - loss: 1.6402 - mae: 1.0027 - mape: 447.9995 - val_loss: 1.5620 - val_mae: 1.0932 - val_mape: 583.2651\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 32s 527ms/step - loss: 1.4858 - mae: 0.9556 - mape: 423.5318 - val_loss: 2.9134 - val_mae: 1.2896 - val_mape: 473.8510\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 32s 531ms/step - loss: 1.3132 - mae: 0.8857 - mape: 332.6142 - val_loss: 1.9773 - val_mae: 0.9865 - val_mape: 242.0220\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 32s 531ms/step - loss: 1.3947 - mae: 0.9225 - mape: 398.4892 - val_loss: 2.7473 - val_mae: 1.2312 - val_mape: 436.8584\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 32s 520ms/step - loss: 1.3634 - mae: 0.9009 - mape: 375.3585 - val_loss: 1.7755 - val_mae: 0.9361 - val_mape: 182.5279\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 32s 523ms/step - loss: 1.3530 - mae: 0.9023 - mape: 324.6697 - val_loss: 1.9330 - val_mae: 0.9746 - val_mape: 229.2944\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 33s 544ms/step - loss: 1.3404 - mae: 0.9019 - mape: 375.6556 - val_loss: 1.2941 - val_mae: 0.9383 - val_mape: 370.6271\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 32s 525ms/step - loss: 1.4613 - mae: 0.9514 - mape: 422.5062 - val_loss: 1.5772 - val_mae: 0.8969 - val_mape: 120.7174\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 31s 509ms/step - loss: 1.4107 - mae: 0.9241 - mape: 296.6744 - val_loss: 1.3825 - val_mae: 0.8728 - val_mape: 150.1816\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 31s 505ms/step - loss: 1.2687 - mae: 0.8767 - mape: 335.4963 - val_loss: 1.5853 - val_mae: 0.8984 - val_mape: 123.2791\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 31s 504ms/step - loss: 1.2398 - mae: 0.8650 - mape: 298.5653 - val_loss: 2.2055 - val_mae: 1.0525 - val_mape: 304.5570\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 31s 503ms/step - loss: 1.1496 - mae: 0.8244 - mape: 248.6961 - val_loss: 1.4840 - val_mae: 0.8819 - val_mape: 102.9174\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 31s 501ms/step - loss: 1.4539 - mae: 0.9407 - mape: 345.5005 - val_loss: 2.3337 - val_mae: 1.3715 - val_mape: 853.8281\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 30s 493ms/step - loss: 1.3338 - mae: 0.9059 - mape: 415.0838 - val_loss: 1.8468 - val_mae: 0.9526 - val_mape: 203.9416\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 29s 473ms/step - loss: 1.2559 - mae: 0.8739 - mape: 305.2251 - val_loss: 2.8788 - val_mae: 1.2774 - val_mape: 466.2619\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 31s 500ms/step - loss: 1.3250 - mae: 0.8935 - mape: 331.8387 - val_loss: 1.6002 - val_mae: 0.9010 - val_mape: 127.9688\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 31s 503ms/step - loss: 1.2482 - mae: 0.8670 - mape: 289.9261 - val_loss: 2.7911 - val_mae: 1.2465 - val_mape: 446.7475\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 30s 499ms/step - loss: 1.2369 - mae: 0.8592 - mape: 330.4408 - val_loss: 1.5700 - val_mae: 0.8956 - val_mape: 118.4205\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 31s 502ms/step - loss: 1.3066 - mae: 0.8829 - mape: 316.3643 - val_loss: 1.4699 - val_mae: 0.8799 - val_mape: 107.1489\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 31s 503ms/step - loss: 1.2977 - mae: 0.8885 - mape: 321.2454 - val_loss: 1.2846 - val_mae: 0.8867 - val_mape: 257.3344\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 31s 508ms/step - loss: 1.1628 - mae: 0.8372 - mape: 260.3994 - val_loss: 3.5573 - val_mae: 1.5114 - val_mape: 604.3705\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 31s 507ms/step - loss: 1.3538 - mae: 0.9045 - mape: 344.5137 - val_loss: 3.5492 - val_mae: 1.5087 - val_mape: 602.8484\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 31s 508ms/step - loss: 1.3291 - mae: 0.8955 - mape: 342.5008 - val_loss: 1.5297 - val_mae: 0.8888 - val_mape: 106.3737\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 31s 504ms/step - loss: 1.1966 - mae: 0.8500 - mape: 302.0888 - val_loss: 2.6420 - val_mae: 1.1949 - val_mape: 412.6220\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 31s 505ms/step - loss: 1.2381 - mae: 0.8620 - mape: 313.4872 - val_loss: 1.2765 - val_mae: 0.9014 - val_mape: 296.6082\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 31s 510ms/step - loss: 1.3395 - mae: 0.9056 - mape: 321.4260 - val_loss: 1.4159 - val_mae: 0.8745 - val_mape: 130.5783\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 31s 503ms/step - loss: 1.2567 - mae: 0.8789 - mape: 310.6535 - val_loss: 2.5784 - val_mae: 1.1732 - val_mape: 397.6655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "61/61 [==============================] - 30s 493ms/step - loss: 1.3538 - mae: 0.9059 - mape: 345.9333 - val_loss: 1.2768 - val_mae: 0.8992 - val_mape: 291.4945\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 31s 504ms/step - loss: 1.2462 - mae: 0.8696 - mape: 288.2489 - val_loss: 1.4857 - val_mae: 1.0581 - val_mape: 541.8459\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 8716<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_130924-oikn5xn0\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_130924-oikn5xn0\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>49</td></tr><tr><td>loss</td><td>1.26401</td></tr><tr><td>mae</td><td>0.87569</td></tr><tr><td>mape</td><td>311.57013</td></tr><tr><td>val_loss</td><td>1.48573</td></tr><tr><td>val_mae</td><td>1.05807</td></tr><tr><td>val_mape</td><td>541.84595</td></tr><tr><td>_runtime</td><td>1595</td></tr><tr><td>_timestamp</td><td>1620041759</td></tr><tr><td>_step</td><td>49</td></tr><tr><td>best_val_loss</td><td>1.2765</td></tr><tr><td>best_epoch</td><td>45</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▅▃▃▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mae</td><td>█▇▅▄▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mape</td><td>██▆▅▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆▇▃▁▄▁▃▂▁▄▂▁▂▁▄▃▁▃▂▂▂▁▁▁▂▁▂▃▁▃▁▁▄▄▁▁▁▃▁</td></tr><tr><td>val_mae</td><td>█▆▇▅▂▄▂▃▂▁▄▃▁▁▂▄▂▂▃▂▁▂▁▁▁▂▁▃▃▁▃▁▁▄▄▁▁▁▂▂</td></tr><tr><td>val_mape</td><td>▆█▆▆▄▄▃▃▂▂▄▅▃▁▃▄▃▄▃▂▁▂▃▁▁▂▁▅▃▁▃▁▂▄▄▁▂▁▃▄</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">cool-sweep-2</strong>: <a href=\"https://wandb.ai/nbvanting/thesis/runs/oikn5xn0\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/oikn5xn0</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: 8razd1gg with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 32\n",
      "wandb: \tcnn_layer_size_1: 188\n",
      "wandb: \tcnn_layer_size_2: 51\n",
      "wandb: \tdropout: 0.2846871559925311\n",
      "wandb: \tepochs: 50\n",
      "wandb: \tgru_layer_size_1: 207\n",
      "wandb: \tgru_layer_size_2: 154\n",
      "wandb: \tlearning_rate: 0.005971002603623766\n",
      "wandb: \tlookback: 193\n",
      "wandb: \tmomentum: 0.95\n",
      "wandb: \tnum_cnn_layers: 2\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 1\n",
      "wandb: \toptimizer: adam\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">worthy-sweep-3</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/8razd1gg\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/8razd1gg</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_133603-8razd1gg</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "473/473 [==============================] - 35s 65ms/step - loss: 0.4788 - mae: 0.4928 - mape: 11557.8610 - val_loss: 0.1615 - val_mae: 0.3169 - val_mape: 175.9272\n",
      "Epoch 2/50\n",
      "473/473 [==============================] - 29s 61ms/step - loss: 0.1519 - mae: 0.2988 - mape: 3487.8635 - val_loss: 0.1492 - val_mae: 0.3057 - val_mape: 182.9475\n",
      "Epoch 3/50\n",
      "473/473 [==============================] - 29s 62ms/step - loss: 0.1542 - mae: 0.2998 - mape: 6189.6245 - val_loss: 0.2205 - val_mae: 0.3786 - val_mape: 229.5633\n",
      "Epoch 4/50\n",
      "473/473 [==============================] - 29s 61ms/step - loss: 0.1414 - mae: 0.2901 - mape: 2927.8784 - val_loss: 0.1511 - val_mae: 0.3096 - val_mape: 193.4067\n",
      "Epoch 5/50\n",
      "473/473 [==============================] - 29s 61ms/step - loss: 0.1308 - mae: 0.2789 - mape: 1114.8923 - val_loss: 0.1590 - val_mae: 0.3055 - val_mape: 162.4254\n",
      "Epoch 6/50\n",
      "473/473 [==============================] - 29s 61ms/step - loss: 0.1432 - mae: 0.2929 - mape: 5692.5821 - val_loss: 0.1877 - val_mae: 0.3414 - val_mape: 235.5847\n",
      "Epoch 7/50\n",
      "473/473 [==============================] - 29s 61ms/step - loss: 0.1393 - mae: 0.2864 - mape: 2814.1602 - val_loss: 0.1974 - val_mae: 0.3581 - val_mape: 317.8884\n",
      "Epoch 8/50\n",
      "473/473 [==============================] - 29s 61ms/step - loss: 0.1665 - mae: 0.3159 - mape: 13307.0988 - val_loss: 0.1992 - val_mae: 0.3331 - val_mape: 152.9149\n",
      "Epoch 9/50\n",
      "473/473 [==============================] - 29s 61ms/step - loss: 0.1421 - mae: 0.2912 - mape: 11823.2271 - val_loss: 0.1488 - val_mae: 0.2958 - val_mape: 174.8966\n",
      "Epoch 10/50\n",
      "473/473 [==============================] - 29s 61ms/step - loss: 0.1685 - mae: 0.3165 - mape: 25251.1739 - val_loss: 0.1889 - val_mae: 0.3472 - val_mape: 212.0676\n",
      "Epoch 11/50\n",
      "473/473 [==============================] - 29s 61ms/step - loss: 0.3223 - mae: 0.4417 - mape: 4824.0431 - val_loss: 0.2603 - val_mae: 0.4008 - val_mape: 227.0501\n",
      "Epoch 12/50\n",
      "473/473 [==============================] - 29s 61ms/step - loss: 0.2909 - mae: 0.4233 - mape: 7745.2491 - val_loss: 0.2353 - val_mae: 0.3771 - val_mape: 235.6525\n",
      "Epoch 13/50\n",
      "473/473 [==============================] - 29s 61ms/step - loss: 0.2274 - mae: 0.3735 - mape: 7675.0874 - val_loss: 0.2619 - val_mae: 0.4016 - val_mape: 313.3730\n",
      "Epoch 14/50\n",
      "473/473 [==============================] - 29s 61ms/step - loss: 0.2276 - mae: 0.3698 - mape: 335.6452 - val_loss: 0.2242 - val_mae: 0.3715 - val_mape: 287.2530\n",
      "Epoch 15/50\n",
      "473/473 [==============================] - 29s 60ms/step - loss: 0.2468 - mae: 0.3850 - mape: 19293.5943 - val_loss: 0.4473 - val_mae: 0.5357 - val_mape: 442.3017\n",
      "Epoch 16/50\n",
      "473/473 [==============================] - 29s 60ms/step - loss: 0.2813 - mae: 0.4139 - mape: 6458.1913 - val_loss: 0.2143 - val_mae: 0.3570 - val_mape: 252.5281\n",
      "Epoch 17/50\n",
      "473/473 [==============================] - 29s 60ms/step - loss: 0.2320 - mae: 0.3739 - mape: 5166.7958 - val_loss: 0.2612 - val_mae: 0.3923 - val_mape: 238.2914\n",
      "Epoch 18/50\n",
      "473/473 [==============================] - 29s 60ms/step - loss: 0.2706 - mae: 0.4039 - mape: 11261.7190 - val_loss: 0.4218 - val_mae: 0.5056 - val_mape: 292.3691\n",
      "Epoch 19/50\n",
      "473/473 [==============================] - 29s 61ms/step - loss: 0.3163 - mae: 0.4429 - mape: 17502.7977 - val_loss: 0.3243 - val_mae: 0.4371 - val_mape: 207.6629\n",
      "Epoch 20/50\n",
      "473/473 [==============================] - 29s 61ms/step - loss: 0.2736 - mae: 0.4088 - mape: 11942.6212 - val_loss: 0.3185 - val_mae: 0.4260 - val_mape: 261.6902\n",
      "Epoch 21/50\n",
      "473/473 [==============================] - 29s 60ms/step - loss: 0.3262 - mae: 0.4407 - mape: 7614.3554 - val_loss: 0.2722 - val_mae: 0.3997 - val_mape: 155.1830\n",
      "Epoch 22/50\n",
      "473/473 [==============================] - 29s 60ms/step - loss: 0.2576 - mae: 0.3982 - mape: 14077.2682 - val_loss: 0.2361 - val_mae: 0.3840 - val_mape: 212.0406\n",
      "Epoch 23/50\n",
      "473/473 [==============================] - 29s 60ms/step - loss: 0.3133 - mae: 0.4300 - mape: 15448.3964 - val_loss: 0.3838 - val_mae: 0.4799 - val_mape: 260.1137\n",
      "Epoch 24/50\n",
      "473/473 [==============================] - 29s 60ms/step - loss: 0.3000 - mae: 0.4273 - mape: 16713.0659 - val_loss: 0.3385 - val_mae: 0.4781 - val_mape: 309.7305\n",
      "Epoch 25/50\n",
      "473/473 [==============================] - 29s 60ms/step - loss: 0.2618 - mae: 0.4010 - mape: 3681.4336 - val_loss: 0.2588 - val_mae: 0.3906 - val_mape: 173.7461\n",
      "Epoch 26/50\n",
      "473/473 [==============================] - 28s 60ms/step - loss: 0.2752 - mae: 0.4096 - mape: 9841.0517 - val_loss: 0.8108 - val_mae: 0.6558 - val_mape: 251.7944\n",
      "Epoch 27/50\n",
      "473/473 [==============================] - 28s 60ms/step - loss: 0.6674 - mae: 0.6218 - mape: 9295.6711 - val_loss: 1.1582 - val_mae: 0.8684 - val_mape: 402.8139\n",
      "Epoch 28/50\n",
      "473/473 [==============================] - 29s 61ms/step - loss: 0.7831 - mae: 0.6955 - mape: 7884.9079 - val_loss: 0.7633 - val_mae: 0.7079 - val_mape: 308.6137\n",
      "Epoch 29/50\n",
      "473/473 [==============================] - 28s 60ms/step - loss: 0.6386 - mae: 0.6243 - mape: 5581.6943 - val_loss: 0.6809 - val_mae: 0.6660 - val_mape: 271.9573\n",
      "Epoch 30/50\n",
      "473/473 [==============================] - 28s 60ms/step - loss: 0.4731 - mae: 0.5322 - mape: 15892.9420 - val_loss: 0.3867 - val_mae: 0.5028 - val_mape: 200.0262\n",
      "Epoch 31/50\n",
      "473/473 [==============================] - 28s 60ms/step - loss: 0.3938 - mae: 0.4874 - mape: 5240.4581 - val_loss: 0.3726 - val_mae: 0.4808 - val_mape: 220.6197\n",
      "Epoch 32/50\n",
      "473/473 [==============================] - 28s 60ms/step - loss: 0.3514 - mae: 0.4577 - mape: 4714.9151 - val_loss: 0.3656 - val_mae: 0.4788 - val_mape: 187.9911\n",
      "Epoch 33/50\n",
      "473/473 [==============================] - 28s 60ms/step - loss: 0.3580 - mae: 0.4646 - mape: 16084.2937 - val_loss: 0.3201 - val_mae: 0.4444 - val_mape: 147.9043\n",
      "Epoch 34/50\n",
      "473/473 [==============================] - 29s 60ms/step - loss: 0.3219 - mae: 0.4425 - mape: 18623.1655 - val_loss: 0.3097 - val_mae: 0.4140 - val_mape: 141.5412\n",
      "Epoch 35/50\n",
      "473/473 [==============================] - 28s 60ms/step - loss: 0.3018 - mae: 0.4254 - mape: 2161.7245 - val_loss: 0.2893 - val_mae: 0.4239 - val_mape: 179.8864\n",
      "Epoch 36/50\n",
      "473/473 [==============================] - 29s 61ms/step - loss: 0.3060 - mae: 0.4304 - mape: 12749.0198 - val_loss: 0.3595 - val_mae: 0.4856 - val_mape: 312.3834\n",
      "Epoch 37/50\n",
      "473/473 [==============================] - 29s 60ms/step - loss: 0.3205 - mae: 0.4431 - mape: 5159.9460 - val_loss: 0.3329 - val_mae: 0.4571 - val_mape: 180.6381\n",
      "Epoch 38/50\n",
      "473/473 [==============================] - 29s 60ms/step - loss: 0.3474 - mae: 0.4536 - mape: 20908.4404 - val_loss: 0.3892 - val_mae: 0.5012 - val_mape: 214.6852\n",
      "Epoch 39/50\n",
      "473/473 [==============================] - 28s 60ms/step - loss: 0.3191 - mae: 0.4446 - mape: 15566.2163 - val_loss: 0.2910 - val_mae: 0.4263 - val_mape: 241.8583\n",
      "Epoch 40/50\n",
      "473/473 [==============================] - 29s 60ms/step - loss: 0.2877 - mae: 0.4190 - mape: 7822.1225 - val_loss: 0.2917 - val_mae: 0.4239 - val_mape: 172.0330\n",
      "Epoch 41/50\n",
      "473/473 [==============================] - 28s 60ms/step - loss: 0.3013 - mae: 0.4291 - mape: 7048.6860 - val_loss: 0.4743 - val_mae: 0.5469 - val_mape: 380.9233\n",
      "Epoch 42/50\n",
      "473/473 [==============================] - 29s 60ms/step - loss: 0.4202 - mae: 0.5041 - mape: 16220.9371 - val_loss: 0.5559 - val_mae: 0.6252 - val_mape: 352.7099\n",
      "Epoch 43/50\n",
      "473/473 [==============================] - 28s 60ms/step - loss: 0.3994 - mae: 0.4937 - mape: 6872.7465 - val_loss: 0.5496 - val_mae: 0.5645 - val_mape: 223.5895\n",
      "Epoch 44/50\n",
      "473/473 [==============================] - 29s 60ms/step - loss: 0.4623 - mae: 0.5296 - mape: 6469.9349 - val_loss: 0.4366 - val_mae: 0.5292 - val_mape: 186.5873\n",
      "Epoch 45/50\n",
      "473/473 [==============================] - 30s 63ms/step - loss: 0.3920 - mae: 0.4920 - mape: 7050.3140 - val_loss: 0.4178 - val_mae: 0.5251 - val_mape: 213.3234\n",
      "Epoch 46/50\n",
      "473/473 [==============================] - 30s 64ms/step - loss: 0.3770 - mae: 0.4829 - mape: 5262.2342 - val_loss: 0.3730 - val_mae: 0.5022 - val_mape: 243.0825\n",
      "Epoch 47/50\n",
      "473/473 [==============================] - 29s 60ms/step - loss: 0.3577 - mae: 0.4686 - mape: 11642.6816 - val_loss: 0.3530 - val_mae: 0.4625 - val_mape: 211.2403\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "473/473 [==============================] - 29s 61ms/step - loss: 0.3484 - mae: 0.4575 - mape: 8299.5921 - val_loss: 0.3109 - val_mae: 0.4501 - val_mape: 202.3988\n",
      "Epoch 49/50\n",
      "473/473 [==============================] - 31s 66ms/step - loss: 0.3123 - mae: 0.4353 - mape: 2355.4475 - val_loss: 0.2968 - val_mae: 0.4366 - val_mape: 166.8070\n",
      "Epoch 50/50\n",
      "473/473 [==============================] - 31s 66ms/step - loss: 0.2945 - mae: 0.4264 - mape: 8965.0328 - val_loss: 0.3303 - val_mae: 0.4631 - val_mape: 158.3954\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 17152<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_133603-8razd1gg\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_133603-8razd1gg\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>49</td></tr><tr><td>loss</td><td>0.3026</td></tr><tr><td>mae</td><td>0.43223</td></tr><tr><td>mape</td><td>11105.64258</td></tr><tr><td>val_loss</td><td>0.33031</td></tr><tr><td>val_mae</td><td>0.46314</td></tr><tr><td>val_mape</td><td>158.39539</td></tr><tr><td>_runtime</td><td>1451</td></tr><tr><td>_timestamp</td><td>1620043214</td></tr><tr><td>_step</td><td>49</td></tr><tr><td>best_val_loss</td><td>0.14885</td></tr><tr><td>best_epoch</td><td>8</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▂▁▁▁▁▁▁▁▃▃▂▂▂▂▃▃▃▂▃▃▃██▇▄▃▃▃▃▃▄▃▃▄▄▄▄▃▃▃</td></tr><tr><td>mae</td><td>▃▁▁▁▁▁▁▁▄▃▃▃▃▃▄▄▄▃▄▃▃██▇▄▄▄▄▃▄▄▄▄▅▅▅▄▄▄▄</td></tr><tr><td>mape</td><td>▄▂▃▂▃▂▅▅▃▃▃▁▃▂▄▆▃▅▆▆▄▄▃▃▂▃▆▆▅▂█▆▃▆▃▃▂▄▃▄</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▂▂▂▂▁▂▃▂▂▂▃▂▆█▅▅▃▃▂▂▂▂▃▂▃▄▄▃▃▂▂▂</td></tr><tr><td>val_mae</td><td>▁▁▂▁▂▂▁▁▂▂▂▂▂▂▄▃▂▂▃▃▅█▆▆▃▃▃▂▃▃▄▃▄▅▄▄▄▃▃▃</td></tr><tr><td>val_mape</td><td>▂▂▃▂▄▆▁▂▃▄▆▅▄▄▅▃▁▃▄▆▄█▅▄▃▂▁▁▆▂▃▄▇▇▃▂▄▃▃▁</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">worthy-sweep-3</strong>: <a href=\"https://wandb.ai/nbvanting/thesis/runs/8razd1gg\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/8razd1gg</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: t6qod9ri with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 37\n",
      "wandb: \tcnn_layer_size_1: 32\n",
      "wandb: \tcnn_layer_size_2: 181\n",
      "wandb: \tdropout: 0.4440781710876469\n",
      "wandb: \tepochs: 50\n",
      "wandb: \tgru_layer_size_1: 52\n",
      "wandb: \tgru_layer_size_2: 208\n",
      "wandb: \tlearning_rate: 0.07789108069018007\n",
      "wandb: \tlookback: 542\n",
      "wandb: \tmomentum: 0.95\n",
      "wandb: \tnum_cnn_layers: 2\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 1\n",
      "wandb: \toptimizer: rmsprop\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">dutiful-sweep-4</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/t6qod9ri\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/t6qod9ri</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_140023-t6qod9ri</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "399/399 [==============================] - 65s 153ms/step - loss: 21.5581 - mae: 3.5820 - mape: 3927.1816 - val_loss: 4.3164 - val_mae: 1.8980 - val_mape: 5787.4277\n",
      "Epoch 2/50\n",
      "399/399 [==============================] - 62s 156ms/step - loss: 3.3781 - mae: 1.4818 - mape: 1171.0088 - val_loss: 2.1336 - val_mae: 1.0202 - val_mape: 1178.6941\n",
      "Epoch 3/50\n",
      "399/399 [==============================] - 61s 152ms/step - loss: 2.1670 - mae: 1.1541 - mape: 923.8455 - val_loss: 2.5483 - val_mae: 1.1479 - val_mape: 1709.1880\n",
      "Epoch 4/50\n",
      "399/399 [==============================] - 63s 159ms/step - loss: 1.8279 - mae: 1.0594 - mape: 561.1759 - val_loss: 1.3949 - val_mae: 0.8816 - val_mape: 548.7462\n",
      "Epoch 5/50\n",
      "399/399 [==============================] - 61s 154ms/step - loss: 1.7014 - mae: 1.0194 - mape: 553.0189 - val_loss: 2.2728 - val_mae: 1.3563 - val_mape: 3810.8350\n",
      "Epoch 6/50\n",
      "399/399 [==============================] - 61s 152ms/step - loss: 1.6350 - mae: 1.0028 - mape: 656.4524 - val_loss: 1.8284 - val_mae: 0.9434 - val_mape: 702.7385\n",
      "Epoch 7/50\n",
      "399/399 [==============================] - 64s 161ms/step - loss: 1.6489 - mae: 0.9983 - mape: 624.5899 - val_loss: 1.6397 - val_mae: 1.1232 - val_mape: 2743.0208\n",
      "Epoch 8/50\n",
      "399/399 [==============================] - 63s 158ms/step - loss: 1.5513 - mae: 0.9741 - mape: 473.5932 - val_loss: 1.3892 - val_mae: 0.9943 - val_mape: 1970.6198\n",
      "Epoch 9/50\n",
      "399/399 [==============================] - 61s 152ms/step - loss: 1.5321 - mae: 0.9651 - mape: 481.7126 - val_loss: 2.1010 - val_mae: 1.0112 - val_mape: 1132.1649\n",
      "Epoch 10/50\n",
      "399/399 [==============================] - 60s 149ms/step - loss: 1.4795 - mae: 0.9466 - mape: 390.7201 - val_loss: 1.4828 - val_mae: 0.8860 - val_mape: 235.9131\n",
      "Epoch 11/50\n",
      "399/399 [==============================] - 63s 158ms/step - loss: 1.4191 - mae: 0.9292 - mape: 466.2811 - val_loss: 1.7725 - val_mae: 0.9324 - val_mape: 603.0839\n",
      "Epoch 12/50\n",
      "399/399 [==============================] - 66s 166ms/step - loss: 1.4505 - mae: 0.9338 - mape: 622.0946 - val_loss: 3.0964 - val_mae: 1.3389 - val_mape: 2295.3882\n",
      "Epoch 13/50\n",
      "399/399 [==============================] - 66s 165ms/step - loss: 1.4101 - mae: 0.9217 - mape: 465.3586 - val_loss: 1.8195 - val_mae: 0.9416 - val_mape: 687.2089\n",
      "Epoch 14/50\n",
      "399/399 [==============================] - 69s 173ms/step - loss: 1.4334 - mae: 0.9260 - mape: 487.4828 - val_loss: 1.6256 - val_mae: 0.9061 - val_mape: 310.9973\n",
      "Epoch 15/50\n",
      "399/399 [==============================] - 65s 163ms/step - loss: 1.4093 - mae: 0.9237 - mape: 573.2661 - val_loss: 1.5250 - val_mae: 0.8910 - val_mape: 120.9402\n",
      "Epoch 16/50\n",
      "399/399 [==============================] - 64s 161ms/step - loss: 1.4217 - mae: 0.9336 - mape: 454.1029 - val_loss: 2.1166 - val_mae: 1.0155 - val_mape: 1154.4623\n",
      "Epoch 17/50\n",
      "399/399 [==============================] - 64s 162ms/step - loss: 1.4582 - mae: 0.9358 - mape: 591.3978 - val_loss: 1.3936 - val_mae: 0.8816 - val_mape: 554.2089\n",
      "Epoch 18/50\n",
      "399/399 [==============================] - 69s 172ms/step - loss: 1.3981 - mae: 0.9159 - mape: 431.3535 - val_loss: 1.3184 - val_mae: 0.9009 - val_mape: 1111.6826\n",
      "Epoch 19/50\n",
      "399/399 [==============================] - 65s 162ms/step - loss: 1.3965 - mae: 0.9170 - mape: 435.4906 - val_loss: 1.6972 - val_mae: 0.9187 - val_mape: 459.7697\n",
      "Epoch 20/50\n",
      "399/399 [==============================] - 69s 172ms/step - loss: 1.4267 - mae: 0.9339 - mape: 419.7536 - val_loss: 1.3879 - val_mae: 0.9934 - val_mape: 1964.2505\n",
      "Epoch 21/50\n",
      "399/399 [==============================] - 68s 172ms/step - loss: 1.4116 - mae: 0.9268 - mape: 470.6908 - val_loss: 1.3154 - val_mae: 0.9192 - val_mape: 1334.0629\n",
      "Epoch 22/50\n",
      "399/399 [==============================] - 74s 185ms/step - loss: 1.3988 - mae: 0.9151 - mape: 359.4026 - val_loss: 1.3974 - val_mae: 0.8816 - val_mape: 537.5306\n",
      "Epoch 23/50\n",
      "399/399 [==============================] - 68s 170ms/step - loss: 1.3496 - mae: 0.8996 - mape: 337.9371 - val_loss: 1.8428 - val_mae: 0.9464 - val_mape: 727.5544\n",
      "Epoch 24/50\n",
      "311/399 [======================>.......] - ETA: 13s - loss: 1.3966 - mae: 0.9197 - mape: 486.5187"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4964<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_140023-t6qod9ri\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_140023-t6qod9ri\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>22</td></tr><tr><td>loss</td><td>1.31354</td></tr><tr><td>mae</td><td>0.89291</td></tr><tr><td>mape</td><td>348.57889</td></tr><tr><td>val_loss</td><td>1.8428</td></tr><tr><td>val_mae</td><td>0.94644</td></tr><tr><td>val_mape</td><td>727.55438</td></tr><tr><td>_runtime</td><td>1498</td></tr><tr><td>_timestamp</td><td>1620044721</td></tr><tr><td>_step</td><td>22</td></tr><tr><td>best_val_loss</td><td>1.31545</td></tr><tr><td>best_epoch</td><td>20</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mae</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mape</td><td>█▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▃▄▁▃▂▂▁▃▁▂▅▂▂▁▃▁▁▂▁▁▁▂</td></tr><tr><td>val_mae</td><td>█▂▃▁▄▁▃▂▂▁▁▄▁▁▁▂▁▁▁▂▁▁▁</td></tr><tr><td>val_mape</td><td>█▂▃▂▆▂▄▃▂▁▂▄▂▁▁▂▂▂▁▃▂▂▂</td></tr><tr><td>_runtime</td><td>▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>_step</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">dutiful-sweep-4</strong>: <a href=\"https://wandb.ai/nbvanting/thesis/runs/t6qod9ri\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/t6qod9ri</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: 48gzxqo2 with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 54\n",
      "wandb: \tcnn_layer_size_1: 49\n",
      "wandb: \tcnn_layer_size_2: 147\n",
      "wandb: \tdropout: 0.45363602986662555\n",
      "wandb: \tepochs: 50\n",
      "wandb: \tgru_layer_size_1: 144\n",
      "wandb: \tgru_layer_size_2: 52\n",
      "wandb: \tlearning_rate: 0.016630001680326734\n",
      "wandb: \tlookback: 300\n",
      "wandb: \tmomentum: 0.95\n",
      "wandb: \tnum_cnn_layers: 2\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 2\n",
      "wandb: \toptimizer: adam\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">crimson-sweep-5</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/48gzxqo2\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/48gzxqo2</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_142616-48gzxqo2</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "278/278 [==============================] - 52s 164ms/step - loss: 1.8931 - mae: 0.9696 - mape: 268.3515 - val_loss: 1.4547 - val_mae: 0.8807 - val_mape: 109.8010\n",
      "Epoch 2/50\n",
      "278/278 [==============================] - 43s 155ms/step - loss: 1.0264 - mae: 0.7879 - mape: 166.5707 - val_loss: 1.5063 - val_mae: 0.8882 - val_mape: 105.1137\n",
      "Epoch 3/50\n",
      "278/278 [==============================] - 40s 144ms/step - loss: 1.0023 - mae: 0.7788 - mape: 157.8813 - val_loss: 1.5355 - val_mae: 0.8929 - val_mape: 114.7806\n",
      "Epoch 4/50\n",
      "278/278 [==============================] - 41s 148ms/step - loss: 1.0119 - mae: 0.7789 - mape: 166.5847 - val_loss: 1.4757 - val_mae: 0.8836 - val_mape: 102.3072\n",
      "Epoch 5/50\n",
      "278/278 [==============================] - 41s 147ms/step - loss: 1.0194 - mae: 0.7845 - mape: 181.0987 - val_loss: 1.4224 - val_mae: 0.8769 - val_mape: 124.7365\n",
      "Epoch 6/50\n",
      "278/278 [==============================] - 41s 148ms/step - loss: 1.0139 - mae: 0.7821 - mape: 170.4851 - val_loss: 1.7184 - val_mae: 0.9271 - val_mape: 179.8709\n",
      "Epoch 7/50\n",
      "278/278 [==============================] - 42s 149ms/step - loss: 1.0243 - mae: 0.7852 - mape: 202.7253 - val_loss: 1.3938 - val_mae: 0.8745 - val_mape: 141.1676\n",
      "Epoch 8/50\n",
      "278/278 [==============================] - 42s 153ms/step - loss: 1.0189 - mae: 0.7833 - mape: 158.8150 - val_loss: 1.5144 - val_mae: 0.8895 - val_mape: 107.6544\n",
      "Epoch 9/50\n",
      "278/278 [==============================] - 40s 145ms/step - loss: 1.0166 - mae: 0.7826 - mape: 193.1690 - val_loss: 1.4539 - val_mae: 0.8806 - val_mape: 110.1358\n",
      "Epoch 10/50\n",
      "278/278 [==============================] - 43s 153ms/step - loss: 1.0205 - mae: 0.7831 - mape: 168.5766 - val_loss: 1.4430 - val_mae: 0.8792 - val_mape: 114.6791\n",
      "Epoch 11/50\n",
      "278/278 [==============================] - 42s 149ms/step - loss: 1.0167 - mae: 0.7829 - mape: 181.8539 - val_loss: 1.8280 - val_mae: 0.9518 - val_mape: 217.1440\n",
      "Epoch 12/50\n",
      "278/278 [==============================] - 42s 150ms/step - loss: 1.0379 - mae: 0.7930 - mape: 192.9040 - val_loss: 1.3804 - val_mae: 0.8737 - val_mape: 149.8428\n",
      "Epoch 13/50\n",
      "278/278 [==============================] - 44s 158ms/step - loss: 1.0218 - mae: 0.7863 - mape: 150.3696 - val_loss: 1.6747 - val_mae: 0.9183 - val_mape: 164.6629\n",
      "Epoch 14/50\n",
      "278/278 [==============================] - 43s 155ms/step - loss: 1.0357 - mae: 0.7900 - mape: 186.4701 - val_loss: 1.5190 - val_mae: 0.8902 - val_mape: 109.1543\n",
      "Epoch 15/50\n",
      "278/278 [==============================] - 42s 152ms/step - loss: 1.0179 - mae: 0.7837 - mape: 172.4434 - val_loss: 1.6168 - val_mae: 0.9072 - val_mape: 144.1010\n",
      "Epoch 16/50\n",
      "278/278 [==============================] - 45s 161ms/step - loss: 1.0147 - mae: 0.7806 - mape: 149.6013 - val_loss: 1.5565 - val_mae: 0.8964 - val_mape: 122.2743\n",
      "Epoch 17/50\n",
      "278/278 [==============================] - 42s 150ms/step - loss: 1.0154 - mae: 0.7821 - mape: 157.6740 - val_loss: 1.4272 - val_mae: 0.8774 - val_mape: 122.2547\n",
      "Epoch 18/50\n",
      "278/278 [==============================] - 40s 143ms/step - loss: 1.0137 - mae: 0.7830 - mape: 152.0527 - val_loss: 1.5796 - val_mae: 0.9005 - val_mape: 130.6595\n",
      "Epoch 19/50\n",
      "278/278 [==============================] - 40s 142ms/step - loss: 1.0241 - mae: 0.7864 - mape: 167.2602 - val_loss: 1.7594 - val_mae: 0.9359 - val_mape: 193.9559\n",
      "Epoch 20/50\n",
      "278/278 [==============================] - 40s 142ms/step - loss: 1.0224 - mae: 0.7865 - mape: 171.8657 - val_loss: 1.4087 - val_mae: 0.8757 - val_mape: 132.2727\n",
      "Epoch 21/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 1.0232 - mae: 0.7852 - mape: 163.9218"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 35788<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_142616-48gzxqo2\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_142616-48gzxqo2\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>1.02648</td></tr><tr><td>mae</td><td>0.78602</td></tr><tr><td>mape</td><td>178.83694</td></tr><tr><td>val_loss</td><td>1.40873</td></tr><tr><td>val_mae</td><td>0.87567</td></tr><tr><td>val_mape</td><td>132.27267</td></tr><tr><td>_runtime</td><td>850</td></tr><tr><td>_timestamp</td><td>1620045626</td></tr><tr><td>_step</td><td>19</td></tr><tr><td>best_val_loss</td><td>1.38037</td></tr><tr><td>best_epoch</td><td>11</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>mae</td><td>█▂▂▁▂▂▂▂▂▁▂▃▂▂▁▁▂▁▂▂</td></tr><tr><td>mape</td><td>▅▂▃▄▄▅█▃▆▄▆▇▂▄▅▂▄▁▅▃</td></tr><tr><td>val_loss</td><td>▂▃▃▂▂▆▁▃▂▂█▁▆▃▅▄▂▄▇▁</td></tr><tr><td>val_mae</td><td>▂▂▃▂▁▆▁▂▂▁█▁▅▂▄▃▁▃▇▁</td></tr><tr><td>val_mape</td><td>▁▁▂▁▂▆▃▁▁▂█▄▅▁▄▂▂▃▇▃</td></tr><tr><td>_runtime</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>_step</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">crimson-sweep-5</strong>: <a href=\"https://wandb.ai/nbvanting/thesis/runs/48gzxqo2\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/48gzxqo2</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: qlmq5an2 with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 133\n",
      "wandb: \tcnn_layer_size_1: 233\n",
      "wandb: \tcnn_layer_size_2: 44\n",
      "wandb: \tdropout: 0.24295156749592733\n",
      "wandb: \tepochs: 50\n",
      "wandb: \tgru_layer_size_1: 94\n",
      "wandb: \tgru_layer_size_2: 106\n",
      "wandb: \tlearning_rate: 0.0489416542430523\n",
      "wandb: \tlookback: 569\n",
      "wandb: \tmomentum: 0.95\n",
      "wandb: \tnum_cnn_layers: 1\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 1\n",
      "wandb: \toptimizer: sgd\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">honest-sweep-6</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/qlmq5an2\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/qlmq5an2</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_144110-qlmq5an2</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "111/111 [==============================] - 94s 802ms/step - loss: 0.7218 - mae: 0.6581 - mape: 402.6249 - val_loss: 0.5642 - val_mae: 0.6034 - val_mape: 268.9284\n",
      "Epoch 2/50\n",
      "111/111 [==============================] - 90s 809ms/step - loss: 0.3313 - mae: 0.4440 - mape: 429.1275 - val_loss: 0.2116 - val_mae: 0.3686 - val_mape: 231.7255\n",
      "Epoch 3/50\n",
      "111/111 [==============================] - 89s 803ms/step - loss: 0.1843 - mae: 0.3305 - mape: 248.4228 - val_loss: 0.2686 - val_mae: 0.4312 - val_mape: 262.7609\n",
      "Epoch 4/50\n",
      "111/111 [==============================] - 90s 810ms/step - loss: 0.1584 - mae: 0.3086 - mape: 210.0589 - val_loss: 0.2225 - val_mae: 0.3918 - val_mape: 258.3604\n",
      "Epoch 5/50\n",
      "111/111 [==============================] - 88s 792ms/step - loss: 0.1378 - mae: 0.2880 - mape: 267.0298 - val_loss: 0.1525 - val_mae: 0.3137 - val_mape: 176.2404\n",
      "Epoch 6/50\n",
      "111/111 [==============================] - 89s 804ms/step - loss: 0.1253 - mae: 0.2736 - mape: 280.8017 - val_loss: 0.1534 - val_mae: 0.3169 - val_mape: 211.5447\n",
      "Epoch 7/50\n",
      "111/111 [==============================] - 92s 833ms/step - loss: 0.1210 - mae: 0.2707 - mape: 209.0341 - val_loss: 0.1483 - val_mae: 0.3115 - val_mape: 191.6492\n",
      "Epoch 8/50\n",
      "111/111 [==============================] - 89s 803ms/step - loss: 0.1126 - mae: 0.2604 - mape: 219.9472 - val_loss: 0.1468 - val_mae: 0.3036 - val_mape: 201.2390\n",
      "Epoch 9/50\n",
      "111/111 [==============================] - 95s 857ms/step - loss: 0.1122 - mae: 0.2603 - mape: 251.6061 - val_loss: 0.1811 - val_mae: 0.3451 - val_mape: 232.7298\n",
      "Epoch 10/50\n",
      "111/111 [==============================] - 91s 817ms/step - loss: 0.1087 - mae: 0.2555 - mape: 235.5304 - val_loss: 0.1221 - val_mae: 0.2681 - val_mape: 144.3105\n",
      "Epoch 11/50\n",
      "111/111 [==============================] - 87s 782ms/step - loss: 0.1123 - mae: 0.2595 - mape: 276.2916 - val_loss: 0.1531 - val_mae: 0.3157 - val_mape: 203.8402\n",
      "Epoch 12/50\n",
      "111/111 [==============================] - 89s 800ms/step - loss: 0.1039 - mae: 0.2492 - mape: 244.7326 - val_loss: 0.1364 - val_mae: 0.2976 - val_mape: 151.6094\n",
      "Epoch 13/50\n",
      "111/111 [==============================] - 87s 786ms/step - loss: 0.0996 - mae: 0.2437 - mape: 307.4932 - val_loss: 0.1437 - val_mae: 0.3034 - val_mape: 201.7216\n",
      "Epoch 14/50\n",
      "111/111 [==============================] - 89s 798ms/step - loss: 0.0940 - mae: 0.2380 - mape: 274.6911 - val_loss: 0.1604 - val_mae: 0.3276 - val_mape: 171.0502\n",
      "Epoch 15/50\n",
      "111/111 [==============================] - 87s 786ms/step - loss: 0.0975 - mae: 0.2430 - mape: 194.2611 - val_loss: 0.1188 - val_mae: 0.2687 - val_mape: 128.6418\n",
      "Epoch 16/50\n",
      "111/111 [==============================] - 89s 804ms/step - loss: 0.0890 - mae: 0.2319 - mape: 265.8266 - val_loss: 0.1143 - val_mae: 0.2674 - val_mape: 122.0266\n",
      "Epoch 17/50\n",
      "111/111 [==============================] - 89s 798ms/step - loss: 0.0883 - mae: 0.2301 - mape: 198.1488 - val_loss: 0.1341 - val_mae: 0.2943 - val_mape: 210.3321\n",
      "Epoch 18/50\n",
      "111/111 [==============================] - 87s 787ms/step - loss: 0.0909 - mae: 0.2340 - mape: 255.1232 - val_loss: 0.1476 - val_mae: 0.3075 - val_mape: 190.9702\n",
      "Epoch 19/50\n",
      "111/111 [==============================] - 89s 800ms/step - loss: 0.0895 - mae: 0.2326 - mape: 236.4618 - val_loss: 0.1729 - val_mae: 0.3353 - val_mape: 157.0348\n",
      "Epoch 20/50\n",
      "111/111 [==============================] - 89s 801ms/step - loss: 0.0880 - mae: 0.2297 - mape: 196.0335 - val_loss: 0.1258 - val_mae: 0.2832 - val_mape: 171.9046\n",
      "Epoch 21/50\n",
      "111/111 [==============================] - 89s 800ms/step - loss: 0.0843 - mae: 0.2257 - mape: 226.3605 - val_loss: 0.1741 - val_mae: 0.3431 - val_mape: 208.2996\n",
      "Epoch 22/50\n",
      "111/111 [==============================] - 90s 810ms/step - loss: 0.0867 - mae: 0.2316 - mape: 236.1413 - val_loss: 0.1154 - val_mae: 0.2606 - val_mape: 147.2128\n",
      "Epoch 23/50\n",
      "111/111 [==============================] - 89s 804ms/step - loss: 0.0841 - mae: 0.2243 - mape: 219.7194 - val_loss: 0.1458 - val_mae: 0.3021 - val_mape: 118.9531\n",
      "Epoch 24/50\n",
      "111/111 [==============================] - 91s 816ms/step - loss: 0.0924 - mae: 0.2346 - mape: 240.5322 - val_loss: 0.1210 - val_mae: 0.2701 - val_mape: 121.2158\n",
      "Epoch 25/50\n",
      "111/111 [==============================] - 89s 799ms/step - loss: 0.0807 - mae: 0.2190 - mape: 194.0909 - val_loss: 0.1601 - val_mae: 0.3281 - val_mape: 185.1369\n",
      "Epoch 26/50\n",
      "111/111 [==============================] - 94s 850ms/step - loss: 0.0787 - mae: 0.2175 - mape: 227.0464 - val_loss: 0.1383 - val_mae: 0.2976 - val_mape: 198.7062\n",
      "Epoch 27/50\n",
      "111/111 [==============================] - 91s 815ms/step - loss: 0.0762 - mae: 0.2149 - mape: 156.5905 - val_loss: 0.1543 - val_mae: 0.3169 - val_mape: 170.3606\n",
      "Epoch 28/50\n",
      "111/111 [==============================] - 88s 794ms/step - loss: 0.0789 - mae: 0.2186 - mape: 215.5353 - val_loss: 0.1205 - val_mae: 0.2699 - val_mape: 159.3089\n",
      "Epoch 29/50\n",
      "111/111 [==============================] - 88s 791ms/step - loss: 0.0793 - mae: 0.2186 - mape: 170.9392 - val_loss: 0.1538 - val_mae: 0.3123 - val_mape: 166.3640\n",
      "Epoch 30/50\n",
      "111/111 [==============================] - 87s 779ms/step - loss: 0.0761 - mae: 0.2139 - mape: 194.9016 - val_loss: 0.1608 - val_mae: 0.3239 - val_mape: 202.6535\n",
      "Epoch 31/50\n",
      "111/111 [==============================] - 92s 825ms/step - loss: 0.0760 - mae: 0.2152 - mape: 237.5535 - val_loss: 0.1269 - val_mae: 0.2886 - val_mape: 181.6252\n",
      "Epoch 32/50\n",
      "111/111 [==============================] - 87s 786ms/step - loss: 0.0753 - mae: 0.2125 - mape: 225.9733 - val_loss: 0.1452 - val_mae: 0.3076 - val_mape: 201.3749\n",
      "Epoch 33/50\n",
      "111/111 [==============================] - 85s 765ms/step - loss: 0.0769 - mae: 0.2150 - mape: 225.2580 - val_loss: 0.1660 - val_mae: 0.3241 - val_mape: 161.3792\n",
      "Epoch 34/50\n",
      "111/111 [==============================] - 81s 730ms/step - loss: 0.0759 - mae: 0.2143 - mape: 266.7030 - val_loss: 0.1129 - val_mae: 0.2659 - val_mape: 147.7960\n",
      "Epoch 35/50\n",
      "111/111 [==============================] - 81s 732ms/step - loss: 0.0683 - mae: 0.2039 - mape: 182.6183 - val_loss: 0.1207 - val_mae: 0.2794 - val_mape: 175.4766\n",
      "Epoch 36/50\n",
      "111/111 [==============================] - 81s 729ms/step - loss: 0.0712 - mae: 0.2088 - mape: 230.4074 - val_loss: 0.1416 - val_mae: 0.2968 - val_mape: 194.3665\n",
      "Epoch 37/50\n",
      "111/111 [==============================] - 81s 729ms/step - loss: 0.0709 - mae: 0.2071 - mape: 297.7746 - val_loss: 0.1281 - val_mae: 0.2889 - val_mape: 187.0133\n",
      "Epoch 38/50\n",
      "111/111 [==============================] - 81s 730ms/step - loss: 0.0700 - mae: 0.2048 - mape: 224.3366 - val_loss: 0.1374 - val_mae: 0.2874 - val_mape: 180.7857\n",
      "Epoch 39/50\n",
      "111/111 [==============================] - 81s 731ms/step - loss: 0.0661 - mae: 0.2000 - mape: 231.3951 - val_loss: 0.1332 - val_mae: 0.2963 - val_mape: 178.5959\n",
      "Epoch 40/50\n",
      "111/111 [==============================] - 81s 725ms/step - loss: 0.0658 - mae: 0.2003 - mape: 198.4787 - val_loss: 0.1127 - val_mae: 0.2601 - val_mape: 145.9401\n",
      "Epoch 41/50\n",
      "111/111 [==============================] - 81s 726ms/step - loss: 0.0671 - mae: 0.2025 - mape: 207.8017 - val_loss: 0.1427 - val_mae: 0.3019 - val_mape: 227.6574\n",
      "Epoch 42/50\n",
      "111/111 [==============================] - 81s 733ms/step - loss: 0.0688 - mae: 0.2044 - mape: 191.1843 - val_loss: 0.1229 - val_mae: 0.2791 - val_mape: 147.1565\n",
      "Epoch 43/50\n",
      "111/111 [==============================] - 81s 725ms/step - loss: 0.0668 - mae: 0.2016 - mape: 261.9771 - val_loss: 0.1167 - val_mae: 0.2678 - val_mape: 144.1980\n",
      "Epoch 44/50\n",
      "111/111 [==============================] - 81s 725ms/step - loss: 0.0683 - mae: 0.2039 - mape: 260.0439 - val_loss: 0.1217 - val_mae: 0.2792 - val_mape: 157.6530\n",
      "Epoch 45/50\n",
      "111/111 [==============================] - 81s 726ms/step - loss: 0.0619 - mae: 0.1947 - mape: 261.6895 - val_loss: 0.1329 - val_mae: 0.2884 - val_mape: 167.9142\n",
      "Epoch 46/50\n",
      "111/111 [==============================] - 81s 726ms/step - loss: 0.0638 - mae: 0.1977 - mape: 226.4335 - val_loss: 0.1304 - val_mae: 0.2808 - val_mape: 163.2700\n",
      "Epoch 47/50\n",
      "111/111 [==============================] - 81s 726ms/step - loss: 0.0651 - mae: 0.1984 - mape: 210.7495 - val_loss: 0.1236 - val_mae: 0.2721 - val_mape: 169.4107\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 81s 727ms/step - loss: 0.0609 - mae: 0.1920 - mape: 167.7071 - val_loss: 0.1526 - val_mae: 0.3111 - val_mape: 214.6399\n",
      "Epoch 49/50\n",
      "111/111 [==============================] - 81s 726ms/step - loss: 0.0622 - mae: 0.1939 - mape: 177.5846 - val_loss: 0.1158 - val_mae: 0.2639 - val_mape: 148.4326\n",
      "Epoch 50/50\n",
      "111/111 [==============================] - 80s 725ms/step - loss: 0.0569 - mae: 0.1856 - mape: 260.7002 - val_loss: 0.1444 - val_mae: 0.3015 - val_mape: 182.5918\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 23944<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_144110-qlmq5an2\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_144110-qlmq5an2\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>49</td></tr><tr><td>loss</td><td>0.05751</td></tr><tr><td>mae</td><td>0.18615</td></tr><tr><td>mape</td><td>237.56248</td></tr><tr><td>val_loss</td><td>0.14438</td></tr><tr><td>val_mae</td><td>0.3015</td></tr><tr><td>val_mape</td><td>182.5918</td></tr><tr><td>_runtime</td><td>4329</td></tr><tr><td>_timestamp</td><td>1620049999</td></tr><tr><td>_step</td><td>49</td></tr><tr><td>best_val_loss</td><td>0.11269</td></tr><tr><td>best_epoch</td><td>39</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▄▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mae</td><td>█▅▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mape</td><td>█▇▃▃▄▂▃▄▄▄▄▄▄▂▃▃▃▃▂▃▃▁▃▂▄▃▃▄▃▄▂▃▃▂▃▃▃▂▁▄</td></tr><tr><td>val_loss</td><td>█▃▃▃▂▂▂▂▂▁▁▂▁▁▂▂▂▁▂▁▁▂▁▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▂▁</td></tr><tr><td>val_mae</td><td>█▃▄▄▂▂▂▃▂▂▂▂▁▂▂▃▃▁▂▁▂▂▁▂▂▂▂▁▂▂▂▂▂▁▁▁▁▁▂▂</td></tr><tr><td>val_mape</td><td>█▆██▅▄▅▆▅▃▅▃▁▅▄▃▅▂▁▁▅▃▃▃▄▅▃▂▅▄▄▄▆▂▂▃▃▃▅▄</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">honest-sweep-6</strong>: <a href=\"https://wandb.ai/nbvanting/thesis/runs/qlmq5an2\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/qlmq5an2</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: pza99qh9 with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 225\n",
      "wandb: \tcnn_layer_size_1: 211\n",
      "wandb: \tcnn_layer_size_2: 157\n",
      "wandb: \tdropout: 0.4757026996014911\n",
      "wandb: \tepochs: 50\n",
      "wandb: \tgru_layer_size_1: 228\n",
      "wandb: \tgru_layer_size_2: 56\n",
      "wandb: \tlearning_rate: 0.03638779782590248\n",
      "wandb: \tlookback: 500\n",
      "wandb: \tmomentum: 0.95\n",
      "wandb: \tnum_cnn_layers: 2\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 2\n",
      "wandb: \toptimizer: sgd\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">dry-sweep-7</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/pza99qh9\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/pza99qh9</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_155324-pza99qh9</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "66/66 [==============================] - 114s 2s/step - loss: 0.8144 - mae: 0.7080 - mape: 306.1196 - val_loss: 1.3728 - val_mae: 0.9954 - val_mape: 486.3775\n",
      "Epoch 2/50\n",
      "66/66 [==============================] - 96s 1s/step - loss: 0.7758 - mae: 0.7017 - mape: 365.9320 - val_loss: 1.1839 - val_mae: 0.9036 - val_mape: 367.1230\n",
      "Epoch 3/50\n",
      "66/66 [==============================] - 99s 1s/step - loss: 0.6260 - mae: 0.6224 - mape: 330.8493 - val_loss: 0.3618 - val_mae: 0.4657 - val_mape: 247.1225\n",
      "Epoch 4/50\n",
      "66/66 [==============================] - 97s 1s/step - loss: 0.2802 - mae: 0.4115 - mape: 253.2418 - val_loss: 0.2174 - val_mae: 0.3790 - val_mape: 181.9884\n",
      "Epoch 5/50\n",
      "66/66 [==============================] - 94s 1s/step - loss: 0.1663 - mae: 0.3150 - mape: 214.5869 - val_loss: 0.1611 - val_mae: 0.3285 - val_mape: 151.2149\n",
      "Epoch 6/50\n",
      "66/66 [==============================] - 95s 1s/step - loss: 0.1430 - mae: 0.2920 - mape: 191.9240 - val_loss: 0.1602 - val_mae: 0.3292 - val_mape: 188.8456\n",
      "Epoch 7/50\n",
      "66/66 [==============================] - 94s 1s/step - loss: 0.1315 - mae: 0.2780 - mape: 206.6221 - val_loss: 0.1589 - val_mae: 0.3284 - val_mape: 190.1677\n",
      "Epoch 8/50\n",
      "66/66 [==============================] - 96s 1s/step - loss: 0.1225 - mae: 0.2683 - mape: 175.7252 - val_loss: 0.1310 - val_mae: 0.2928 - val_mape: 153.4808\n",
      "Epoch 9/50\n",
      "66/66 [==============================] - 94s 1s/step - loss: 0.1211 - mae: 0.2684 - mape: 205.1948 - val_loss: 0.1467 - val_mae: 0.3164 - val_mape: 161.3127\n",
      "Epoch 10/50\n",
      "66/66 [==============================] - 95s 1s/step - loss: 0.1141 - mae: 0.2607 - mape: 188.9170 - val_loss: 0.1252 - val_mae: 0.2857 - val_mape: 143.8764\n",
      "Epoch 11/50\n",
      "66/66 [==============================] - 95s 1s/step - loss: 0.1245 - mae: 0.2704 - mape: 168.4501 - val_loss: 0.1440 - val_mae: 0.3076 - val_mape: 185.4951\n",
      "Epoch 12/50\n",
      "66/66 [==============================] - 96s 1s/step - loss: 0.1085 - mae: 0.2537 - mape: 159.0448 - val_loss: 0.1187 - val_mae: 0.2754 - val_mape: 134.3155\n",
      "Epoch 13/50\n",
      "66/66 [==============================] - 93s 1s/step - loss: 0.1127 - mae: 0.2598 - mape: 157.4322 - val_loss: 0.1261 - val_mae: 0.2911 - val_mape: 182.9011\n",
      "Epoch 14/50\n",
      "66/66 [==============================] - 93s 1s/step - loss: 0.1059 - mae: 0.2505 - mape: 176.2766 - val_loss: 0.1595 - val_mae: 0.3250 - val_mape: 172.2758\n",
      "Epoch 15/50\n",
      "66/66 [==============================] - 95s 1s/step - loss: 0.1034 - mae: 0.2472 - mape: 170.7169 - val_loss: 0.1096 - val_mae: 0.2608 - val_mape: 135.0445\n",
      "Epoch 16/50\n",
      "66/66 [==============================] - 91s 1s/step - loss: 0.1057 - mae: 0.2494 - mape: 154.0058 - val_loss: 0.1503 - val_mae: 0.3263 - val_mape: 166.6766\n",
      "Epoch 17/50\n",
      "66/66 [==============================] - 95s 1s/step - loss: 0.0969 - mae: 0.2398 - mape: 168.4548 - val_loss: 0.1199 - val_mae: 0.2801 - val_mape: 134.5978\n",
      "Epoch 18/50\n",
      "66/66 [==============================] - 97s 1s/step - loss: 0.0989 - mae: 0.2400 - mape: 195.0119 - val_loss: 0.1368 - val_mae: 0.2942 - val_mape: 170.5121\n",
      "Epoch 19/50\n",
      "66/66 [==============================] - 95s 1s/step - loss: 0.0963 - mae: 0.2360 - mape: 190.2896 - val_loss: 0.1262 - val_mae: 0.2713 - val_mape: 150.9953\n",
      "Epoch 20/50\n",
      "66/66 [==============================] - 96s 1s/step - loss: 0.0932 - mae: 0.2334 - mape: 144.7404 - val_loss: 0.1202 - val_mae: 0.2793 - val_mape: 165.8273\n",
      "Epoch 21/50\n",
      "66/66 [==============================] - 95s 1s/step - loss: 0.0862 - mae: 0.2248 - mape: 138.3959 - val_loss: 0.1363 - val_mae: 0.3048 - val_mape: 199.0381\n",
      "Epoch 22/50\n",
      "66/66 [==============================] - 97s 1s/step - loss: 0.0850 - mae: 0.2245 - mape: 165.6213 - val_loss: 0.1129 - val_mae: 0.2652 - val_mape: 138.7345\n",
      "Epoch 23/50\n",
      "66/66 [==============================] - 93s 1s/step - loss: 0.0871 - mae: 0.2266 - mape: 143.8099 - val_loss: 0.1376 - val_mae: 0.3034 - val_mape: 189.2810\n",
      "Epoch 24/50\n",
      "66/66 [==============================] - 95s 1s/step - loss: 0.0833 - mae: 0.2203 - mape: 157.7763 - val_loss: 0.1181 - val_mae: 0.2714 - val_mape: 180.0559\n",
      "Epoch 25/50\n",
      "66/66 [==============================] - 93s 1s/step - loss: 0.0897 - mae: 0.2290 - mape: 140.1164 - val_loss: 0.1218 - val_mae: 0.2763 - val_mape: 170.1200\n",
      "Epoch 26/50\n",
      "66/66 [==============================] - 95s 1s/step - loss: 0.0870 - mae: 0.2239 - mape: 138.5156 - val_loss: 0.1229 - val_mae: 0.2749 - val_mape: 151.8109\n",
      "Epoch 27/50\n",
      "66/66 [==============================] - 90s 1s/step - loss: 0.0849 - mae: 0.2222 - mape: 179.9983 - val_loss: 0.1175 - val_mae: 0.2718 - val_mape: 148.9099\n",
      "Epoch 28/50\n",
      "66/66 [==============================] - 96s 1s/step - loss: 0.0789 - mae: 0.2130 - mape: 129.1483 - val_loss: 0.1113 - val_mae: 0.2618 - val_mape: 168.7662\n",
      "Epoch 29/50\n",
      "66/66 [==============================] - 93s 1s/step - loss: 0.0852 - mae: 0.2228 - mape: 159.8489 - val_loss: 0.1194 - val_mae: 0.2776 - val_mape: 179.6925\n",
      "Epoch 30/50\n",
      "66/66 [==============================] - 95s 1s/step - loss: 0.0904 - mae: 0.2314 - mape: 146.6070 - val_loss: 0.1615 - val_mae: 0.3239 - val_mape: 170.6810\n",
      "Epoch 31/50\n",
      "66/66 [==============================] - 92s 1s/step - loss: 0.0779 - mae: 0.2137 - mape: 122.3926 - val_loss: 0.1567 - val_mae: 0.3243 - val_mape: 184.4055\n",
      "Epoch 32/50\n",
      "66/66 [==============================] - 98s 1s/step - loss: 0.0775 - mae: 0.2131 - mape: 135.8898 - val_loss: 0.1672 - val_mae: 0.3356 - val_mape: 176.2220\n",
      "Epoch 33/50\n",
      "66/66 [==============================] - 104s 2s/step - loss: 0.0786 - mae: 0.2159 - mape: 183.3194 - val_loss: 0.1353 - val_mae: 0.2867 - val_mape: 182.7028\n",
      "Epoch 34/50\n",
      "66/66 [==============================] - 102s 2s/step - loss: 0.0753 - mae: 0.2098 - mape: 143.2256 - val_loss: 0.1227 - val_mae: 0.2804 - val_mape: 165.9017\n",
      "Epoch 35/50\n",
      "66/66 [==============================] - 102s 2s/step - loss: 0.0732 - mae: 0.2085 - mape: 132.5315 - val_loss: 0.1530 - val_mae: 0.3085 - val_mape: 163.6206\n",
      "Epoch 36/50\n",
      "66/66 [==============================] - 97s 1s/step - loss: 0.0757 - mae: 0.2094 - mape: 151.3400 - val_loss: 0.1366 - val_mae: 0.2988 - val_mape: 165.1856\n",
      "Epoch 37/50\n",
      "66/66 [==============================] - 102s 2s/step - loss: 0.0723 - mae: 0.2029 - mape: 128.4251 - val_loss: 0.1292 - val_mae: 0.2824 - val_mape: 137.4259\n",
      "Epoch 38/50\n",
      "66/66 [==============================] - 100s 2s/step - loss: 0.0722 - mae: 0.2049 - mape: 133.5888 - val_loss: 0.1279 - val_mae: 0.2799 - val_mape: 150.7992\n",
      "Epoch 39/50\n",
      "66/66 [==============================] - 98s 1s/step - loss: 0.0687 - mae: 0.2002 - mape: 135.4903 - val_loss: 0.1288 - val_mae: 0.2850 - val_mape: 168.5908\n",
      "Epoch 40/50\n",
      "66/66 [==============================] - 99s 1s/step - loss: 0.0735 - mae: 0.2051 - mape: 113.7252 - val_loss: 0.1207 - val_mae: 0.2732 - val_mape: 171.6190\n",
      "Epoch 41/50\n",
      "66/66 [==============================] - 98s 1s/step - loss: 0.0675 - mae: 0.1984 - mape: 121.5756 - val_loss: 0.1228 - val_mae: 0.2771 - val_mape: 166.3771\n",
      "Epoch 42/50\n",
      "66/66 [==============================] - 101s 2s/step - loss: 0.0654 - mae: 0.1960 - mape: 137.0165 - val_loss: 0.1255 - val_mae: 0.2797 - val_mape: 160.9664\n",
      "Epoch 43/50\n",
      "66/66 [==============================] - 103s 2s/step - loss: 0.0676 - mae: 0.1974 - mape: 152.4917 - val_loss: 0.1484 - val_mae: 0.3040 - val_mape: 164.9221\n",
      "Epoch 44/50\n",
      "66/66 [==============================] - 99s 1s/step - loss: 0.0736 - mae: 0.2068 - mape: 123.7538 - val_loss: 0.1785 - val_mae: 0.3351 - val_mape: 188.4329\n",
      "Epoch 45/50\n",
      "66/66 [==============================] - 103s 2s/step - loss: 0.0706 - mae: 0.2005 - mape: 122.1715 - val_loss: 0.1310 - val_mae: 0.2823 - val_mape: 176.4144\n",
      "Epoch 46/50\n",
      "66/66 [==============================] - 104s 2s/step - loss: 0.0636 - mae: 0.1908 - mape: 117.8036 - val_loss: 0.1268 - val_mae: 0.2819 - val_mape: 185.0802\n",
      "Epoch 47/50\n",
      "66/66 [==============================] - 104s 2s/step - loss: 0.0624 - mae: 0.1893 - mape: 151.6334 - val_loss: 0.1352 - val_mae: 0.2906 - val_mape: 174.9323\n",
      "Epoch 48/50\n",
      "66/66 [==============================] - 105s 2s/step - loss: 0.0642 - mae: 0.1951 - mape: 134.4433 - val_loss: 0.1430 - val_mae: 0.2969 - val_mape: 156.2252\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 104s 2s/step - loss: 0.0703 - mae: 0.2017 - mape: 137.3866 - val_loss: 0.1268 - val_mae: 0.2785 - val_mape: 155.4462\n",
      "Epoch 50/50\n",
      "66/66 [==============================] - 100s 2s/step - loss: 0.0629 - mae: 0.1926 - mape: 125.2586 - val_loss: 0.1299 - val_mae: 0.2846 - val_mape: 203.0389\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 36392<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_155324-pza99qh9\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_155324-pza99qh9\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>49</td></tr><tr><td>loss</td><td>0.06211</td></tr><tr><td>mae</td><td>0.1903</td></tr><tr><td>mape</td><td>106.41327</td></tr><tr><td>val_loss</td><td>0.12988</td></tr><tr><td>val_mae</td><td>0.2846</td></tr><tr><td>val_mape</td><td>203.03889</td></tr><tr><td>_runtime</td><td>4883</td></tr><tr><td>_timestamp</td><td>1620054887</td></tr><tr><td>_step</td><td>49</td></tr><tr><td>best_val_loss</td><td>0.10962</td></tr><tr><td>best_epoch</td><td>14</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>██▅▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mae</td><td>██▆▄▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mape</td><td>▇█▇▅▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▂▁</td></tr><tr><td>val_loss</td><td>█▇▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_mae</td><td>█▇▃▂▂▂▁▂▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁</td></tr><tr><td>val_mape</td><td>█▆▃▂▂▂▁▂▂▁▂▂▂▁▂▁▂▁▂▂▁▁▂▂▂▂▂▂▂▁▁▂▂▂▂▂▂▂▁▂</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">dry-sweep-7</strong>: <a href=\"https://wandb.ai/nbvanting/thesis/runs/pza99qh9\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/pza99qh9</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: zfhffzho with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 79\n",
      "wandb: \tcnn_layer_size_1: 41\n",
      "wandb: \tcnn_layer_size_2: 49\n",
      "wandb: \tdropout: 0.2881730564496367\n",
      "wandb: \tepochs: 50\n",
      "wandb: \tgru_layer_size_1: 222\n",
      "wandb: \tgru_layer_size_2: 254\n",
      "wandb: \tlearning_rate: 0.040815253236972\n",
      "wandb: \tlookback: 225\n",
      "wandb: \tmomentum: 0.95\n",
      "wandb: \tnum_cnn_layers: 2\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 1\n",
      "wandb: \toptimizer: rmsprop\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">wobbly-sweep-8</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/zfhffzho\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/zfhffzho</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_171452-zfhffzho</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "191/191 [==============================] - 42s 193ms/step - loss: 26.0220 - mae: 4.2119 - mape: 3256.7400 - val_loss: 15.1219 - val_mae: 3.7248 - val_mape: 7466.7300\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 37s 196ms/step - loss: 7.7289 - mae: 2.4887 - mape: 2152.2890 - val_loss: 6.1130 - val_mae: 2.2646 - val_mape: 6177.7080\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 38s 199ms/step - loss: 5.2892 - mae: 2.0525 - mape: 1617.4234 - val_loss: 4.6452 - val_mae: 1.8432 - val_mape: 3138.3247\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 40s 209ms/step - loss: 4.5811 - mae: 1.7719 - mape: 1449.7352 - val_loss: 6.0460 - val_mae: 2.1905 - val_mape: 3937.1890\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 41s 217ms/step - loss: 4.9569 - mae: 1.9564 - mape: 1539.2770 - val_loss: 3.8159 - val_mae: 1.7679 - val_mape: 4793.8354\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 41s 215ms/step - loss: 5.0576 - mae: 1.9809 - mape: 1495.6307 - val_loss: 9.3511 - val_mae: 2.8467 - val_mape: 5446.6050\n",
      "Epoch 7/50\n",
      " 55/191 [=======>......................] - ETA: 27s - loss: 5.1399 - mae: 2.0132 - mape: 1821.7398"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 35636<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_171452-zfhffzho\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_171452-zfhffzho\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>5</td></tr><tr><td>loss</td><td>5.06161</td></tr><tr><td>mae</td><td>1.98202</td></tr><tr><td>mape</td><td>1321.82996</td></tr><tr><td>val_loss</td><td>9.35114</td></tr><tr><td>val_mae</td><td>2.84665</td></tr><tr><td>val_mape</td><td>5446.60498</td></tr><tr><td>_runtime</td><td>246</td></tr><tr><td>_timestamp</td><td>1620055138</td></tr><tr><td>_step</td><td>5</td></tr><tr><td>best_val_loss</td><td>3.81595</td></tr><tr><td>best_epoch</td><td>4</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▄▅▇█</td></tr><tr><td>loss</td><td>█▂▁▁▁▁</td></tr><tr><td>mae</td><td>█▂▁▁▁▁</td></tr><tr><td>mape</td><td>█▃▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▂▂▂▁▄</td></tr><tr><td>val_mae</td><td>█▃▁▃▁▅</td></tr><tr><td>val_mape</td><td>█▆▁▂▄▅</td></tr><tr><td>_runtime</td><td>▁▂▄▅▇█</td></tr><tr><td>_timestamp</td><td>▁▂▄▅▇█</td></tr><tr><td>_step</td><td>▁▂▄▅▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">wobbly-sweep-8</strong>: <a href=\"https://wandb.ai/nbvanting/thesis/runs/zfhffzho\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/zfhffzho</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: 9ac5xfsd with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 126\n",
      "wandb: \tcnn_layer_size_1: 37\n",
      "wandb: \tcnn_layer_size_2: 187\n",
      "wandb: \tdropout: 0.009393302344775645\n",
      "wandb: \tepochs: 50\n",
      "wandb: \tgru_layer_size_1: 127\n",
      "wandb: \tgru_layer_size_2: 205\n",
      "wandb: \tlearning_rate: 0.044024628023275544\n",
      "wandb: \tlookback: 666\n",
      "wandb: \tmomentum: 0.9\n",
      "wandb: \tnum_cnn_layers: 2\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 1\n",
      "wandb: \toptimizer: sgd\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">apricot-sweep-9</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/9ac5xfsd\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/9ac5xfsd</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_171915-9ac5xfsd</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "117/117 [==============================] - 104s 848ms/step - loss: 0.6807 - mae: 0.6432 - mape: 389.6943 - val_loss: 0.2142 - val_mae: 0.3693 - val_mape: 134.2088\n",
      "Epoch 2/50\n",
      "117/117 [==============================] - 85s 722ms/step - loss: 0.1623 - mae: 0.3101 - mape: 212.6897 - val_loss: 0.1389 - val_mae: 0.2937 - val_mape: 126.9131\n",
      "Epoch 3/50\n",
      "117/117 [==============================] - 84s 718ms/step - loss: 0.1093 - mae: 0.2532 - mape: 188.5748 - val_loss: 0.1383 - val_mae: 0.3024 - val_mape: 147.8172\n",
      "Epoch 4/50\n",
      "117/117 [==============================] - 86s 734ms/step - loss: 0.1025 - mae: 0.2475 - mape: 211.7731 - val_loss: 0.1251 - val_mae: 0.2845 - val_mape: 138.9978\n",
      "Epoch 5/50\n",
      "117/117 [==============================] - 85s 723ms/step - loss: 0.0922 - mae: 0.2326 - mape: 209.8805 - val_loss: 0.1113 - val_mae: 0.2671 - val_mape: 123.2643\n",
      "Epoch 6/50\n",
      "117/117 [==============================] - 84s 718ms/step - loss: 0.0856 - mae: 0.2254 - mape: 181.0188 - val_loss: 0.1279 - val_mae: 0.2927 - val_mape: 134.0417\n",
      "Epoch 7/50\n",
      "117/117 [==============================] - 86s 732ms/step - loss: 0.0829 - mae: 0.2210 - mape: 180.2177 - val_loss: 0.1085 - val_mae: 0.2647 - val_mape: 122.7115\n",
      "Epoch 8/50\n",
      "117/117 [==============================] - 86s 733ms/step - loss: 0.0764 - mae: 0.2131 - mape: 153.7004 - val_loss: 0.1183 - val_mae: 0.2791 - val_mape: 142.2861\n",
      "Epoch 9/50\n",
      "117/117 [==============================] - 85s 729ms/step - loss: 0.0815 - mae: 0.2196 - mape: 182.0113 - val_loss: 0.1059 - val_mae: 0.2612 - val_mape: 108.6350\n",
      "Epoch 10/50\n",
      "117/117 [==============================] - 84s 719ms/step - loss: 0.0727 - mae: 0.2074 - mape: 168.3204 - val_loss: 0.1291 - val_mae: 0.2980 - val_mape: 139.1717\n",
      "Epoch 11/50\n",
      "117/117 [==============================] - 85s 724ms/step - loss: 0.0715 - mae: 0.2055 - mape: 188.5081 - val_loss: 0.1121 - val_mae: 0.2717 - val_mape: 121.7055\n",
      "Epoch 12/50\n",
      "117/117 [==============================] - 76s 649ms/step - loss: 0.0705 - mae: 0.2034 - mape: 133.0867 - val_loss: 0.1132 - val_mae: 0.2725 - val_mape: 133.5941\n",
      "Epoch 13/50\n",
      "117/117 [==============================] - 75s 644ms/step - loss: 0.0706 - mae: 0.2044 - mape: 171.1089 - val_loss: 0.0988 - val_mae: 0.2502 - val_mape: 118.0823\n",
      "Epoch 14/50\n",
      "117/117 [==============================] - 75s 640ms/step - loss: 0.0643 - mae: 0.1948 - mape: 148.5999 - val_loss: 0.0934 - val_mae: 0.2420 - val_mape: 116.4532\n",
      "Epoch 15/50\n",
      "117/117 [==============================] - 77s 654ms/step - loss: 0.0604 - mae: 0.1886 - mape: 136.2129 - val_loss: 0.1278 - val_mae: 0.2897 - val_mape: 131.1646\n",
      "Epoch 16/50\n",
      "117/117 [==============================] - 75s 638ms/step - loss: 0.0584 - mae: 0.1854 - mape: 140.9754 - val_loss: 0.1038 - val_mae: 0.2574 - val_mape: 110.6338\n",
      "Epoch 17/50\n",
      "117/117 [==============================] - 75s 641ms/step - loss: 0.0587 - mae: 0.1864 - mape: 153.3567 - val_loss: 0.1013 - val_mae: 0.2507 - val_mape: 107.6386\n",
      "Epoch 18/50\n",
      "117/117 [==============================] - 75s 637ms/step - loss: 0.0554 - mae: 0.1799 - mape: 118.6787 - val_loss: 0.1118 - val_mae: 0.2690 - val_mape: 122.7074\n",
      "Epoch 19/50\n",
      "117/117 [==============================] - 75s 639ms/step - loss: 0.0531 - mae: 0.1770 - mape: 145.7429 - val_loss: 0.1053 - val_mae: 0.2546 - val_mape: 114.0282\n",
      "Epoch 20/50\n",
      "117/117 [==============================] - 75s 642ms/step - loss: 0.0516 - mae: 0.1747 - mape: 139.4114 - val_loss: 0.1310 - val_mae: 0.2935 - val_mape: 145.6411\n",
      "Epoch 21/50\n",
      "117/117 [==============================] - 75s 642ms/step - loss: 0.0544 - mae: 0.1772 - mape: 135.8510 - val_loss: 0.1143 - val_mae: 0.2637 - val_mape: 121.9510\n",
      "Epoch 22/50\n",
      "117/117 [==============================] - 75s 639ms/step - loss: 0.0504 - mae: 0.1730 - mape: 127.1586 - val_loss: 0.1064 - val_mae: 0.2620 - val_mape: 105.2812\n",
      "Epoch 23/50\n",
      "117/117 [==============================] - 75s 643ms/step - loss: 0.0545 - mae: 0.1789 - mape: 139.6360 - val_loss: 0.1048 - val_mae: 0.2591 - val_mape: 119.2580\n",
      "Epoch 24/50\n",
      "117/117 [==============================] - 75s 641ms/step - loss: 0.0444 - mae: 0.1622 - mape: 134.5387 - val_loss: 0.1172 - val_mae: 0.2656 - val_mape: 108.8093\n",
      "Epoch 25/50\n",
      "117/117 [==============================] - 75s 640ms/step - loss: 0.0459 - mae: 0.1647 - mape: 153.2593 - val_loss: 0.1086 - val_mae: 0.2608 - val_mape: 109.2454\n",
      "Epoch 26/50\n",
      "117/117 [==============================] - 75s 640ms/step - loss: 0.0437 - mae: 0.1607 - mape: 146.7390 - val_loss: 0.1000 - val_mae: 0.2466 - val_mape: 107.1289\n",
      "Epoch 27/50\n",
      "117/117 [==============================] - 75s 645ms/step - loss: 0.0416 - mae: 0.1571 - mape: 144.9268 - val_loss: 0.1063 - val_mae: 0.2555 - val_mape: 120.8799\n",
      "Epoch 28/50\n",
      "117/117 [==============================] - 75s 639ms/step - loss: 0.0413 - mae: 0.1566 - mape: 131.9448 - val_loss: 0.1090 - val_mae: 0.2592 - val_mape: 119.6755\n",
      "Epoch 29/50\n",
      "117/117 [==============================] - 75s 638ms/step - loss: 0.0409 - mae: 0.1558 - mape: 142.0336 - val_loss: 0.1213 - val_mae: 0.2730 - val_mape: 117.7258\n",
      "Epoch 30/50\n",
      "117/117 [==============================] - 75s 637ms/step - loss: 0.0353 - mae: 0.1458 - mape: 130.8578 - val_loss: 0.1229 - val_mae: 0.2756 - val_mape: 132.3046\n",
      "Epoch 31/50\n",
      "117/117 [==============================] - 75s 642ms/step - loss: 0.0387 - mae: 0.1524 - mape: 115.1971 - val_loss: 0.1178 - val_mae: 0.2661 - val_mape: 122.2027\n",
      "Epoch 32/50\n",
      "117/117 [==============================] - 75s 642ms/step - loss: 0.0374 - mae: 0.1486 - mape: 124.7912 - val_loss: 0.1233 - val_mae: 0.2788 - val_mape: 125.1300\n",
      "Epoch 33/50\n",
      "117/117 [==============================] - 75s 643ms/step - loss: 0.0347 - mae: 0.1444 - mape: 132.7087 - val_loss: 0.1387 - val_mae: 0.2844 - val_mape: 118.8608\n",
      "Epoch 34/50\n",
      "117/117 [==============================] - 75s 640ms/step - loss: 0.0362 - mae: 0.1470 - mape: 124.3824 - val_loss: 0.1209 - val_mae: 0.2766 - val_mape: 128.6127\n",
      "Epoch 35/50\n",
      "117/117 [==============================] - 75s 641ms/step - loss: 0.0316 - mae: 0.1383 - mape: 117.3094 - val_loss: 0.1336 - val_mae: 0.2810 - val_mape: 132.3306\n",
      "Epoch 36/50\n",
      "117/117 [==============================] - 75s 641ms/step - loss: 0.0324 - mae: 0.1397 - mape: 107.7347 - val_loss: 0.1318 - val_mae: 0.2773 - val_mape: 124.1914\n",
      "Epoch 37/50\n",
      "117/117 [==============================] - 75s 640ms/step - loss: 0.0320 - mae: 0.1390 - mape: 127.6622 - val_loss: 0.1191 - val_mae: 0.2656 - val_mape: 121.3553\n",
      "Epoch 38/50\n",
      "117/117 [==============================] - 75s 640ms/step - loss: 0.0285 - mae: 0.1320 - mape: 97.0059 - val_loss: 0.1276 - val_mae: 0.2740 - val_mape: 132.0870\n",
      "Epoch 39/50\n",
      "117/117 [==============================] - 75s 644ms/step - loss: 0.0291 - mae: 0.1325 - mape: 93.5443 - val_loss: 0.1182 - val_mae: 0.2617 - val_mape: 122.1189\n",
      "Epoch 40/50\n",
      "117/117 [==============================] - 75s 643ms/step - loss: 0.0260 - mae: 0.1258 - mape: 104.6702 - val_loss: 0.1191 - val_mae: 0.2635 - val_mape: 127.4308\n",
      "Epoch 41/50\n",
      "117/117 [==============================] - 75s 639ms/step - loss: 0.0269 - mae: 0.1281 - mape: 129.0561 - val_loss: 0.1358 - val_mae: 0.2824 - val_mape: 137.9566\n",
      "Epoch 42/50\n",
      "117/117 [==============================] - 75s 642ms/step - loss: 0.0253 - mae: 0.1243 - mape: 148.6980 - val_loss: 0.1264 - val_mae: 0.2706 - val_mape: 126.8767\n",
      "Epoch 43/50\n",
      "117/117 [==============================] - 75s 639ms/step - loss: 0.0252 - mae: 0.1235 - mape: 89.4338 - val_loss: 0.1337 - val_mae: 0.2915 - val_mape: 134.4315\n",
      "Epoch 44/50\n",
      "117/117 [==============================] - 75s 641ms/step - loss: 0.0260 - mae: 0.1256 - mape: 133.9193 - val_loss: 0.1235 - val_mae: 0.2691 - val_mape: 115.2915\n",
      "Epoch 45/50\n",
      "117/117 [==============================] - 75s 642ms/step - loss: 0.0242 - mae: 0.1210 - mape: 95.2547 - val_loss: 0.1315 - val_mae: 0.2881 - val_mape: 147.2227\n",
      "Epoch 46/50\n",
      "117/117 [==============================] - 75s 641ms/step - loss: 0.0212 - mae: 0.1133 - mape: 109.3294 - val_loss: 0.1358 - val_mae: 0.2777 - val_mape: 128.2840\n",
      "Epoch 47/50\n",
      "117/117 [==============================] - 75s 641ms/step - loss: 0.0215 - mae: 0.1151 - mape: 107.7764 - val_loss: 0.1249 - val_mae: 0.2680 - val_mape: 131.2037\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 75s 640ms/step - loss: 0.0206 - mae: 0.1119 - mape: 102.1834 - val_loss: 0.1256 - val_mae: 0.2697 - val_mape: 127.4876\n",
      "Epoch 49/50\n",
      "117/117 [==============================] - 74s 636ms/step - loss: 0.0206 - mae: 0.1124 - mape: 89.9972 - val_loss: 0.1280 - val_mae: 0.2770 - val_mape: 127.4416\n",
      "Epoch 50/50\n",
      "117/117 [==============================] - 75s 638ms/step - loss: 0.0212 - mae: 0.1136 - mape: 95.0212 - val_loss: 0.1222 - val_mae: 0.2688 - val_mape: 132.6637\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 26292<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_171915-9ac5xfsd\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_171915-9ac5xfsd\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>49</td></tr><tr><td>loss</td><td>0.02031</td></tr><tr><td>mae</td><td>0.11122</td></tr><tr><td>mape</td><td>91.58892</td></tr><tr><td>val_loss</td><td>0.12222</td></tr><tr><td>val_mae</td><td>0.26883</td></tr><tr><td>val_mape</td><td>132.66365</td></tr><tr><td>_runtime</td><td>3887</td></tr><tr><td>_timestamp</td><td>1620059042</td></tr><tr><td>_step</td><td>49</td></tr><tr><td>best_val_loss</td><td>0.09337</td></tr><tr><td>best_epoch</td><td>13</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mae</td><td>█▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mape</td><td>█▄▃▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▂▂▁▂▂▁▁▁</td></tr><tr><td>val_loss</td><td>█▄▄▃▃▂▂▂▂▂▁▁▂▁▂▂▂▂▂▂▁▂▂▃▂▃▄▃▃▂▃▂▃▃▃▃▃▃▃▃</td></tr><tr><td>val_mae</td><td>█▄▄▃▄▂▃▂▃▃▁▁▂▁▂▂▂▂▂▂▁▂▂▃▂▃▃▃▃▂▃▂▃▃▄▂▃▂▃▂</td></tr><tr><td>val_mape</td><td>▆▅█▇▆▄▇▂▄▆▃▃▂▁▄▂▄▁▃▂▁▄▃▃▄▄▃▅▄▄▅▄▆▅▆▃▅▅▅▆</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">apricot-sweep-9</strong>: <a href=\"https://wandb.ai/nbvanting/thesis/runs/9ac5xfsd\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/9ac5xfsd</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: wvl6kbm9 with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 183\n",
      "wandb: \tcnn_layer_size_1: 129\n",
      "wandb: \tcnn_layer_size_2: 82\n",
      "wandb: \tdropout: 0.11261000099545448\n",
      "wandb: \tepochs: 50\n",
      "wandb: \tgru_layer_size_1: 40\n",
      "wandb: \tgru_layer_size_2: 38\n",
      "wandb: \tlearning_rate: 0.07911497407574514\n",
      "wandb: \tlookback: 414\n",
      "wandb: \tmomentum: 0.9\n",
      "wandb: \tnum_cnn_layers: 1\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 1\n",
      "wandb: \toptimizer: adam\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">chocolate-sweep-10</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/wvl6kbm9\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/wvl6kbm9</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_182407-wvl6kbm9</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "82/82 [==============================] - 32s 337ms/step - loss: 1.8827 - mae: 0.9933 - mape: 398.2573 - val_loss: 1.7255 - val_mae: 0.9251 - val_mape: 153.8946\n",
      "Epoch 2/50\n",
      "82/82 [==============================] - 27s 326ms/step - loss: 0.9655 - mae: 0.7608 - mape: 257.0517 - val_loss: 1.6657 - val_mae: 0.9177 - val_mape: 128.2459\n",
      "Epoch 3/50\n",
      "82/82 [==============================] - 25s 305ms/step - loss: 1.0329 - mae: 0.7874 - mape: 157.5566 - val_loss: 1.5185 - val_mae: 0.8929 - val_mape: 102.0786\n",
      "Epoch 4/50\n",
      "82/82 [==============================] - 25s 301ms/step - loss: 1.0956 - mae: 0.8074 - mape: 225.5746 - val_loss: 1.6544 - val_mae: 0.9156 - val_mape: 125.4023\n",
      "Epoch 5/50\n",
      "82/82 [==============================] - 25s 300ms/step - loss: 1.0336 - mae: 0.7851 - mape: 166.4043 - val_loss: 1.6540 - val_mae: 0.9155 - val_mape: 125.3038\n",
      "Epoch 6/50\n",
      "82/82 [==============================] - 25s 300ms/step - loss: 1.0093 - mae: 0.7762 - mape: 138.4123 - val_loss: 1.7576 - val_mae: 0.9350 - val_mape: 151.0373\n",
      "Epoch 7/50\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 1.0352 - mae: 0.7860 - mape: 148.6728"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1864<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_182407-wvl6kbm9\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_182407-wvl6kbm9\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>5</td></tr><tr><td>loss</td><td>1.02082</td></tr><tr><td>mae</td><td>0.78406</td></tr><tr><td>mape</td><td>140.6042</td></tr><tr><td>val_loss</td><td>1.75756</td></tr><tr><td>val_mae</td><td>0.93505</td></tr><tr><td>val_mape</td><td>151.03731</td></tr><tr><td>_runtime</td><td>162</td></tr><tr><td>_timestamp</td><td>1620059210</td></tr><tr><td>_step</td><td>5</td></tr><tr><td>best_val_loss</td><td>1.51853</td></tr><tr><td>best_epoch</td><td>2</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▄▅▇█</td></tr><tr><td>loss</td><td>█▁▃▅▂▂</td></tr><tr><td>mae</td><td>█▁▅▇▃▃</td></tr><tr><td>mape</td><td>█▄▃▅▂▁</td></tr><tr><td>val_loss</td><td>▇▅▁▅▅█</td></tr><tr><td>val_mae</td><td>▆▅▁▅▅█</td></tr><tr><td>val_mape</td><td>█▅▁▄▄█</td></tr><tr><td>_runtime</td><td>▁▃▄▅▇█</td></tr><tr><td>_timestamp</td><td>▁▃▄▅▇█</td></tr><tr><td>_step</td><td>▁▂▄▅▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">chocolate-sweep-10</strong>: <a href=\"https://wandb.ai/nbvanting/thesis/runs/wvl6kbm9\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/wvl6kbm9</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: 7n3x866i with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 227\n",
      "wandb: \tcnn_layer_size_1: 70\n",
      "wandb: \tcnn_layer_size_2: 106\n",
      "wandb: \tdropout: 0.01530791982572427\n",
      "wandb: \tepochs: 50\n",
      "wandb: \tgru_layer_size_1: 51\n",
      "wandb: \tgru_layer_size_2: 194\n",
      "wandb: \tlearning_rate: 0.024205150803738973\n",
      "wandb: \tlookback: 718\n",
      "wandb: \tmomentum: 0.9\n",
      "wandb: \tnum_cnn_layers: 2\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 2\n",
      "wandb: \toptimizer: sgd\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">easy-sweep-11</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/7n3x866i\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/7n3x866i</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_182719-7n3x866i</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "65/65 [==============================] - 72s 1s/step - loss: 0.8073 - mae: 0.7035 - mape: 265.9180 - val_loss: 1.4211 - val_mae: 1.0004 - val_mape: 354.0415\n",
      "Epoch 2/50\n",
      "65/65 [==============================] - 68s 1s/step - loss: 0.7066 - mae: 0.6671 - mape: 322.5278 - val_loss: 1.2597 - val_mae: 0.8957 - val_mape: 252.7139\n",
      "Epoch 3/50\n",
      "65/65 [==============================] - 70s 1s/step - loss: 0.6136 - mae: 0.6206 - mape: 292.9874 - val_loss: 0.5242 - val_mae: 0.5423 - val_mape: 178.0345\n",
      "Epoch 4/50\n",
      "65/65 [==============================] - 72s 1s/step - loss: 0.3206 - mae: 0.4396 - mape: 250.7209 - val_loss: 0.1989 - val_mae: 0.3559 - val_mape: 125.0303\n",
      "Epoch 5/50\n",
      "65/65 [==============================] - 68s 1s/step - loss: 0.1816 - mae: 0.3330 - mape: 209.9811 - val_loss: 0.2087 - val_mae: 0.3795 - val_mape: 152.3450\n",
      "Epoch 6/50\n",
      "65/65 [==============================] - 68s 1s/step - loss: 0.1454 - mae: 0.2970 - mape: 190.8417 - val_loss: 0.1242 - val_mae: 0.2807 - val_mape: 104.3039\n",
      "Epoch 7/50\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.1226 - mae: 0.2710 - mape: 191.6811 - val_loss: 0.1387 - val_mae: 0.3073 - val_mape: 124.7857\n",
      "Epoch 8/50\n",
      "65/65 [==============================] - 68s 1s/step - loss: 0.1058 - mae: 0.2521 - mape: 174.0386 - val_loss: 0.1231 - val_mae: 0.2888 - val_mape: 114.4790\n",
      "Epoch 9/50\n",
      "65/65 [==============================] - 68s 1s/step - loss: 0.0967 - mae: 0.2408 - mape: 166.6996 - val_loss: 0.1227 - val_mae: 0.2875 - val_mape: 113.0888\n",
      "Epoch 10/50\n",
      "65/65 [==============================] - 68s 1s/step - loss: 0.0912 - mae: 0.2336 - mape: 153.0829 - val_loss: 0.1081 - val_mae: 0.2711 - val_mape: 100.4095\n",
      "Epoch 11/50\n",
      "65/65 [==============================] - 68s 1s/step - loss: 0.0895 - mae: 0.2304 - mape: 146.6440 - val_loss: 0.1003 - val_mae: 0.2552 - val_mape: 99.5299\n",
      "Epoch 12/50\n",
      "65/65 [==============================] - 68s 1s/step - loss: 0.0835 - mae: 0.2228 - mape: 150.6311 - val_loss: 0.1124 - val_mae: 0.2709 - val_mape: 117.6271\n",
      "Epoch 13/50\n",
      "65/65 [==============================] - 68s 1s/step - loss: 0.0829 - mae: 0.2215 - mape: 158.4868 - val_loss: 0.1079 - val_mae: 0.2729 - val_mape: 108.1130\n",
      "Epoch 14/50\n",
      "65/65 [==============================] - 68s 1s/step - loss: 0.0798 - mae: 0.2182 - mape: 161.4714 - val_loss: 0.1082 - val_mae: 0.2687 - val_mape: 118.1090\n",
      "Epoch 15/50\n",
      "65/65 [==============================] - 68s 1s/step - loss: 0.0772 - mae: 0.2144 - mape: 145.3140 - val_loss: 0.0891 - val_mae: 0.2419 - val_mape: 101.7545\n",
      "Epoch 16/50\n",
      "65/65 [==============================] - 68s 1s/step - loss: 0.0733 - mae: 0.2082 - mape: 135.9158 - val_loss: 0.0918 - val_mae: 0.2450 - val_mape: 106.4157\n",
      "Epoch 17/50\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0724 - mae: 0.2066 - mape: 132.1159 - val_loss: 0.1194 - val_mae: 0.2806 - val_mape: 120.8109\n",
      "Epoch 18/50\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0704 - mae: 0.2046 - mape: 139.5300 - val_loss: 0.0905 - val_mae: 0.2449 - val_mape: 99.1418\n",
      "Epoch 19/50\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0678 - mae: 0.2005 - mape: 142.8846 - val_loss: 0.1003 - val_mae: 0.2600 - val_mape: 111.3932\n",
      "Epoch 20/50\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0666 - mae: 0.1993 - mape: 145.1043 - val_loss: 0.0833 - val_mae: 0.2324 - val_mape: 92.0062\n",
      "Epoch 21/50\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0655 - mae: 0.1965 - mape: 138.0890 - val_loss: 0.0812 - val_mae: 0.2297 - val_mape: 91.3148\n",
      "Epoch 22/50\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0656 - mae: 0.1970 - mape: 153.7837 - val_loss: 0.1051 - val_mae: 0.2673 - val_mape: 123.7976\n",
      "Epoch 23/50\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0670 - mae: 0.1987 - mape: 135.1398 - val_loss: 0.0936 - val_mae: 0.2489 - val_mape: 104.5317\n",
      "Epoch 24/50\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0639 - mae: 0.1957 - mape: 134.2902 - val_loss: 0.1252 - val_mae: 0.2927 - val_mape: 132.8427\n",
      "Epoch 25/50\n",
      "65/65 [==============================] - 68s 1s/step - loss: 0.0610 - mae: 0.1914 - mape: 140.7480 - val_loss: 0.0846 - val_mae: 0.2367 - val_mape: 98.9281\n",
      "Epoch 26/50\n",
      "65/65 [==============================] - 68s 1s/step - loss: 0.0607 - mae: 0.1901 - mape: 134.3131 - val_loss: 0.1015 - val_mae: 0.2661 - val_mape: 114.1527\n",
      "Epoch 27/50\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0587 - mae: 0.1871 - mape: 126.5819 - val_loss: 0.0923 - val_mae: 0.2482 - val_mape: 103.8754\n",
      "Epoch 28/50\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0591 - mae: 0.1882 - mape: 129.3716 - val_loss: 0.0805 - val_mae: 0.2263 - val_mape: 95.0134\n",
      "Epoch 29/50\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0546 - mae: 0.1802 - mape: 123.6941 - val_loss: 0.1017 - val_mae: 0.2604 - val_mape: 112.1561\n",
      "Epoch 30/50\n",
      "65/65 [==============================] - 70s 1s/step - loss: 0.0564 - mae: 0.1831 - mape: 121.6492 - val_loss: 0.0921 - val_mae: 0.2498 - val_mape: 109.9886\n",
      "Epoch 31/50\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0537 - mae: 0.1782 - mape: 120.6240 - val_loss: 0.1040 - val_mae: 0.2595 - val_mape: 115.3310\n",
      "Epoch 32/50\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0555 - mae: 0.1828 - mape: 120.1351 - val_loss: 0.0851 - val_mae: 0.2307 - val_mape: 95.7259\n",
      "Epoch 33/50\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0549 - mae: 0.1809 - mape: 132.1464 - val_loss: 0.0845 - val_mae: 0.2334 - val_mape: 98.6866\n",
      "Epoch 34/50\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0540 - mae: 0.1802 - mape: 125.0178 - val_loss: 0.0819 - val_mae: 0.2276 - val_mape: 91.8465\n",
      "Epoch 35/50\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0537 - mae: 0.1794 - mape: 123.7263 - val_loss: 0.0851 - val_mae: 0.2381 - val_mape: 99.1551\n",
      "Epoch 36/50\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0498 - mae: 0.1730 - mape: 122.9036 - val_loss: 0.0804 - val_mae: 0.2300 - val_mape: 93.5362\n",
      "Epoch 37/50\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0492 - mae: 0.1731 - mape: 124.2397 - val_loss: 0.0748 - val_mae: 0.2160 - val_mape: 87.3816\n",
      "Epoch 38/50\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0480 - mae: 0.1694 - mape: 106.6397 - val_loss: 0.0863 - val_mae: 0.2384 - val_mape: 98.8600\n",
      "Epoch 39/50\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0486 - mae: 0.1704 - mape: 121.8114 - val_loss: 0.1050 - val_mae: 0.2645 - val_mape: 114.1286\n",
      "Epoch 40/50\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0453 - mae: 0.1648 - mape: 107.5324 - val_loss: 0.0833 - val_mae: 0.2328 - val_mape: 96.9158\n",
      "Epoch 41/50\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0468 - mae: 0.1674 - mape: 116.8560 - val_loss: 0.0795 - val_mae: 0.2272 - val_mape: 92.4141\n",
      "Epoch 42/50\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0486 - mae: 0.1705 - mape: 119.2983 - val_loss: 0.0794 - val_mae: 0.2296 - val_mape: 94.1181\n",
      "Epoch 43/50\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0469 - mae: 0.1681 - mape: 122.8930 - val_loss: 0.0865 - val_mae: 0.2403 - val_mape: 101.7464\n",
      "Epoch 44/50\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0447 - mae: 0.1635 - mape: 119.5468 - val_loss: 0.0794 - val_mae: 0.2255 - val_mape: 94.4069\n",
      "Epoch 45/50\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0438 - mae: 0.1626 - mape: 122.2122 - val_loss: 0.0926 - val_mae: 0.2478 - val_mape: 103.2600\n",
      "Epoch 46/50\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0426 - mae: 0.1592 - mape: 120.4940 - val_loss: 0.0831 - val_mae: 0.2342 - val_mape: 101.0274\n",
      "Epoch 47/50\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0437 - mae: 0.1633 - mape: 107.7800 - val_loss: 0.1149 - val_mae: 0.2758 - val_mape: 122.1539\n",
      "Epoch 48/50\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0440 - mae: 0.1634 - mape: 115.7840 - val_loss: 0.0913 - val_mae: 0.2440 - val_mape: 103.5575\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 67s 1s/step - loss: 0.0431 - mae: 0.1607 - mape: 113.3857 - val_loss: 0.0843 - val_mae: 0.2372 - val_mape: 100.3949\n",
      "Epoch 50/50\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0412 - mae: 0.1574 - mape: 97.0587 - val_loss: 0.0861 - val_mae: 0.2402 - val_mape: 95.6702\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 34176<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_182719-7n3x866i\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_182719-7n3x866i\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>49</td></tr><tr><td>loss</td><td>0.04012</td></tr><tr><td>mae</td><td>0.15542</td></tr><tr><td>mape</td><td>112.10014</td></tr><tr><td>val_loss</td><td>0.08609</td></tr><tr><td>val_mae</td><td>0.24015</td></tr><tr><td>val_mape</td><td>95.67025</td></tr><tr><td>_runtime</td><td>3385</td></tr><tr><td>_timestamp</td><td>1620062624</td></tr><tr><td>_step</td><td>49</td></tr><tr><td>best_val_loss</td><td>0.07479</td></tr><tr><td>best_epoch</td><td>36</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>██▆▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mae</td><td>██▇▄▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mape</td><td>▇█▇▅▃▃▃▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▂▁▂▁▁▂▁</td></tr><tr><td>val_loss</td><td>█▇▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_mae</td><td>█▇▄▂▂▂▂▂▁▁▂▁▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁</td></tr><tr><td>val_mape</td><td>█▅▃▂▁▂▂▂▁▂▂▂▁▂▁▂▁▂▁▂▂▁▁▂▂▁▁▁▁▁▁▂▁▁▁▁▁▂▁▁</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">easy-sweep-11</strong>: <a href=\"https://wandb.ai/nbvanting/thesis/runs/7n3x866i\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/7n3x866i</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: u8f490yw with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 248\n",
      "wandb: \tcnn_layer_size_1: 39\n",
      "wandb: \tcnn_layer_size_2: 174\n",
      "wandb: \tdropout: 0.3526781533415718\n",
      "wandb: \tepochs: 50\n",
      "wandb: \tgru_layer_size_1: 244\n",
      "wandb: \tgru_layer_size_2: 190\n",
      "wandb: \tlearning_rate: 0.06175795516981232\n",
      "wandb: \tlookback: 680\n",
      "wandb: \tmomentum: 0.95\n",
      "wandb: \tnum_cnn_layers: 2\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 2\n",
      "wandb: \toptimizer: adam\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">olive-sweep-12</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/u8f490yw\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/u8f490yw</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_192350-u8f490yw</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "59/59 [==============================] - 160s 3s/step - loss: 10.4496 - mae: 2.2160 - mape: 1375.9313 - val_loss: 1.6411 - val_mae: 0.9044 - val_mape: 116.6543\n",
      "Epoch 2/50\n",
      "59/59 [==============================] - 147s 2s/step - loss: 1.3088 - mae: 0.8885 - mape: 583.9628 - val_loss: 1.4718 - val_mae: 0.8850 - val_mape: 123.6730\n",
      "Epoch 3/50\n",
      "59/59 [==============================] - 151s 3s/step - loss: 1.0384 - mae: 0.7961 - mape: 213.7951 - val_loss: 1.5196 - val_mae: 0.8887 - val_mape: 106.8226\n",
      "Epoch 4/50\n",
      "59/59 [==============================] - 154s 3s/step - loss: 1.0921 - mae: 0.8125 - mape: 222.8495 - val_loss: 1.6171 - val_mae: 0.9008 - val_mape: 111.0275\n",
      "Epoch 5/50\n",
      "59/59 [==============================] - 153s 3s/step - loss: 1.0431 - mae: 0.7926 - mape: 183.0406 - val_loss: 1.7375 - val_mae: 0.9202 - val_mape: 139.9775\n",
      "Epoch 6/50\n",
      "59/59 [==============================] - 153s 3s/step - loss: 1.0639 - mae: 0.7992 - mape: 228.5217 - val_loss: 1.3693 - val_mae: 0.8945 - val_mape: 198.2023\n",
      "Epoch 7/50\n",
      "46/59 [======================>.......] - ETA: 33s - loss: 1.1127 - mae: 0.8204 - mape: 245.3880"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 22284<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_192350-u8f490yw\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_192350-u8f490yw\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>5</td></tr><tr><td>loss</td><td>1.04661</td></tr><tr><td>mae</td><td>0.79274</td></tr><tr><td>mape</td><td>254.69891</td></tr><tr><td>val_loss</td><td>1.36929</td></tr><tr><td>val_mae</td><td>0.89446</td></tr><tr><td>val_mape</td><td>198.20227</td></tr><tr><td>_runtime</td><td>923</td></tr><tr><td>_timestamp</td><td>1620063553</td></tr><tr><td>_step</td><td>5</td></tr><tr><td>best_val_loss</td><td>1.36929</td></tr><tr><td>best_epoch</td><td>5</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▄▅▇█</td></tr><tr><td>loss</td><td>█▁▁▁▁▁</td></tr><tr><td>mae</td><td>█▁▁▁▁▁</td></tr><tr><td>mape</td><td>█▃▁▂▁▁</td></tr><tr><td>val_loss</td><td>▆▃▄▆█▁</td></tr><tr><td>val_mae</td><td>▅▁▂▄█▃</td></tr><tr><td>val_mape</td><td>▂▂▁▁▄█</td></tr><tr><td>_runtime</td><td>▁▂▄▅▇█</td></tr><tr><td>_timestamp</td><td>▁▂▄▅▇█</td></tr><tr><td>_step</td><td>▁▂▄▅▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">olive-sweep-12</strong>: <a href=\"https://wandb.ai/nbvanting/thesis/runs/u8f490yw\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/u8f490yw</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: qyqjfrtg with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 247\n",
      "wandb: \tcnn_layer_size_1: 191\n",
      "wandb: \tcnn_layer_size_2: 128\n",
      "wandb: \tdropout: 0.4676747098177177\n",
      "wandb: \tepochs: 50\n",
      "wandb: \tgru_layer_size_1: 156\n",
      "wandb: \tgru_layer_size_2: 45\n",
      "wandb: \tlearning_rate: 0.011999687466323749\n",
      "wandb: \tlookback: 187\n",
      "wandb: \tmomentum: 0.9\n",
      "wandb: \tnum_cnn_layers: 2\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 2\n",
      "wandb: \toptimizer: sgd\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">eager-sweep-13</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/qyqjfrtg\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/qyqjfrtg</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_194119-qyqjfrtg</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "62/62 [==============================] - 31s 415ms/step - loss: 0.8134 - mae: 0.7079 - mape: 389.7472 - val_loss: 1.1777 - val_mae: 0.9023 - val_mape: 431.9393\n",
      "Epoch 2/50\n",
      "62/62 [==============================] - 25s 408ms/step - loss: 0.6924 - mae: 0.6592 - mape: 435.0676 - val_loss: 1.1155 - val_mae: 0.8423 - val_mape: 289.9789\n",
      "Epoch 3/50\n",
      "62/62 [==============================] - 25s 399ms/step - loss: 0.6686 - mae: 0.6517 - mape: 474.3593 - val_loss: 1.0983 - val_mae: 0.8315 - val_mape: 257.2895\n",
      "Epoch 4/50\n",
      "62/62 [==============================] - 25s 399ms/step - loss: 0.6502 - mae: 0.6447 - mape: 376.4436 - val_loss: 0.9120 - val_mae: 0.7987 - val_mape: 343.6653\n",
      "Epoch 5/50\n",
      "62/62 [==============================] - 25s 397ms/step - loss: 0.5490 - mae: 0.5956 - mape: 348.4166 - val_loss: 0.5326 - val_mae: 0.5677 - val_mape: 245.6507\n",
      "Epoch 6/50\n",
      "62/62 [==============================] - 25s 400ms/step - loss: 0.4052 - mae: 0.5006 - mape: 333.7822 - val_loss: 0.3758 - val_mae: 0.5083 - val_mape: 295.2832\n",
      "Epoch 7/50\n",
      "12/62 [====>.........................] - ETA: 19s - loss: 0.3427 - mae: 0.4609 - mape: 414.9124"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 21964<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_194119-qyqjfrtg\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_194119-qyqjfrtg\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>5</td></tr><tr><td>loss</td><td>0.38591</td></tr><tr><td>mae</td><td>0.48462</td></tr><tr><td>mape</td><td>273.7373</td></tr><tr><td>val_loss</td><td>0.37581</td></tr><tr><td>val_mae</td><td>0.50826</td></tr><tr><td>val_mape</td><td>295.28323</td></tr><tr><td>_runtime</td><td>160</td></tr><tr><td>_timestamp</td><td>1620063840</td></tr><tr><td>_step</td><td>5</td></tr><tr><td>best_val_loss</td><td>0.37581</td></tr><tr><td>best_epoch</td><td>5</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▄▅▇█</td></tr><tr><td>loss</td><td>█▇▇▆▄▁</td></tr><tr><td>mae</td><td>█▇▇▇▄▁</td></tr><tr><td>mape</td><td>▇▇█▆▄▁</td></tr><tr><td>val_loss</td><td>█▇▇▆▂▁</td></tr><tr><td>val_mae</td><td>█▇▇▆▂▁</td></tr><tr><td>val_mape</td><td>█▃▁▅▁▃</td></tr><tr><td>_runtime</td><td>▁▂▄▅▇█</td></tr><tr><td>_timestamp</td><td>▁▂▄▅▇█</td></tr><tr><td>_step</td><td>▁▂▄▅▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">eager-sweep-13</strong>: <a href=\"https://wandb.ai/nbvanting/thesis/runs/qyqjfrtg\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/qyqjfrtg</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: 1atnnqcr with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 76\n",
      "wandb: \tcnn_layer_size_1: 135\n",
      "wandb: \tcnn_layer_size_2: 233\n",
      "wandb: \tdropout: 0.17163355609271924\n",
      "wandb: \tepochs: 50\n",
      "wandb: \tgru_layer_size_1: 236\n",
      "wandb: \tgru_layer_size_2: 52\n",
      "wandb: \tlearning_rate: 0.0860510828384059\n",
      "wandb: \tlookback: 704\n",
      "wandb: \tmomentum: 0.95\n",
      "wandb: \tnum_cnn_layers: 2\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 1\n",
      "wandb: \toptimizer: adam\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">laced-sweep-14</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/1atnnqcr\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/1atnnqcr</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_194411-1atnnqcr</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "193/193 [==============================] - 126s 631ms/step - loss: 1.3896 - mae: 0.9080 - mape: 378.5829 - val_loss: 1.4205 - val_mae: 0.8752 - val_mape: 137.6582\n",
      "Epoch 2/50\n",
      "193/193 [==============================] - 120s 622ms/step - loss: 1.0635 - mae: 0.8026 - mape: 193.9255 - val_loss: 1.4517 - val_mae: 1.0200 - val_mape: 381.6514\n",
      "Epoch 3/50\n",
      "193/193 [==============================] - 115s 596ms/step - loss: 1.2102 - mae: 0.8600 - mape: 301.2205 - val_loss: 1.6922 - val_mae: 0.9089 - val_mape: 131.4606\n",
      "Epoch 4/50\n",
      "193/193 [==============================] - 114s 590ms/step - loss: 1.1025 - mae: 0.8168 - mape: 310.2066 - val_loss: 1.3818 - val_mae: 0.8768 - val_mape: 162.2321\n",
      "Epoch 5/50\n",
      "193/193 [==============================] - 114s 592ms/step - loss: 1.1323 - mae: 0.8282 - mape: 256.1383 - val_loss: 1.4758 - val_mae: 0.8776 - val_mape: 113.7972\n",
      "Epoch 6/50\n",
      "193/193 [==============================] - 114s 593ms/step - loss: 1.0573 - mae: 0.8013 - mape: 212.2550 - val_loss: 1.9383 - val_mae: 0.9602 - val_mape: 187.5995\n",
      "Epoch 7/50\n",
      "193/193 [==============================] - 114s 591ms/step - loss: 1.0715 - mae: 0.8034 - mape: 197.4857 - val_loss: 1.5585 - val_mae: 0.8875 - val_mape: 102.4064\n",
      "Epoch 8/50\n",
      "193/193 [==============================] - 120s 623ms/step - loss: 1.1515 - mae: 0.8306 - mape: 296.4415 - val_loss: 1.4218 - val_mae: 0.8752 - val_mape: 136.9160\n",
      "Epoch 9/50\n",
      "124/193 [==================>...........] - ETA: 43s - loss: 1.0912 - mae: 0.8132 - mape: 277.4508"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 21040<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_194411-1atnnqcr\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_194411-1atnnqcr\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>7</td></tr><tr><td>loss</td><td>1.09452</td></tr><tr><td>mae</td><td>0.81104</td></tr><tr><td>mape</td><td>248.57501</td></tr><tr><td>val_loss</td><td>1.42184</td></tr><tr><td>val_mae</td><td>0.87516</td></tr><tr><td>val_mape</td><td>136.91605</td></tr><tr><td>_runtime</td><td>943</td></tr><tr><td>_timestamp</td><td>1620064794</td></tr><tr><td>_step</td><td>7</td></tr><tr><td>best_val_loss</td><td>1.38176</td></tr><tr><td>best_epoch</td><td>3</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>loss</td><td>█▃▅▅▅▁▂▅</td></tr><tr><td>mae</td><td>█▃▆▅▅▁▂▅</td></tr><tr><td>mape</td><td>▇▃▆█▄▂▁▅</td></tr><tr><td>val_loss</td><td>▁▂▅▁▂█▃▂</td></tr><tr><td>val_mae</td><td>▁█▃▁▁▅▂▁</td></tr><tr><td>val_mape</td><td>▂█▂▂▁▃▁▂</td></tr><tr><td>_runtime</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▄▅▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">laced-sweep-14</strong>: <a href=\"https://wandb.ai/nbvanting/thesis/runs/1atnnqcr\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/1atnnqcr</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: icgco3tt with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 230\n",
      "wandb: \tcnn_layer_size_1: 237\n",
      "wandb: \tcnn_layer_size_2: 34\n",
      "wandb: \tdropout: 0.3580256262036787\n",
      "wandb: \tepochs: 50\n",
      "wandb: \tgru_layer_size_1: 59\n",
      "wandb: \tgru_layer_size_2: 202\n",
      "wandb: \tlearning_rate: 0.06418519205943991\n",
      "wandb: \tlookback: 174\n",
      "wandb: \tmomentum: 0.9\n",
      "wandb: \tnum_cnn_layers: 2\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 1\n",
      "wandb: \toptimizer: rmsprop\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">firm-sweep-15</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/icgco3tt\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/icgco3tt</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_200118-icgco3tt</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "66/66 [==============================] - 23s 277ms/step - loss: 24.9860 - mae: 3.6159 - mape: 21401.7243 - val_loss: 6.7944 - val_mae: 2.3980 - val_mape: 2438.9023\n",
      "Epoch 2/50\n",
      "66/66 [==============================] - 18s 266ms/step - loss: 12.1038 - mae: 3.1105 - mape: 17252.5471 - val_loss: 9.3897 - val_mae: 2.8622 - val_mape: 2868.5659\n",
      "Epoch 3/50\n",
      "66/66 [==============================] - 18s 267ms/step - loss: 7.2454 - mae: 2.3554 - mape: 12288.3195 - val_loss: 13.7975 - val_mae: 3.5429 - val_mape: 3464.0093\n",
      "Epoch 4/50\n",
      "66/66 [==============================] - 18s 267ms/step - loss: 5.9873 - mae: 2.0312 - mape: 13521.2256 - val_loss: 2.2556 - val_mae: 1.3417 - val_mape: 1282.1586\n",
      "Epoch 5/50\n",
      "66/66 [==============================] - 18s 265ms/step - loss: 4.4496 - mae: 1.7736 - mape: 10073.5473 - val_loss: 2.9376 - val_mae: 1.5410 - val_mape: 1533.9121\n",
      "Epoch 6/50\n",
      "66/66 [==============================] - 18s 265ms/step - loss: 2.8191 - mae: 1.3749 - mape: 5826.5409 - val_loss: 1.5855 - val_mae: 1.1059 - val_mape: 926.2328\n",
      "Epoch 7/50\n",
      "66/66 [==============================] - 18s 267ms/step - loss: 3.1519 - mae: 1.4339 - mape: 4305.9533 - val_loss: 9.7144 - val_mae: 2.9165 - val_mape: 2917.2119\n",
      "Epoch 8/50\n",
      "66/66 [==============================] - 18s 266ms/step - loss: 2.9992 - mae: 1.3615 - mape: 12205.9905 - val_loss: 1.6561 - val_mae: 1.1341 - val_mape: 974.5629\n",
      "Epoch 9/50\n",
      "58/66 [=========================>....] - ETA: 2s - loss: 2.5740 - mae: 1.3076 - mape: 2153.3103"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 21956<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_200118-icgco3tt\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_200118-icgco3tt\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>7</td></tr><tr><td>loss</td><td>2.53077</td></tr><tr><td>mae</td><td>1.26404</td></tr><tr><td>mape</td><td>7655.06348</td></tr><tr><td>val_loss</td><td>1.65606</td></tr><tr><td>val_mae</td><td>1.13411</td></tr><tr><td>val_mape</td><td>974.56293</td></tr><tr><td>_runtime</td><td>151</td></tr><tr><td>_timestamp</td><td>1620065029</td></tr><tr><td>_step</td><td>7</td></tr><tr><td>best_val_loss</td><td>1.58553</td></tr><tr><td>best_epoch</td><td>5</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>loss</td><td>█▅▃▂▂▁▁▁</td></tr><tr><td>mae</td><td>█▇▄▃▂▁▁▁</td></tr><tr><td>mape</td><td>█▆▆▆▂▁▁▄</td></tr><tr><td>val_loss</td><td>▄▅█▁▂▁▆▁</td></tr><tr><td>val_mae</td><td>▅▆█▂▂▁▆▁</td></tr><tr><td>val_mape</td><td>▅▆█▂▃▁▆▁</td></tr><tr><td>_runtime</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▄▅▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">firm-sweep-15</strong>: <a href=\"https://wandb.ai/nbvanting/thesis/runs/icgco3tt\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/icgco3tt</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: r7yneo68 with config:\n",
      "wandb: \tactivation_cnn: relu\n",
      "wandb: \tactivation_gru: tanh\n",
      "wandb: \tbatch_size: 38\n",
      "wandb: \tcnn_layer_size_1: 225\n",
      "wandb: \tcnn_layer_size_2: 128\n",
      "wandb: \tdropout: 0.31963665946425573\n",
      "wandb: \tepochs: 50\n",
      "wandb: \tgru_layer_size_1: 104\n",
      "wandb: \tgru_layer_size_2: 238\n",
      "wandb: \tlearning_rate: 0.053036436782389416\n",
      "wandb: \tlookback: 470\n",
      "wandb: \tmomentum: 0.8\n",
      "wandb: \tnum_cnn_layers: 1\n",
      "wandb: \tnum_features: 9\n",
      "wandb: \tnum_gru_layers: 2\n",
      "wandb: \toptimizer: adam\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">frosty-sweep-16</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nbvanting/thesis\" target=\"_blank\">https://wandb.ai/nbvanting/thesis</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/sweeps/y7xar0dh</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nbvanting/thesis/runs/r7yneo68\" target=\"_blank\">https://wandb.ai/nbvanting/thesis/runs/r7yneo68</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\nicol\\Documents\\SDU\\thesis\\model\\wandb\\run-20210503_200410-r7yneo68</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 162s 399ms/step - loss: 4.8730 - mae: 1.4642 - mape: 2630.2871 - val_loss: 1.5800 - val_mae: 0.9033 - val_mape: 111.8551\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 163s 417ms/step - loss: 1.4660 - mae: 0.9458 - mape: 595.1624 - val_loss: 2.1494 - val_mae: 1.0332 - val_mape: 255.4025\n",
      "Epoch 3/50\n",
      "148/391 [==========>...................] - ETA: 1:35 - loss: 1.5886 - mae: 0.9867 - mape: 540.6973"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=run_tuner, count=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-teaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-exhibition",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
